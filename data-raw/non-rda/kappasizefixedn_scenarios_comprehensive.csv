"domain","scenario_id","study_type","description","outcome_categories","raters","kappa0","proportions","alpha","n","constraint_type","clinical_context","research_question"
"small_sample_fixed","pilot_dermato_n30","Dermatology Pilot Study","Small pilot: What agreement detectable with n=30?",2,2,0.4,"0.10, 0.90",0.05,30,"pilot_budget","Dermatology resident training evaluation with limited budget for 30 cases","With only 30 melanoma cases available, what minimum agreement can we detect?"
"small_sample_fixed","emergency_protocol_n40","Emergency Protocol Feasibility","Emergency department feasibility: n=40 stroke CTs",2,2,0.5,"0.15, 0.85",0.05,40,"time_constraint","ED can review 40 stroke CT cases in 2 months, need to know detectable agreement","Given time constraints (2 months), what minimum kappa is detectable with n=40?"
"small_sample_fixed","rare_pathology_n35","Rare Pathology Limited Cases","Rare tumor: only 35 cases available annually",3,2,0.4,"0.30, 0.40, 0.30",0.05,35,"case_availability","Rare tumor type with only 35 cases per year in tertiary center","What minimum 3-level grading agreement can we assess with 35 rare cases?"
"small_sample_fixed","training_validation_n50","Training Program Validation","Post-training assessment with n=50 budget",2,3,0.5,"0.25, 0.75",0.05,50,"educational_budget","Three pathology trainees, budget allows 50 cases for competency assessment","With 50-case training budget and 3 raters, what agreement level is detectable?"
"small_sample_fixed","telemedicine_pilot_n45","Telemedicine Pilot Study","Telemedicine diagnostic agreement pilot",2,2,0.5,"0.30, 0.70",0.05,45,"pilot_phase","Pilot telemedicine program comparing remote vs in-person diagnosis","Pilot phase limited to 45 consultations: what minimum agreement detectable?"
"moderate_sample_fixed","radiology_qa_n100","Radiology QA Program","Standard QA sample: annual 100 mammograms",2,2,0.5,"0.20, 0.80",0.05,100,"qa_protocol","Annual quality assurance reviewing 100 mammograms per radiologist pair","With standard QA protocol (n=100), what minimum BIRADS agreement detectable?"
"moderate_sample_fixed","pathology_accred_n120","Pathology Accreditation","Accreditation requirement: minimum 120 cases",4,2,0.5,"0.25, 0.30, 0.30, 0.15",0.05,120,"regulatory_minimum","Accreditation body requires minimum 120 tumor grades for validation","Meeting minimum accreditation n=120, what 4-level grading agreement detectable?"
"moderate_sample_fixed","clinical_trial_n150","Clinical Trial Agreement","Biomarker agreement in n=150 trial",2,2,0.6,"0.35, 0.65",0.05,150,"trial_enrollment","Clinical trial enrolled 150 patients, need central pathology review agreement","Trial n=150 fixed by enrollment, what biomarker scoring agreement detectable?"
"moderate_sample_fixed","multicenter_qa_n90","Multicenter QA Study","Multicenter study: 30 cases × 3 sites",3,2,0.5,"0.30, 0.45, 0.25",0.05,90,"site_contribution","Three centers each contributing 30 cases for standardization study","With n=90 from 3 centers, what 3-level severity agreement detectable?"
"moderate_sample_fixed","insurance_audit_n80","Insurance Audit Sample","Audit sample size predetermined: n=80",2,2,0.4,"0.40, 0.60",0.05,80,"audit_protocol","Insurance company audits 80 randomly selected diagnosis codes annually","Fixed audit n=80 per protocol, what diagnosis agreement is detectable?"
"large_sample_fixed","registry_validation_n250","Cancer Registry Validation","Registry validation: 250 cases per year",5,2,0.6,"0.20, 0.25, 0.25, 0.20, 0.10",0.05,250,"registry_capacity","Cancer registry has capacity to validate 250 staging cases annually","With registry capacity n=250, what 5-stage TNM agreement detectable?"
"large_sample_fixed","screening_program_n300","Screening Program QA","National screening: 300 case QA sample",2,2,0.7,"0.25, 0.75",0.01,300,"national_program","National mammography screening program with 300-case annual QA","Stringent α=0.01, n=300 QA sample: what minimum screening agreement detectable?"
"large_sample_fixed","ai_validation_n400","AI Algorithm Validation","AI validation study: 400 images budgeted",2,2,0.6,"0.30, 0.70",0.05,400,"validation_protocol","AI diagnostic algorithm validation with 400 expert-labeled images","With 400-image validation set, what AI-human agreement is detectable?"
"large_sample_fixed","biobank_study_n500","Biobank Retrospective Study","Biobank cohort: 500 cases with tissue",4,2,0.65,"0.30, 0.30, 0.25, 0.15",0.05,500,"biobank_availability","Biobank has 500 cases with adequate tissue for central review","Using all 500 biobank cases, what 4-grade agreement is detectable?"
"large_sample_fixed","pharma_trial_n200","Pharmaceutical Trial Endpoint","Phase III trial: 200 patients enrolled",3,3,0.6,"0.35, 0.40, 0.25",0.05,200,"trial_completion","Completed phase III trial with 200 patients, 3-rater endpoint assessment","Trial complete with n=200 and 3 raters, what endpoint agreement detectable?"
"very_large_fixed","national_survey_n1000","National Health Survey","National survey: 1000 participant target",2,2,0.7,"0.50, 0.50",0.05,1000,"survey_design","National health survey with predetermined 1000-participant sample","Large national survey n=1000, what diagnostic agreement is detectable?"
"very_large_fixed","consortium_study_n800","International Consortium","Consortium study: 100 cases × 8 centers",3,2,0.65,"0.30, 0.45, 0.25",0.01,800,"center_contribution","International consortium, each of 8 centers contributes 100 cases","With n=800 consortium cases at α=0.01, what 3-level agreement detectable?"
"very_large_fixed","ehr_validation_n750","EHR Data Validation","Electronic health record: 750 chart reviews",2,2,0.6,"0.40, 0.60",0.05,750,"chart_review_capacity","EHR validation study with resources for 750 manual chart reviews","Chart review capacity n=750, what diagnosis coding agreement detectable?"
"very_large_fixed","longitudinal_cohort_n600","Longitudinal Cohort Follow-up","Cohort study: 600 patients reached at follow-up",4,2,0.6,"0.25, 0.30, 0.30, 0.15",0.05,600,"cohort_retention","Longitudinal cohort retained 600 of 800 original patients for imaging review","With n=600 retained patients, what 4-level imaging agreement detectable?"
"very_large_fixed","database_linkage_n900","Database Linkage Study","Linked databases: 900 matched patients",2,2,0.65,"0.30, 0.70",0.05,900,"record_linkage","Successful linkage of 900 patients between two clinical databases","Database linkage yielded n=900 matches, what diagnosis agreement detectable?"
"multi_rater_fixed","training_3raters_n60","Three-Rater Training Study","Training evaluation: 3 raters, 60 cases",2,3,0.5,"0.30, 0.70",0.05,60,"training_program","Pathology training program with 3 trainees reviewing 60 cases","With 3 raters and n=60 training cases, what minimum agreement detectable?"
"multi_rater_fixed","consensus_4raters_n80","Four-Rater Consensus Study","Consensus panel: 4 experts, 80 cases",3,4,0.6,"0.30, 0.40, 0.30",0.05,80,"expert_panel","Four experts forming consensus panel for guideline development","Expert panel (4 raters) with n=80, what 3-level consensus detectable?"
"multi_rater_fixed","multicenter_5raters_n100","Five-Center Comparison","Five centers: 1 rater each, 100 cases",2,5,0.55,"0.25, 0.75",0.05,100,"center_comparison","Comparing diagnostic practices across 5 centers (1 rater per center)","Five-center study with n=100 shared cases, what agreement detectable?"
"stringent_alpha_fixed","regulatory_n200_alpha01","Regulatory Submission","Regulatory requirement: n=200, α=0.01",2,2,0.7,"0.30, 0.70",0.01,200,"regulatory_standard","FDA submission requires 200 cases with 99% confidence for diagnostic agreement","Meeting regulatory n=200 at α=0.01, what minimum agreement detectable?"
