---
title: "Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making"
author: "ClinicoPath"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    code_folding: show
vignette: >
  %\VignetteIndexEntry{Co-Testing Analysis: Combining Diagnostic Tests for Better Clinical Decision Making}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  dpi = 150,
  out.width = "100%"
)

library(ClinicoPath)
```

# Introduction to Co-Testing Analysis

In clinical practice, physicians often use multiple diagnostic tests to improve diagnostic accuracy. The **co-testing analysis** function in ClinicoPath helps clinicians understand how combining two diagnostic tests affects post-test probabilities and clinical decision-making.

## What is Co-Testing?

Co-testing refers to the simultaneous use of two diagnostic tests to improve diagnostic performance. This approach is common in:

- **Cancer screening** (e.g., mammography + ultrasound)
- **Infectious disease diagnosis** (e.g., antigen test + PCR)
- **Cardiac evaluation** (e.g., troponin + ECG)
- **Neurological assessment** (e.g., MRI + clinical examination)

## Key Concepts

### Post-Test Probability
The probability of disease after obtaining test results, calculated using Bayes' theorem.

### Test Independence
Whether the results of one test influence the results of another test, given the patient's true disease status.

### Likelihood Ratios
- **Positive Likelihood Ratio (PLR)**: How much more likely a positive result is in diseased vs. non-diseased patients
- **Negative Likelihood Ratio (NLR)**: How much more likely a negative result is in diseased vs. non-diseased patients

# Understanding Test Independence vs. Dependence

## Independent Tests

Tests are **conditionally independent** when the result of one test doesn't affect the probability of the other test result, given the disease status.

**Mathematical formulation for independent tests:**
- P(Test1+ and Test2+ | Disease+) = Sensitivity₁ × Sensitivity₂
- P(Test1+ and Test2+ | Disease-) = (1-Specificity₁) × (1-Specificity₂)

## Dependent Tests

Tests are **conditionally dependent** when knowing one test result changes the probability of the other test result, even when disease status is known.

**When tests are likely dependent:**
- Both tests measure similar biological phenomena
- Tests use the same specimen or mechanism
- Tests are affected by the same confounding factors

# Clinical Examples

## Example 1: COVID-19 Screening with Independent Tests

Let's analyze a scenario where we use an antigen test and PCR test for COVID-19 screening, assuming they are independent.

```{r covid_independent}
# COVID-19 screening with antigen + PCR (independent)
covid_independent <- cotest(
  test1_sens = 0.68,    # Antigen test sensitivity
  test1_spec = 0.99,    # Antigen test specificity
  test2_sens = 0.95,    # PCR test sensitivity
  test2_spec = 0.99,    # PCR test specificity
  prevalence = 0.05,    # Community prevalence (5%)
  indep = TRUE,         # Assume independence
  fagan = TRUE,         # Show Fagan nomogram
  fnote = TRUE          # Show explanatory footnotes
)

print(covid_independent)
```

### Interpretation
- **Pre-test probability**: 5% (community prevalence)
- **Both tests positive**: Dramatically increases disease probability
- **Both tests negative**: Substantially decreases disease probability
- **Mixed results**: Individual test probabilities apply

## Example 2: COVID-19 Screening with Dependent Tests

Now let's consider the same tests but account for potential dependence (e.g., both tests may be affected by viral load).

```{r covid_dependent}
# COVID-19 screening with antigen + PCR (dependent)
covid_dependent <- cotest(
  test1_sens = 0.68,    # Antigen test sensitivity
  test1_spec = 0.99,    # Antigen test specificity
  test2_sens = 0.95,    # PCR test sensitivity
  test2_spec = 0.99,    # PCR test specificity
  prevalence = 0.05,    # Community prevalence (5%)
  indep = FALSE,        # Account for dependence
  cond_dep_pos = 0.15,  # Dependence in COVID+ patients
  cond_dep_neg = 0.05,  # Dependence in COVID- patients
  fagan = TRUE,         # Show Fagan nomogram
  fnote = TRUE          # Show explanatory footnotes
)

print(covid_dependent)
```

### Key Differences
When accounting for dependence, the benefit of combined testing is typically **reduced** compared to the independence assumption. This is because:
- Positive results are less surprising (tests tend to agree)
- The tests provide less independent evidence

## Example 3: Cancer Screening Scenario

Breast cancer screening using mammography and ultrasound in a high-risk population.

```{r cancer_screening}
# Breast cancer screening in high-risk women
cancer_screening <- cotest(
  test1_sens = 0.88,    # Mammography sensitivity
  test1_spec = 0.92,    # Mammography specificity
  test2_sens = 0.95,    # Ultrasound sensitivity
  test2_spec = 0.85,    # Ultrasound specificity
  prevalence = 0.08,    # High-risk population (8% prevalence)
  indep = FALSE,        # Tests likely dependent
  cond_dep_pos = 0.25,  # High dependence in cancer patients
  cond_dep_neg = 0.15,  # Moderate dependence in non-cancer patients
  fagan = TRUE,
  fnote = TRUE
)

print(cancer_screening)
```

### Clinical Decision Points
This analysis helps determine:
- **When to biopsy**: High post-test probability after positive tests
- **When to reassure**: Very low probability after negative tests
- **When to use additional testing**: Intermediate probabilities

## Example 4: Cardiac Biomarkers in Emergency Department

Evaluating chest pain patients using troponin and CK-MB.

```{r cardiac_biomarkers}
# Cardiac biomarkers for myocardial infarction
cardiac_biomarkers <- cotest(
  test1_sens = 0.92,    # Troponin sensitivity
  test1_spec = 0.89,    # Troponin specificity
  test2_sens = 0.85,    # CK-MB sensitivity
  test2_spec = 0.94,    # CK-MB specificity
  prevalence = 0.25,    # ED chest pain patients (25% MI rate)
  indep = FALSE,        # Biomarkers likely correlated
  cond_dep_pos = 0.30,  # High correlation in MI patients
  cond_dep_neg = 0.20,  # Moderate correlation in non-MI patients
  fagan = TRUE,
  fnote = TRUE
)

print(cardiac_biomarkers)
```

### Clinical Application
- **Both positive**: Strong evidence for MI, immediate intervention
- **Both negative**: Low MI probability, consider discharge protocols
- **Discordant results**: May need additional testing or clinical correlation

# Practical Guidelines for Co-Testing Analysis

## When to Use Independent vs. Dependent Models

### Use **Independent Model** when:
- Tests measure completely different biological phenomena
- Tests use different specimens or mechanisms
- No evidence of correlation between test results
- Limited information about test interactions

### Use **Dependent Model** when:
- Tests measure similar biological phenomena
- Tests use the same specimen
- Previous studies show correlation
- Both tests affected by same confounding factors

## Estimating Dependence Parameters

When dependence parameters are unknown:

1. **Literature Review**: Look for studies with paired testing data
2. **Expert Opinion**: Consult specialists familiar with the tests
3. **Sensitivity Analysis**: Test range of plausible values (0.05, 0.1, 0.2, 0.3)
4. **Conservative Approach**: Use moderate dependence (0.1-0.2) when uncertain

```{r sensitivity_analysis}
# Sensitivity analysis with different dependence levels
scenarios <- list(
  "Low Dependence" = 0.05,
  "Moderate Dependence" = 0.15,
  "High Dependence" = 0.30
)

sensitivity_results <- lapply(names(scenarios), function(scenario_name) {
  dep_value <- scenarios[[scenario_name]]
  
  result <- cotest(
    test1_sens = 0.85,
    test1_spec = 0.90,
    test2_sens = 0.80,
    test2_spec = 0.95,
    prevalence = 0.10,
    indep = FALSE,
    cond_dep_pos = dep_value,
    cond_dep_neg = dep_value
  )
  
  cat("\n", scenario_name, "(ρ =", dep_value, "):\n")
  print(result)
  
  return(result)
})
```

## Impact of Ignoring Dependence

Ignoring conditional dependence when it exists typically leads to:

- **Overestimating** the benefit of combined testing
- **Exaggerating** post-test probabilities
- **Overly optimistic** assessment of diagnostic accuracy
- **Unrealistic** confidence intervals

# Advanced Applications

## Sequential vs. Simultaneous Testing

While this function models simultaneous testing, it can inform sequential testing strategies:

```{r sequential_strategy}
# First test: High sensitivity screening test
first_test <- cotest(
  test1_sens = 0.95,    # High sensitivity screening
  test1_spec = 0.80,    # Lower specificity acceptable
  test2_sens = 0.95,    # Dummy second test (same values)
  test2_spec = 0.80,
  prevalence = 0.05,
  indep = TRUE
)

# If first test positive, use confirmatory test
confirmatory_test <- cotest(
  test1_sens = 0.95,    # Original screening test
  test1_spec = 0.80,
  test2_sens = 0.85,    # Confirmatory test (different characteristics)
  test2_spec = 0.98,    # Higher specificity
  prevalence = 0.25,    # Higher prevalence after positive screen
  indep = FALSE,
  cond_dep_pos = 0.20,
  cond_dep_neg = 0.10
)

cat("Sequential Testing Strategy:\n")
cat("Step 1 - Screening Test Results:\n")
print(first_test)

cat("\nStep 2 - Confirmatory Testing (if screen positive):\n")
print(confirmatory_test)
```

## Cost-Effectiveness Considerations

Co-testing analysis can inform cost-effectiveness decisions:

```{r cost_effectiveness}
# High-cost, high-accuracy test combination
high_cost_scenario <- cotest(
  test1_sens = 0.98,    # Expensive, highly accurate test 1
  test1_spec = 0.99,
  test2_sens = 0.96,    # Expensive, highly accurate test 2
  test2_spec = 0.99,
  prevalence = 0.02,    # Low prevalence setting
  indep = TRUE,
  fagan = TRUE
)

# Moderate-cost, good-accuracy test combination
moderate_cost_scenario <- cotest(
  test1_sens = 0.85,    # Moderate cost, good accuracy test 1
  test1_spec = 0.90,
  test2_sens = 0.88,    # Moderate cost, good accuracy test 2
  test2_spec = 0.92,
  prevalence = 0.02,    # Same prevalence
  indep = TRUE,
  fagan = TRUE
)

cat("High-Cost Scenario:\n")
print(high_cost_scenario)

cat("\nModerate-Cost Scenario:\n")
print(moderate_cost_scenario)
```

# Clinical Decision Thresholds

Understanding when co-testing changes clinical decisions:

## Treatment Threshold Analysis

```{r threshold_analysis}
# Define clinical scenarios with different action thresholds
scenarios <- data.frame(
  Clinical_Setting = c("Screening", "Symptomatic", "High_Risk"),
  Prevalence = c(0.01, 0.15, 0.40),
  Treatment_Threshold = c(0.05, 0.20, 0.60),
  Test_Threshold = c(0.02, 0.08, 0.30)
)

for (i in 1:nrow(scenarios)) {
  setting <- scenarios[i, ]
  
  cat("\n", setting$Clinical_Setting, "Setting:\n")
  cat("Prevalence:", setting$Prevalence * 100, "%\n")
  cat("Treatment threshold:", setting$Treatment_Threshold * 100, "%\n")
  
  result <- cotest(
    test1_sens = 0.85,
    test1_spec = 0.90,
    test2_sens = 0.80,
    test2_spec = 0.95,
    prevalence = setting$Prevalence,
    indep = TRUE
  )
  
  print(result)
}
```

# Summary and Best Practices

## Key Takeaways

1. **Co-testing can significantly improve diagnostic accuracy** when used appropriately
2. **Test dependence matters** - ignoring it can lead to overoptimistic results
3. **Clinical context is crucial** - consider prevalence, thresholds, and consequences
4. **Sensitivity analysis** helps understand uncertainty in dependence parameters

## Best Practices

### Before Analysis
- Understand the biological basis for potential test dependence
- Gather accurate sensitivity and specificity data
- Estimate realistic prevalence for your population
- Define clinical decision thresholds

### During Analysis
- Start with independence assumption as baseline
- Test dependence scenarios based on biological plausibility
- Use sensitivity analysis for uncertain parameters
- Consider both positive and negative test combinations

### After Analysis
- Interpret results in clinical context
- Consider cost-effectiveness implications
- Validate findings with clinical experience
- Update analysis as new data becomes available

## Limitations

- Assumes binary test results (positive/negative)
- Requires known test characteristics
- Dependence parameters may be difficult to estimate
- Does not account for test timing or sequence effects

## Conclusion

Co-testing analysis provides a quantitative framework for understanding how multiple diagnostic tests interact to influence clinical decision-making. By properly accounting for test dependence and clinical context, this analysis can guide more informed use of diagnostic testing in clinical practice.

The `cotest` function in ClinicoPath makes these complex calculations accessible to clinicians, providing both numerical results and visual tools (Fagan nomograms) to support evidence-based medical decision-making.

---

*This vignette demonstrates the use of the `cotest` function for analyzing combined diagnostic tests. For more information about ClinicoPath, visit our documentation or contact the development team.*
