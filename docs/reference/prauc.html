<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Precision-Recall Analysis — prauc • ClinicoPath</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Precision-Recall Analysis — prauc"><meta name="description" content="Precision-Recall (PR) analysis is superior to ROC analysis for highly
imbalanced datasets, which are common in digital pathology and AI
applications. While ROC curves can be misleading when the negative class
vastly outnumbers the positive class, PR curves focus on the performance in
the minority (positive) class. The area under the PR curve (PR-AUC or
Average Precision) provides a single-number summary of model performance.
PR analysis is essential for evaluating rare event detection (mitotic
figures &amp;lt;1\
positives are rare, quality control in digital pathology where defects are
uncommon, and AI triage systems where abnormal cases are infrequent. This
module provides comprehensive PR analysis with optimal threshold selection,
comparison to baseline (random classifier), and F-score optimization for
different precision-recall trade-offs."><meta property="og:description" content="Precision-Recall (PR) analysis is superior to ROC analysis for highly
imbalanced datasets, which are common in digital pathology and AI
applications. While ROC curves can be misleading when the negative class
vastly outnumbers the positive class, PR curves focus on the performance in
the minority (positive) class. The area under the PR curve (PR-AUC or
Average Precision) provides a single-number summary of model performance.
PR analysis is essential for evaluating rare event detection (mitotic
figures &amp;lt;1\
positives are rare, quality control in digital pathology where defects are
uncommon, and AI triage systems where abnormal cases are infrequent. This
module provides comprehensive PR analysis with optimal threshold selection,
comparison to baseline (random classifier), and F-score optimization for
different precision-recall trade-offs."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ClinicoPath</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.32.72</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../dev/index.html"><span class="fa fa-cogs"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-test-data" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fa-database"></span> Test Data</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-test-data"><li><a class="dropdown-item" href="../articles/test-data-catalog.html">Test Data Catalog</a></li>
    <li><a class="dropdown-item" href="../articles/test-data-complete-catalog.html">Complete Catalog (945 files)</a></li>
    <li><a class="dropdown-item" href="../articles/function-reference.html">Function Reference</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="http://twitter.com/serdarbalci"><span class="fa fab fa-twitter fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/sbalci/ClinicoPathJamoviModule/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Precision-Recall Analysis</h1>
      <small class="dont-index">Source: <a href="https://github.com/sbalci/ClinicoPathJamoviModule/blob/HEAD/R/prauc.h.R" class="external-link"><code>R/prauc.h.R</code></a></small>
      <div class="d-none name"><code>prauc.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Precision-Recall (PR) analysis is superior to ROC analysis for highly
imbalanced datasets, which are common in digital pathology and AI
applications. While ROC curves can be misleading when the negative class
vastly outnumbers the positive class, PR curves focus on the performance in
the minority (positive) class. The area under the PR curve (PR-AUC or
Average Precision) provides a single-number summary of model performance.
PR analysis is essential for evaluating rare event detection (mitotic
figures &lt;1\<!-- %, rare tumor cells, micrometastases), cancer screening where -->
positives are rare, quality control in digital pathology where defects are
uncommon, and AI triage systems where abnormal cases are infrequent. This
module provides comprehensive PR analysis with optimal threshold selection,
comparison to baseline (random classifier), and F-score optimization for
different precision-recall trade-offs.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">prauc</span><span class="op">(</span></span>
<span>  <span class="va">data</span>,</span>
<span>  <span class="va">outcome</span>,</span>
<span>  <span class="va">predictor</span>,</span>
<span>  positive_level <span class="op">=</span> <span class="st">""</span>,</span>
<span>  prevalence <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>,</span>
<span>  calculate_auc <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  calculate_fscore <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  beta_weights <span class="op">=</span> <span class="st">"1, 2, 0.5"</span>,</span>
<span>  confidence_intervals <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  ci_method <span class="op">=</span> <span class="st">"bootstrap"</span>,</span>
<span>  bootstrap_samples <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  confidence_level <span class="op">=</span> <span class="fl">0.95</span>,</span>
<span>  compare_to_roc <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  baseline_comparison <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  interpolation_method <span class="op">=</span> <span class="st">"step"</span>,</span>
<span>  plot_pr_curve <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  plot_comparison <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  plot_fscore <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  min_threshold <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  max_threshold <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  random_seed <span class="op">=</span> <span class="fl">12345</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>The data as a data frame.</p></dd>


<dt id="arg-outcome">outcome<a class="anchor" aria-label="anchor" href="#arg-outcome"></a></dt>
<dd><p>Binary outcome variable (e.g., cancer/non-cancer,
positive/negative). Must have exactly two levels.</p></dd>


<dt id="arg-predictor">predictor<a class="anchor" aria-label="anchor" href="#arg-predictor"></a></dt>
<dd><p>Continuous predictor variable (e.g., AI score, biomarker
level, probability). Higher values should indicate higher likelihood of
positive outcome.</p></dd>


<dt id="arg-positive-level">positive_level<a class="anchor" aria-label="anchor" href="#arg-positive-level"></a></dt>
<dd><p>Level of outcome variable to treat as "positive"
class. If not specified, the second level of the factor is used. Critical
for correct PR analysis.</p></dd>


<dt id="arg-prevalence">prevalence<a class="anchor" aria-label="anchor" href="#arg-prevalence"></a></dt>
<dd><p>Observed prevalence of positive class in dataset.
Automatically calculated if not specified (-1). Used for baseline
comparison and interpretation.</p></dd>


<dt id="arg-calculate-auc">calculate_auc<a class="anchor" aria-label="anchor" href="#arg-calculate-auc"></a></dt>
<dd><p>Calculate area under precision-recall curve (also
called Average Precision). Uses trapezoidal integration. Essential summary
metric for imbalanced data.</p></dd>


<dt id="arg-calculate-fscore">calculate_fscore<a class="anchor" aria-label="anchor" href="#arg-calculate-fscore"></a></dt>
<dd><p>Find optimal threshold that maximizes F1-score
(harmonic mean of precision and recall). Also calculates F2-score
(emphasizes recall) and F0.5-score (emphasizes precision).</p></dd>


<dt id="arg-beta-weights">beta_weights<a class="anchor" aria-label="anchor" href="#arg-beta-weights"></a></dt>
<dd><p>Comma-separated list of beta values for F-score
calculation. F1 (beta=1) balances precision and recall. F2 (beta=2) weights
recall higher. F0.5 (beta=0.5) weights precision higher. Example: "1, 2,
0.5, 3"</p></dd>


<dt id="arg-confidence-intervals">confidence_intervals<a class="anchor" aria-label="anchor" href="#arg-confidence-intervals"></a></dt>
<dd><p>Calculate confidence intervals for PR-AUC using
bootstrap resampling. Provides uncertainty quantification for imbalanced
datasets.</p></dd>


<dt id="arg-ci-method">ci_method<a class="anchor" aria-label="anchor" href="#arg-ci-method"></a></dt>
<dd><p>Method for confidence interval calculation. Bootstrap
percentile is standard. BCa (bias-corrected and accelerated) adjusts for
skewness.</p></dd>


<dt id="arg-bootstrap-samples">bootstrap_samples<a class="anchor" aria-label="anchor" href="#arg-bootstrap-samples"></a></dt>
<dd><p>Number of bootstrap resamples for confidence
interval calculation.</p></dd>


<dt id="arg-confidence-level">confidence_level<a class="anchor" aria-label="anchor" href="#arg-confidence-level"></a></dt>
<dd><p>Confidence level for interval estimation.</p></dd>


<dt id="arg-compare-to-roc">compare_to_roc<a class="anchor" aria-label="anchor" href="#arg-compare-to-roc"></a></dt>
<dd><p>Calculate ROC-AUC for comparison. Demonstrates
advantage of PR analysis for imbalanced data where ROC-AUC may be
misleadingly high.</p></dd>


<dt id="arg-baseline-comparison">baseline_comparison<a class="anchor" aria-label="anchor" href="#arg-baseline-comparison"></a></dt>
<dd><p>Compare PR-AUC to baseline (random classifier).
Baseline PR-AUC equals the prevalence. Shows improvement over chance
performance.</p></dd>


<dt id="arg-interpolation-method">interpolation_method<a class="anchor" aria-label="anchor" href="#arg-interpolation-method"></a></dt>
<dd><p>Method for interpolating PR curve between
points. Step function is standard for PR curves. Linear interpolation can
smooth the curve.</p></dd>


<dt id="arg-plot-pr-curve">plot_pr_curve<a class="anchor" aria-label="anchor" href="#arg-plot-pr-curve"></a></dt>
<dd><p>Plot precision-recall curve with optimal F-score
threshold marked. Shows trade-off between precision and recall across all
thresholds.</p></dd>


<dt id="arg-plot-comparison">plot_comparison<a class="anchor" aria-label="anchor" href="#arg-plot-comparison"></a></dt>
<dd><p>Side-by-side comparison of ROC and PR curves to
demonstrate differences in imbalanced dataset evaluation.</p></dd>


<dt id="arg-plot-fscore">plot_fscore<a class="anchor" aria-label="anchor" href="#arg-plot-fscore"></a></dt>
<dd><p>Plot F-scores (F1, F2, F0.5) across all thresholds to
visualize optimal operating points for different precision-recall
trade-offs.</p></dd>


<dt id="arg-min-threshold">min_threshold<a class="anchor" aria-label="anchor" href="#arg-min-threshold"></a></dt>
<dd><p>Minimum predictor threshold to evaluate. Use to focus
on clinically relevant range.</p></dd>


<dt id="arg-max-threshold">max_threshold<a class="anchor" aria-label="anchor" href="#arg-max-threshold"></a></dt>
<dd><p>Maximum predictor threshold to evaluate.</p></dd>


<dt id="arg-random-seed">random_seed<a class="anchor" aria-label="anchor" href="#arg-random-seed"></a></dt>
<dd><p>Random seed for bootstrap procedures to ensure
reproducibility.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A results object containing:</p><table class="table table"><tr><td><code>results$instructions</code></td><td></td><td></td><td></td><td></td><td>a html</td></tr><tr><td><code>results$prSummary</code></td><td></td><td></td><td></td><td></td><td>Precision-Recall area under curve with baseline comparison</td></tr><tr><td><code>results$optimalThresholds</code></td><td></td><td></td><td></td><td></td><td>Optimal operating points for different F-score metrics</td></tr><tr><td><code>results$prCurveData</code></td><td></td><td></td><td></td><td></td><td>Precision and recall values across all thresholds</td></tr><tr><td><code>results$performanceAtKey</code></td><td></td><td></td><td></td><td></td><td>Precision and recall at clinically relevant thresholds</td></tr><tr><td><code>results$prCurvePlot</code></td><td></td><td></td><td></td><td></td><td>Precision-recall curve with optimal F1 threshold marked</td></tr><tr><td><code>results$comparisonPlot</code></td><td></td><td></td><td></td><td></td><td>Side-by-side comparison of ROC and PR curves</td></tr><tr><td><code>results$fscorePlot</code></td><td></td><td></td><td></td><td></td><td>F-scores across thresholds for different beta values</td></tr><tr><td><code>results$interpretation</code></td><td></td><td></td><td></td><td></td><td>a html</td></tr></table><p>Tables can be converted to data frames with <code>asDF</code> or <code><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></code>. For example:</p>
<p><code>results$prSummary$asDF</code></p>
<p><code>as.data.frame(results$prSummary)</code></p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">prauc</span><span class="op">(</span></span></span>
<span class="r-in"><span>    data <span class="op">=</span> <span class="va">pathology_data</span>,</span></span>
<span class="r-in"><span>    outcome <span class="op">=</span> <span class="st">"cancer"</span>,</span></span>
<span class="r-in"><span>    predictor <span class="op">=</span> <span class="st">"ai_score"</span>,</span></span>
<span class="r-in"><span>    positive_level <span class="op">=</span> <span class="st">"positive"</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-err co"><span class="r-pr">#&gt;</span> <span class="error">Error:</span> object 'pathology_data' not found</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://www.serdarbalci.com/" class="external-link">Serdar Balci</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

