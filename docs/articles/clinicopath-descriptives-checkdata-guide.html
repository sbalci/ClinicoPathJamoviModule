<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Single Variable Quality Check (checkdata) - Comprehensive Guide • ClinicoPath</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Single Variable Quality Check (checkdata) - Comprehensive Guide">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ClinicoPath</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.32.72</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../dev/index.html"><span class="fa fa-cogs"></span></a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-test-data" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fa-database"></span> Test Data</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-test-data">
<li><a class="dropdown-item" href="../articles/test-data-catalog.html">Test Data Catalog</a></li>
    <li><a class="dropdown-item" href="../articles/test-data-complete-catalog.html">Complete Catalog (945 files)</a></li>
    <li><a class="dropdown-item" href="../articles/function-reference.html">Function Reference</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="http://twitter.com/serdarbalci"><span class="fa fab fa-twitter fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/sbalci/ClinicoPathJamoviModule/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Single Variable Quality Check (checkdata) - Comprehensive Guide</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/sbalci/ClinicoPathJamoviModule/blob/HEAD/vignettes/clinicopath-descriptives-checkdata-guide.Rmd" class="external-link"><code>vignettes/clinicopath-descriptives-checkdata-guide.Rmd</code></a></small>
      <div class="d-none name"><code>clinicopath-descriptives-checkdata-guide.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="single-variable-quality-check-checkdata---comprehensive-guide">Single Variable Quality Check (<code>checkdata</code>) -
Comprehensive Guide<a class="anchor" aria-label="anchor" href="#single-variable-quality-check-checkdata---comprehensive-guide"></a>
</h2>
<div class="section level3">
<h3 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h3>
<p>The <strong>Single Variable Quality Check</strong> module provides
comprehensive data quality assessment for individual variables in
clinical and pathological research datasets. This tool performs
automated quality screening to identify potential data issues before
statistical analysis.</p>
<p><strong>Important</strong>: This is a <strong>heuristic screening
tool</strong> designed to augment, not replace, clinical and statistical
expertise. All assessments are rule-of-thumb evaluations using
configurable thresholds, not validated diagnostic metrics.</p>
<hr>
</div>
<div class="section level3">
<h3 id="key-features">Key Features<a class="anchor" aria-label="anchor" href="#key-features"></a>
</h3>
<div class="section level4">
<h4 id="multi-method-outlier-detection">1. <strong>Multi-Method Outlier Detection</strong><a class="anchor" aria-label="anchor" href="#multi-method-outlier-detection"></a>
</h4>
<ul>
<li>Three independent outlier detection methods:
<ul>
<li>
<strong>Z-score</strong> (|z| &gt; 3): Standard approach, assumes
normality</li>
<li>
<strong>IQR method</strong> (1.5×IQR rule): Robust to
non-normality</li>
<li>
<strong>Modified Z-score (MAD)</strong> (|z| &gt; 3.5): Most robust
to outliers and skewness</li>
</ul>
</li>
<li>
<strong>Consensus approach</strong>: Points flagged by ≥2 methods
for n≥10</li>
<li>
<strong>Informative mode</strong>: Single-method flags shown for
small samples (n=3-9) with clear warnings</li>
<li>
<strong>Transformation support</strong>: Log or square-root
transformation for right-skewed data</li>
</ul>
</div>
<div class="section level4">
<h4 id="missing-data-pattern-analysis">2. <strong>Missing Data Pattern Analysis</strong><a class="anchor" aria-label="anchor" href="#missing-data-pattern-analysis"></a>
</h4>
<ul>
<li>
<strong>Statistical runs test</strong> with p-values for
clustering/alternating patterns</li>
<li>
<strong>Dropout detection</strong> with Wilson score confidence
intervals</li>
<li>
<strong>Percentage thresholds</strong> with clinical context
(MCAR/MAR/MNAR guidance)</li>
<li>
<strong>Optional MCAR test</strong> (requires <code>naniar</code>
package)</li>
<li>All methods labeled as <strong>HEURISTIC</strong> with limitations
disclosed</li>
</ul>
</div>
<div class="section level4">
<h4 id="distribution-analysis">3. <strong>Distribution Analysis</strong><a class="anchor" aria-label="anchor" href="#distribution-analysis"></a>
</h4>
<ul>
<li>Central tendency (mean, median) with symmetry assessment</li>
<li>Variability metrics:
<ul>
<li>
<strong>SD</strong>: Standard deviation</li>
<li>
<strong>MAD</strong>: Median absolute deviation (robust)</li>
<li>
<strong>IQR</strong>: Interquartile range (robust)</li>
<li>
<strong>CV</strong>: Coefficient of variation (with stability
guard)</li>
</ul>
</li>
<li>
<strong>CV suppression</strong>: When |mean| &lt; threshold (default
0.01) to avoid instability</li>
<li>Skewness and shape interpretation</li>
</ul>
</div>
<div class="section level4">
<h4 id="clinical-plausibility-checks">4. <strong>Clinical Plausibility Checks</strong><a class="anchor" aria-label="anchor" href="#clinical-plausibility-checks"></a>
</h4>
<ul>
<li>
<strong>Unit-aware validation</strong> for:
<ul>
<li>Age (years, with biological limits)</li>
<li>Weight (kg vs lbs auto-detection)</li>
<li>Height (cm, meters, or feet auto-detection)</li>
<li>Lab values (hemoglobin, creatinine with SI vs traditional
units)</li>
</ul>
</li>
<li>
<strong>Configurable unit system</strong>: Auto-detect, Metric, or
Imperial</li>
<li>All checks labeled <strong>“PLAUSIBILITY CHECK”</strong> with
thresholds disclosed</li>
<li>Can be enabled/disabled globally</li>
</ul>
</div>
<div class="section level4">
<h4 id="categorical-variable-analysis">5. <strong>Categorical Variable Analysis</strong><a class="anchor" aria-label="anchor" href="#categorical-variable-analysis"></a>
</h4>
<ul>
<li>
<strong>Entropy-based balance index</strong> with maximum entropy
context</li>
<li>
<strong>Rare category detection</strong> (configurable threshold,
default 5%)</li>
<li>Tied to statistical assumptions (chi-squared expected cell
counts)</li>
<li>Frequency distribution with duplicate detection</li>
</ul>
</div>
<div class="section level4">
<h4 id="heuristic-quality-score">6. <strong>Heuristic Quality Score</strong><a class="anchor" aria-label="anchor" href="#heuristic-quality-score"></a>
</h4>
<ul>
<li>
<strong>Transparent component scoring</strong>:
<ul>
<li>Missing Data: max 40 pts penalty</li>
<li>Outliers: max 30 pts penalty</li>
<li>Variability: max 25 pts penalty</li>
<li>Clinical Checks: max 20 pts penalty</li>
<li>Sample Size: max 30 pts penalty</li>
</ul>
</li>
<li>
<strong>Letter grade bands</strong> (no false precision):
<ul>
<li>A: Excellent (90-100)</li>
<li>B: Good (80-89)</li>
<li>C: Fair (70-79)</li>
<li>D: Poor (&lt;70)</li>
</ul>
</li>
<li>Clear disclaimer: <strong>“NOT a validated metric”</strong>
</li>
</ul>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="configuration-options">Configuration Options<a class="anchor" aria-label="anchor" href="#configuration-options"></a>
</h3>
<div class="section level4">
<h4 id="display-options">Display Options<a class="anchor" aria-label="anchor" href="#display-options"></a>
</h4>
<ul>
<li>
<strong>Show Outlier Analysis</strong>: Enable/disable multi-method
outlier detection</li>
<li>
<strong>Show Distribution Analysis</strong>: Enable/disable
descriptive statistics</li>
<li>
<strong>Show Duplicate Analysis</strong>: Enable/disable duplicate
value detection</li>
<li>
<strong>Show Data Patterns</strong>: Enable/disable missing data
pattern analysis</li>
</ul>
</div>
<div class="section level4">
<h4 id="advanced-settings">Advanced Settings<a class="anchor" aria-label="anchor" href="#advanced-settings"></a>
</h4>
<div class="section level5">
<h5 id="outlier-detection">Outlier Detection<a class="anchor" aria-label="anchor" href="#outlier-detection"></a>
</h5>
<ul>
<li>
<strong>Transformation</strong> (default: None)
<ul>
<li>None: Use raw data</li>
<li>Log transform: For right-skewed distributions (requires all positive
values)</li>
<li>Square root transform: For moderate right skew (requires
non-negative values)</li>
</ul>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="variability-assessment">Variability Assessment<a class="anchor" aria-label="anchor" href="#variability-assessment"></a>
</h5>
<ul>
<li>
<strong>Minimum Mean for CV</strong> (default: 0.01)
<ul>
<li>Suppress coefficient of variation when |mean| below this
threshold</li>
<li>Prevents reporting unstable CVs for data centered near zero</li>
<li>Recommended: 0.01 for most applications</li>
</ul>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="categorical-analysis">Categorical Analysis<a class="anchor" aria-label="anchor" href="#categorical-analysis"></a>
</h5>
<ul>
<li>
<strong>Rare Category Threshold</strong> (default: 5%, range:
0.1-20%)
<ul>
<li>Percentage below which categories are flagged as rare</li>
<li>Tied to chi-squared expected cell count assumptions</li>
<li>Adjust based on downstream analysis plans</li>
</ul>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="clinical-validation">Clinical Validation<a class="anchor" aria-label="anchor" href="#clinical-validation"></a>
</h5>
<ul>
<li>
<strong>Enable Clinical Plausibility Checks</strong> (default: true)
<ul>
<li>Toggle all context-specific validation (age, weight, height,
labs)</li>
<li>Disable for non-clinical variables to avoid false flags</li>
</ul>
</li>
<li>
<strong>Unit System</strong> (default: Auto-detect)
<ul>
<li>Auto-detect: Infer units from data range (recommended)</li>
<li>Metric: Force SI units (kg, cm, g/L, µmol/L)</li>
<li>Imperial: Force US units (lbs, feet, g/dL, mg/dL)</li>
</ul>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="missing-data-analysis">Missing Data Analysis<a class="anchor" aria-label="anchor" href="#missing-data-analysis"></a>
</h5>
<ul>
<li>
<strong>Perform MCAR Statistical Test</strong> (default: false)
<ul>
<li>Enable Little’s MCAR test (requires <code>naniar</code> package
installation)</li>
<li>Provides formal test vs. heuristic runs test</li>
<li>Note: Single-variable analysis has limited MCAR test utility</li>
</ul>
</li>
</ul>
<hr>
</div>
</div>
</div>
<div class="section level3">
<h3 id="interpreting-results">Interpreting Results<a class="anchor" aria-label="anchor" href="#interpreting-results"></a>
</h3>
<div class="section level4">
<h4 id="outlier-detection-tables">Outlier Detection Tables<a class="anchor" aria-label="anchor" href="#outlier-detection-tables"></a>
</h4>
<div class="section level5">
<h5 id="method-summary-table">Method Summary Table<a class="anchor" aria-label="anchor" href="#method-summary-table"></a>
</h5>
<p>Shows each detection method’s performance: - <strong>Method</strong>:
Detection approach used - <strong>Threshold</strong>: Criterion applied
- <strong>Outliers Found</strong>: Count per method -
<strong>Note</strong>: Method characteristics and limitations</p>
<p><strong>Interpretation</strong>: - Compare counts across methods to
assess agreement - Higher MAD count suggests robust outliers (not just
z-score artifacts) - If only Z-score flags points, consider
transformation</p>
</div>
<div class="section level5">
<h5 id="consensus-outliers-table-n10">Consensus Outliers Table (n≥10)<a class="anchor" aria-label="anchor" href="#consensus-outliers-table-n10"></a>
</h5>
<p>Shows points flagged by ≥2 methods: - <strong>Row</strong>: Original
data row number - <strong>Value</strong>: Observed value -
<strong>Z-Score</strong>: On transformed scale if transformation applied
- <strong>Z-score, IQR, MAD flags</strong>: ✓ = flagged, — = not flagged
- <strong>Severity</strong>: Based on z-score magnitude with scale
notation</p>
<p><strong>Severity Levels</strong>: - Mild: 3 &lt; |z| ≤ 4 - Moderate:
4 &lt; |z| ≤ 5 - Severe: 5 &lt; |z| ≤ 6 - Extreme: |z| &gt; 6</p>
<p><strong>Scale Notation</strong>: - “(2/3 methods)” = consensus from 2
of 3 methods - “(on log scale)” = severity assessed after log
transformation</p>
</div>
<div class="section level5">
<h5 id="informative-only-mode-n3-9">Informative-Only Mode (n=3-9)<a class="anchor" aria-label="anchor" href="#informative-only-mode-n3-9"></a>
</h5>
<p>For small samples, single-method flags shown with warning: -
<strong>“INFORMATIVE ONLY (n&lt;10)”</strong>: Not statistically robust
- Use for data-entry error detection only - Do not treat as validated
outliers - Consider manual review of flagged values</p>
<p><strong>Action</strong>: - Investigate high-severity consensus
outliers - Verify single-method flags in small samples manually -
Consider transformation if only Z-score flags points in skewed data -
Document outlier handling decisions</p>
<hr>
</div>
</div>
<div class="section level4">
<h4 id="missing-data-analysis-1">Missing Data Analysis<a class="anchor" aria-label="anchor" href="#missing-data-analysis-1"></a>
</h4>
<div class="section level5">
<h5 id="missing-data-table">Missing Data Table<a class="anchor" aria-label="anchor" href="#missing-data-table"></a>
</h5>
<ul>
<li>
<strong>Metric</strong>: Aspect measured</li>
<li>
<strong>Value</strong>: Observed statistic</li>
<li>
<strong>Interpretation</strong>: Contextual explanation</li>
</ul>
<p><strong>Key Metrics</strong>: - <strong>Missing %</strong>: Overall
missingness rate - <strong>Pattern</strong>:
Clustering/alternating/random (with p-value if n≥5 each) -
<strong>Dropout</strong>: Proportion in last quarter (with 95% CI) -
<strong>MCAR Note</strong>: Test result if enabled</p>
<p><strong>Interpretation Guidelines</strong>:</p>
<table class="table">
<thead><tr class="header">
<th>Missing %</th>
<th>Interpretation</th>
<th>Action</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>&lt;5%</td>
<td>Minimal</td>
<td>Proceed with complete-case analysis</td>
</tr>
<tr class="even">
<td>5-20%</td>
<td>Moderate</td>
<td>Investigate pattern, consider imputation</td>
</tr>
<tr class="odd">
<td>20-50%</td>
<td>Substantial</td>
<td>Assess MCAR/MAR/MNAR, require imputation</td>
</tr>
<tr class="even">
<td>&gt;50%</td>
<td>Severe</td>
<td>Major validity concern, consider re-collection</td>
</tr>
</tbody>
</table>
<p><strong>Pattern Interpretation</strong>: - <strong>“HEURISTIC: Random
(p=0.45)”</strong>: Consistent with MCAR (good) - <strong>“HEURISTIC:
Clustered (p=0.02)”</strong>: Systematic missingness (investigate) -
<strong>“HEURISTIC: Likely dropout (60%, 95% CI: 45-75%)”</strong>:
End-loaded missingness - <strong>“HEURISTIC: Insufficient
data”</strong>: n&lt;5 in at least one group</p>
<p><strong>Action</strong>: - Random patterns (p&gt;0.05): Safe for
complete-case analysis if &lt;20% missing - Clustered/alternating:
Investigate data collection issues - Dropout: Consider
last-observation-carried-forward or trajectory models - &gt;20% missing:
Plan imputation or sensitivity analysis</p>
<hr>
</div>
</div>
<div class="section level4">
<h4 id="distribution-analysis-1">Distribution Analysis<a class="anchor" aria-label="anchor" href="#distribution-analysis-1"></a>
</h4>
<div class="section level5">
<h5 id="for-numeric-variables">For Numeric Variables<a class="anchor" aria-label="anchor" href="#for-numeric-variables"></a>
</h5>
<p><strong>Central Tendency</strong>: - <strong>Mean close to
Median</strong> → Symmetric distribution - <strong>Mean &gt;
Median</strong> → Right-skewed (consider log transform) - <strong>Mean
&lt; Median</strong> → Left-skewed</p>
<p><strong>Variability</strong>: - <strong>SD</strong>: Absolute spread
(same units as data) - <strong>MAD</strong>: Robust spread (resistant to
outliers, use when outliers present) - <strong>IQR</strong>: Robust
range (25th to 75th percentile) - <strong>CV</strong>: Relative
variability (only shown if |mean| ≥ threshold)</p>
<p><strong>CV Interpretation</strong> (when shown): | CV |
Interpretation | Context | |—-|—————-|———| | &lt;10% | Low relative
variability | Tight measurements | | 10-20% | Moderate relative
variability | Typical for many clinical measures | | 20-50% | High
relative variability | Wide spread relative to mean | | &gt;50% | Very
high relative variability | Consider log scale or MAD |</p>
<p><strong>When CV is Suppressed</strong>: - Message: “CV suppressed:
|mean| &lt; 0.01” - Reason: Mean near zero makes CV unstable/misleading
- Alternative: Use MAD or IQR for spread assessment</p>
<p><strong>Skewness</strong>: | Value | Interpretation | Recommendation
| |——-|—————-|—————-| | -0.5 to 0.5 | Approximately symmetric | Standard
methods OK | | 0.5 to 1 or -1 to -0.5 | Moderate skew | Consider
transformation or robust methods | | &gt;1 or &lt;-1 | Severe skew |
Transform before parametric tests |</p>
<p><strong>Action</strong>: - Severe right skew + outliers → Use log
transformation - High CV with outliers → Report MAD instead - Check
distribution plots before parametric tests</p>
</div>
<div class="section level5">
<h5 id="for-categorical-variables">For Categorical Variables<a class="anchor" aria-label="anchor" href="#for-categorical-variables"></a>
</h5>
<p><strong>Category Balance Index (Entropy)</strong>: - Shows: “2.45 of
3.00 max entropy; well balanced” - <strong>High balance</strong>
(&gt;0.8): Categories roughly equal - <strong>Moderate</strong>
(0.6-0.8): Some imbalance - <strong>Low</strong> (&lt;0.6): Dominated by
few categories</p>
<p><strong>Rare Categories</strong>: - Flagged if frequency &lt;
threshold% (default 5%) - Message: “may violate chi-squared assumptions
(expected cell count ≥5)” - <strong>Action</strong>: Combine rare
categories or use exact tests (Fisher’s)</p>
<hr>
</div>
</div>
<div class="section level4">
<h4 id="heuristic-quality-score-1">Heuristic Quality Score<a class="anchor" aria-label="anchor" href="#heuristic-quality-score-1"></a>
</h4>
<p><strong>Score Breakdown</strong>:</p>
<pre><code>SCORING BREAKDOWN (shows penalty applied / maximum penalty):
• Missing Data:      -15 / 40 pts  (Missing 22.3%)
• Outliers:          -10 / 30 pts  (Outlier rate 3.2%)
• Variability:       - 0 / 25 pts  (Uniqueness 45.2%)
• Clinical Checks:   - 5 / 20 pts  (1 plausibility checks failed)
• Sample Size:       - 0 / 30 pts  (n=150)
                     ────────────────
  HEURISTIC GRADE:   B (Good 80-89)</code></pre>
<p><strong>Interpretation</strong>:</p>
<table class="table">
<colgroup>
<col width="16%">
<col width="27%">
<col width="37%">
<col width="18%">
</colgroup>
<thead><tr class="header">
<th>Grade</th>
<th>Score Band</th>
<th>Interpretation</th>
<th>Action</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>90-100</td>
<td>Excellent (by heuristic rules)</td>
<td>Data appears suitable for analysis</td>
</tr>
<tr class="even">
<td>B</td>
<td>80-89</td>
<td>Good with minor issues</td>
<td>Document limitations, proceed with care</td>
</tr>
<tr class="odd">
<td>C</td>
<td>70-79</td>
<td>Quality concerns detected</td>
<td>Review specific issues, consider cleaning</td>
</tr>
<tr class="even">
<td>D</td>
<td>&lt;70</td>
<td>Significant quality issues</td>
<td>Caution: Analysis may produce unreliable results</td>
</tr>
</tbody>
</table>
<p><strong>Critical Warnings</strong>:</p>
<p>⚠️ <strong>This is NOT a validated metric</strong> - Arbitrary
thresholds and penalty weights - Not suitable for regulatory submissions
as-is - Cannot replace domain expertise - Different contexts may need
different thresholds</p>
<p><strong>Action Based on Grade</strong>:</p>
<p><strong>Grade A</strong>: - Document quality assessment in methods -
Proceed with planned analyses - Consider as baseline for ongoing
monitoring</p>
<p><strong>Grade B</strong>: - Note specific issues in study limitations
- Perform sensitivity analyses - Monitor quality trends if ongoing data
collection</p>
<p><strong>Grade C</strong>: - Review component penalties to identify
main issues - Implement targeted data cleaning - Consult with
statistician/data manager - Document all cleaning decisions</p>
<p><strong>Grade D</strong>: - Investigate root causes (systematic
issues in collection?) - Consider feasibility of salvaging data -
Consult senior investigator before analysis - May need additional data
collection</p>
<hr>
</div>
<div class="section level4">
<h4 id="clinical-plausibility-checks-1">Clinical Plausibility Checks<a class="anchor" aria-label="anchor" href="#clinical-plausibility-checks-1"></a>
</h4>
<p>All messages prefixed <strong>“PLAUSIBILITY CHECK:”</strong> with
detected units and thresholds.</p>
<p><strong>Age</strong>: - Negative values → “biologically impossible” -
&gt;120 years → “verify accuracy (threshold: 120)” - &lt;1 year
(fractional) → “verify units (years vs months)”</p>
<p><strong>Weight</strong>: - Auto-detects kg (2-200) vs lbs (5-450) -
Outside range → “verify units or data entry” - Shows detected unit:
“(assumed kg)”</p>
<p><strong>Height</strong>: - Auto-detects cm (50-250), meters
(0.5-2.5), or feet (1.5-8) - Outside range → “verify units” - Shows
detected unit: “(assumed cm)”</p>
<p><strong>Lab Values</strong> (examples): -
<strong>Hemoglobin</strong>: - &gt;25 → likely g/L (30-200 range) - ≤25
→ likely g/dL (3-20 range) - <strong>Creatinine</strong>: - &gt;20 →
likely µmol/L (30-1000 range) - ≤20 → likely mg/dL (0.3-10 range)</p>
<p><strong>False Positives/Negatives</strong>: - <strong>Pediatric
populations</strong>: May flag normal child weights/heights -
<strong>ICU/extreme cases</strong>: May flag valid extreme values -
<strong>Mixed units in dataset</strong>: Auto-detection may fail -
<strong>Population differences</strong>: Different normal ranges by
ethnicity</p>
<p><strong>Action</strong>: - Review flagged values in clinical context
- Override unit system if auto-detection wrong - Adjust thresholds
mentally for special populations - Disable clinical checks for
non-clinical variables</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="best-practices">Best Practices<a class="anchor" aria-label="anchor" href="#best-practices"></a>
</h3>
<div class="section level4">
<h4 id="before-running-analysis">Before Running Analysis<a class="anchor" aria-label="anchor" href="#before-running-analysis"></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Understand Your Data</strong>:
<ul>
<li>Know expected ranges for clinical variables</li>
<li>Identify which variables need specific units</li>
<li>Anticipate potential outliers (e.g., rare diseases)</li>
</ul>
</li>
<li>
<strong>Configure Appropriately</strong>:
<ul>
<li>Set unit system if auto-detection likely to fail</li>
<li>Adjust rare category threshold based on analysis plan</li>
<li>Consider transformation for known skewed variables</li>
</ul>
</li>
<li>
<strong>Review Variable Types</strong>:
<ul>
<li>Ensure numeric variables are not stored as categorical</li>
<li>Check date variables are properly formatted</li>
<li>Verify factor levels are meaningful</li>
</ul>
</li>
</ol>
</div>
<div class="section level4">
<h4 id="interpreting-results-1">Interpreting Results<a class="anchor" aria-label="anchor" href="#interpreting-results-1"></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Outliers</strong>:
<ul>
<li>✅ <strong>Do</strong>: Investigate consensus outliers (≥2
methods)</li>
<li>✅ <strong>Do</strong>: Consider transformation for right-skewed
data</li>
<li>❌ <strong>Don’t</strong>: Automatically remove all flagged
points</li>
<li>❌ <strong>Don’t</strong>: Trust informative-only flags for n&lt;10
without verification</li>
</ul>
</li>
<li>
<strong>Missingness</strong>:
<ul>
<li>✅ <strong>Do</strong>: Assess patterns statistically (runs test
p-values)</li>
<li>✅ <strong>Do</strong>: Report dropout with confidence
intervals</li>
<li>❌ <strong>Don’t</strong>: Accept heuristic patterns as definitive
MCAR/MAR/MNAR</li>
<li>❌ <strong>Don’t</strong>: Ignore &gt;20% missingness without
imputation plan</li>
</ul>
</li>
<li>
<strong>Quality Score</strong>:
<ul>
<li>✅ <strong>Do</strong>: Review component breakdown for specific
issues</li>
<li>✅ <strong>Do</strong>: Use grade as screening tool, not final
verdict</li>
<li>❌ <strong>Don’t</strong>: Report score in publications without
caveats</li>
<li>❌ <strong>Don’t</strong>: Use grade for regulatory
decision-making</li>
</ul>
</li>
<li>
<strong>Clinical Checks</strong>:
<ul>
<li>✅ <strong>Do</strong>: Verify flagged values in source data</li>
<li>✅ <strong>Do</strong>: Override unit system for known
populations</li>
<li>❌ <strong>Don’t</strong>: Assume all flags are true errors</li>
<li>❌ <strong>Don’t</strong>: Apply checks to non-clinical
variables</li>
</ul>
</li>
</ol>
</div>
<div class="section level4">
<h4 id="after-quality-assessment">After Quality Assessment<a class="anchor" aria-label="anchor" href="#after-quality-assessment"></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Document Findings</strong>:
<ul>
<li>Record quality issues identified</li>
<li>Note any data cleaning performed</li>
<li>Save quality check results with raw data</li>
</ul>
</li>
<li>
<strong>Plan Analysis</strong>:
<ul>
<li>Choose appropriate methods for missingness level</li>
<li>Select robust methods if outliers/skewness present</li>
<li>Consider sensitivity analyses for quality concerns</li>
</ul>
</li>
<li>
<strong>Report Transparently</strong>:
<ul>
<li>Describe quality assessment in methods</li>
<li>Report % missing, outliers detected, skewness</li>
<li>Acknowledge limitations from quality issues</li>
</ul>
</li>
</ol>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="common-scenarios">Common Scenarios<a class="anchor" aria-label="anchor" href="#common-scenarios"></a>
</h3>
<div class="section level4">
<h4 id="scenario-1-right-skewed-lab-values-with-outliers">Scenario 1: Right-Skewed Lab Values with Outliers<a class="anchor" aria-label="anchor" href="#scenario-1-right-skewed-lab-values-with-outliers"></a>
</h4>
<p><strong>Symptoms</strong>: - High skewness (&gt;1) - Only Z-score
flags outliers, IQR/MAD don’t - Large CV (&gt;50%)</p>
<p><strong>Actions</strong>: 1. Re-run with <strong>Outlier Transform:
Log</strong> 2. Check if outliers become consensus on log scale 3.
Report MAD instead of SD for spread 4. Use log-transformed values for
parametric tests</p>
<p><strong>Example</strong>:</p>
<pre><code>Before log transform:
- Skewness: 2.3 (severe right skew)
- Outliers: 5 by Z-score, 0 by IQR/MAD
- CV: 85% (very high)

After log transform:
- Skewness: 0.3 (nearly symmetric)
- Outliers: 2 consensus (2/3 methods on log scale)
- CV: 12% (moderate)</code></pre>
</div>
<div class="section level4">
<h4 id="scenario-2-small-sample-n7-with-potential-errors">Scenario 2: Small Sample (n=7) with Potential Errors<a class="anchor" aria-label="anchor" href="#scenario-2-small-sample-n7-with-potential-errors"></a>
</h4>
<p><strong>Symptoms</strong>: - Table shows “INFORMATIVE ONLY (n&lt;10)”
- Single-method flags present - Need early QC</p>
<p><strong>Actions</strong>: 1. Note informative-only status 2. Manually
review all flagged values in source data 3. Cross-check with clinical
plausibility 4. Document verification process 5. Do NOT report as
statistically validated outliers</p>
<p><strong>Example</strong>:</p>
<pre><code>Informative flags (n=7):
- Row 3: Value 250 (✓ Z-score, ✓ IQR, — MAD)
  → Strong signal, verify in source
- Row 5: Value 85 (✓ Z-score, — IQR, — MAD)
  → Weak signal, likely not outlier</code></pre>
</div>
<div class="section level4">
<h4 id="scenario-3-high-missing-rate-with-dropout-pattern">Scenario 3: High Missing Rate with Dropout Pattern<a class="anchor" aria-label="anchor" href="#scenario-3-high-missing-rate-with-dropout-pattern"></a>
</h4>
<p><strong>Symptoms</strong>: - Missing %: 35% - Pattern: “HEURISTIC:
Likely dropout (75%, 95% CI: 62-88%)” - Quality Grade: C</p>
<p><strong>Actions</strong>: 1. Investigate why missingness concentrates
at end 2. Check if dropout related to outcome (MNAR concern) 3. Plan
appropriate imputation method: - LOCF if values expected stable -
Trajectory modeling if time-dependent 4. Perform sensitivity analysis
with complete-case vs imputed 5. Report missingness mechanism
assessment</p>
</div>
<div class="section level4">
<h4 id="scenario-4-cv-suppressed-due-to-mean-near-zero">Scenario 4: CV Suppressed Due to Mean Near Zero<a class="anchor" aria-label="anchor" href="#scenario-4-cv-suppressed-due-to-mean-near-zero"></a>
</h4>
<p><strong>Symptoms</strong>: - Message: “CV suppressed: |mean| &lt;
0.01” - Mean: 0.003, SD: 0.12 - Data are difference scores or
changes</p>
<p><strong>Actions</strong>: 1. Use <strong>MAD</strong> or
<strong>IQR</strong> for spread assessment 2. Do NOT force CV
calculation (unstable) 3. Report: “Median [IQR] = 0.002 [0.001, 0.008]”
4. Consider if ratio-scale interpretation is appropriate</p>
</div>
<div class="section level4">
<h4 id="scenario-5-clinical-check-false-positives-pediatric-data">Scenario 5: Clinical Check False Positives (Pediatric Data)<a class="anchor" aria-label="anchor" href="#scenario-5-clinical-check-false-positives-pediatric-data"></a>
</h4>
<p><strong>Symptoms</strong>: - Many weight/height plausibility flags -
Data from pediatric population - Units are correct (kg, cm)</p>
<p><strong>Actions</strong>: 1. <strong>Disable clinical
validation</strong> if flags are expected 2. Alternatively: Manually
review flagged values 3. Document population characteristics: “pediatric
cohort ages 2-10” 4. Consider stratified quality checks by age group</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="limitations-and-caveats">Limitations and Caveats<a class="anchor" aria-label="anchor" href="#limitations-and-caveats"></a>
</h3>
<div class="section level4">
<h4 id="outlier-detection-1">Outlier Detection<a class="anchor" aria-label="anchor" href="#outlier-detection-1"></a>
</h4>
<p><strong>Assumptions</strong>: - Z-score assumes approximate normality
(robust to moderate violations) - IQR assumes symmetric-ish distribution
- MAD most robust but can miss subtle outliers</p>
<p><strong>Limitations</strong>: - n&lt;10: Informative only, not robust
- Small consensus (&lt;2 outliers): May be biological variation - Skewed
data without transform: Z-score over-flags high values</p>
<p><strong>Mitigation</strong>: - Use transformation for skewed data -
Require consensus (≥2 methods) for n≥10 - Investigate clinical context
of flagged values</p>
</div>
<div class="section level4">
<h4 id="missingness-patterns">Missingness Patterns<a class="anchor" aria-label="anchor" href="#missingness-patterns"></a>
</h4>
<p><strong>Assumptions</strong>: - Runs test assumes independence under
MCAR - Dropout heuristic assumes ordered data (e.g., time, ID) -
Thresholds (50-150% expected runs) are arbitrary</p>
<p><strong>Limitations</strong>: - Cannot definitively prove MCAR vs MAR
vs MNAR - Runs test p-value is approximate - Pattern may be spurious in
very small samples</p>
<p><strong>Mitigation</strong>: - Label all assessments as HEURISTIC -
Use optional MCAR test for formal assessment - Report confidence
intervals for dropout - Complement with subject-matter knowledge</p>
</div>
<div class="section level4">
<h4 id="quality-score">Quality Score<a class="anchor" aria-label="anchor" href="#quality-score"></a>
</h4>
<p><strong>Assumptions</strong>: - Penalty weights (40, 30, 25, 20, 30)
are arbitrary - Thresholds (e.g., &gt;50% missing = 40 pts) are
rules-of-thumb - Letter grades based on conventional 90/80/70
cutoffs</p>
<p><strong>Limitations</strong>: - NOT validated against external
criteria - Context-dependent (clinical trials vs observational) - Equal
weighting may not suit all applications</p>
<p><strong>Mitigation</strong>: - Show component breakdown for
transparency - Use as screening tool only - Apply clinical judgment to
final decision - Do not report grade without caveats</p>
</div>
<div class="section level4">
<h4 id="clinical-plausibility">Clinical Plausibility<a class="anchor" aria-label="anchor" href="#clinical-plausibility"></a>
</h4>
<p><strong>Assumptions</strong>: - Hard-coded ranges (e.g., age &gt;120,
hemoglobin 3-20 g/dL) - Unit detection from data range (heuristic) -
Western adult population norms</p>
<p><strong>Limitations</strong>: - May fail for pediatric, ICU, or
diverse populations - Cannot detect all unit errors (e.g., mmHg vs kPa
for BP) - No custom range specification (yet)</p>
<p><strong>Mitigation</strong>: - Override unit system when
auto-detection fails - Manually review flagged values in clinical
context - Disable checks for non-clinical variables - Document
population characteristics</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="technical-details">Technical Details<a class="anchor" aria-label="anchor" href="#technical-details"></a>
</h3>
<div class="section level4">
<h4 id="statistical-methods">Statistical Methods<a class="anchor" aria-label="anchor" href="#statistical-methods"></a>
</h4>
<div class="section level5">
<h5 id="runs-test-for-missingness">Runs Test for Missingness<a class="anchor" aria-label="anchor" href="#runs-test-for-missingness"></a>
</h5>
<ul>
<li><strong>Wald-Wolfowitz runs test</strong></li>
<li>Null hypothesis: Missing pattern is random</li>
<li>Test statistic: z = (R - E[R]) / SE[R]
<ul>
<li>R = observed runs</li>
<li>E[R] = 2×n₁×n₂ / (n₁+n₂) + 1</li>
<li>SE[R] = √[(2n₁n₂(2n₁n₂ - n)) / (n²(n-1))]</li>
</ul>
</li>
<li>Two-tailed p-value from standard normal</li>
<li>
<strong>Limitation</strong>: Approximate, assumes large-sample</li>
</ul>
</div>
<div class="section level5">
<h5 id="wilson-score-confidence-interval-dropout">Wilson Score Confidence Interval (Dropout)<a class="anchor" aria-label="anchor" href="#wilson-score-confidence-interval-dropout"></a>
</h5>
<ul>
<li>For proportion p̂ with n observations:</li>
<li>Center = (p̂ + z²/2n) / (1 + z²/n)</li>
<li>Width = z × √[p̂(1-p̂)/n + z²/(4n²)] / (1 + z²/n)</li>
<li>z = 1.96 for 95% CI</li>
<li>More accurate than normal approximation for small n</li>
</ul>
</div>
<div class="section level5">
<h5 id="modified-z-score-mad-based">Modified Z-Score (MAD-based)<a class="anchor" aria-label="anchor" href="#modified-z-score-mad-based"></a>
</h5>
<ul>
<li>M_i = 0.6745 × (x_i - median) / MAD</li>
<li>MAD = median(|x_i - median|) × 1.4826</li>
<li>1.4826 = consistency factor for normal distribution</li>
<li>Threshold: |M_i| &gt; 3.5</li>
<li>Most robust to outliers in outlier detection itself</li>
</ul>
</div>
<div class="section level5">
<h5 id="entropy-balance-index">Entropy Balance Index<a class="anchor" aria-label="anchor" href="#entropy-balance-index"></a>
</h5>
<ul>
<li>H = -∑ p_i × log₂(p_i)</li>
<li>H_max = log₂(k) for k categories</li>
<li>Balance = H / H_max ∈ [0, 1]</li>
<li>1 = perfect balance, 0 = one category dominates</li>
</ul>
</div>
</div>
<div class="section level4">
<h4 id="sample-size-considerations">Sample Size Considerations<a class="anchor" aria-label="anchor" href="#sample-size-considerations"></a>
</h4>
<table class="table">
<colgroup>
<col width="23%">
<col width="26%">
<col width="35%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th>Analysis</th>
<th>Minimum n</th>
<th>Recommended n</th>
<th>Note</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Outlier detection (consensus)</td>
<td>10</td>
<td>30+</td>
<td>&lt;10 = informative only</td>
</tr>
<tr class="even">
<td>Runs test (missingness)</td>
<td>5 missing + 5 complete</td>
<td>20+</td>
<td>Approximate p-value</td>
</tr>
<tr class="odd">
<td>Dropout CI</td>
<td>10 missing</td>
<td>20+</td>
<td>Wilson interval valid for small n</td>
</tr>
<tr class="even">
<td>Skewness/kurtosis</td>
<td>3</td>
<td>20+</td>
<td>Unstable for very small n</td>
</tr>
<tr class="odd">
<td>CV calculation</td>
<td>2</td>
<td>10+</td>
<td>Requires mean stability</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="transformation-details">Transformation Details<a class="anchor" aria-label="anchor" href="#transformation-details"></a>
</h4>
<p><strong>Log Transform</strong>: - Applied: log(x) for all x &gt; 0 -
Fails: If any x ≤ 0 (message: “negative values present”) - Use for:
Right-skewed, multiplicative processes (e.g., biomarkers)</p>
<p><strong>Square Root Transform</strong>: - Applied: √x for all x ≥ 0 -
Fails: If any x &lt; 0 (message: “negative values present”) - Use for:
Moderate right skew, count data, Poisson-distributed</p>
<p><strong>Scale Notation</strong>: - Severity assessed on transformed
scale - Original values displayed in table - Message: “(2/3 methods on
log scale)” indicates transformation</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="frequently-asked-questions">Frequently Asked Questions<a class="anchor" aria-label="anchor" href="#frequently-asked-questions"></a>
</h3>
<div class="section level4">
<h4 id="q1-should-i-remove-all-flagged-outliers">Q1: Should I remove all flagged outliers?<a class="anchor" aria-label="anchor" href="#q1-should-i-remove-all-flagged-outliers"></a>
</h4>
<p><strong>A</strong>: No. Outlier detection identifies
<em>potential</em> data quality issues or extreme but valid values.</p>
<p><strong>Action</strong>: 1. Investigate consensus outliers (≥2
methods) 2. Verify in source documents 3. Assess clinical plausibility
4. Consider: - Data entry error → Correct - Valid extreme value → Keep -
Impossible value → Remove or query 5. Document all decisions</p>
</div>
<div class="section level4">
<h4 id="q2-my-quality-grade-is-c--can-i-still-analyze-the-data">Q2: My quality grade is C. Can I still analyze the data?<a class="anchor" aria-label="anchor" href="#q2-my-quality-grade-is-c--can-i-still-analyze-the-data"></a>
</h4>
<p><strong>A</strong>: Yes, with caveats. Grade C = “quality concerns
detected” (by heuristic rules).</p>
<p><strong>Action</strong>: 1. Review component breakdown to identify
specific issues 2. Address critical issues (e.g., &gt;50% missing →
impute) 3. Plan sensitivity analyses 4. Report quality concerns in study
limitations 5. Consult statistician for appropriate methods</p>
<p>Grade D (&lt;70) requires more serious consideration of data
validity.</p>
</div>
<div class="section level4">
<h4 id="q3-why-is-cv-suppressed-when-my-mean-is-0-005">Q3: Why is CV suppressed when my mean is 0.005?<a class="anchor" aria-label="anchor" href="#q3-why-is-cv-suppressed-when-my-mean-is-0-005"></a>
</h4>
<p><strong>A</strong>: Coefficient of variation is unstable when mean is
near zero (creates very large or undefined ratios).</p>
<p><strong>Explanation</strong>: - CV = SD / |mean| × 100% - When mean ≈
0, small changes cause huge CV swings - Example: mean=0.001, SD=0.01 →
CV=1000%</p>
<p><strong>Action</strong>: - Use MAD or IQR for spread assessment -
Report median [IQR] instead of mean ± SD - Consider if ratio-scale
interpretation makes sense for your data</p>
</div>
<div class="section level4">
<h4 id="q4-informative-only-mode-shows-4-outliers-in-my-n8-sample--what-does-this-mean">Q4: Informative-only mode shows 4 outliers in my n=8 sample. What
does this mean?<a class="anchor" aria-label="anchor" href="#q4-informative-only-mode-shows-4-outliers-in-my-n8-sample--what-does-this-mean"></a>
</h4>
<p><strong>A</strong>: Single-method flags are shown for QC, but
<strong>not statistically robust</strong>.</p>
<p><strong>Explanation</strong>: - n&lt;10: Outlier methods become
unreliable - Consensus (≥2 methods) not required to detect obvious
errors - Goal: Early detection of data-entry mistakes</p>
<p><strong>Action</strong>: 1. Manually review all 4 flagged values in
source data 2. Check for typos (e.g., 250 instead of 25.0) 3. Verify
clinical plausibility 4. Do NOT report as “statistically validated
outliers” 5. If collect more data, re-check with full sample</p>
</div>
<div class="section level4">
<h4 id="q5-clinical-checks-flag-many-values-but-theyre-correct--what-should-i-do">Q5: Clinical checks flag many values, but they’re correct. What
should I do?<a class="anchor" aria-label="anchor" href="#q5-clinical-checks-flag-many-values-but-theyre-correct--what-should-i-do"></a>
</h4>
<p><strong>A</strong>: Clinical plausibility checks may not suit your
specific population.</p>
<p><strong>Common scenarios</strong>: - Pediatric data (weight/height
outside adult ranges) - ICU patients (extreme but valid lab values) -
Different ethnic populations (different normal ranges) - Specialized
cohorts (e.g., elite athletes)</p>
<p><strong>Action</strong>: 1. <strong>Option 1</strong>: Disable
clinical validation entirely 2. <strong>Option 2</strong>: Manually
review and document flagged values as expected for your population 3.
<strong>Option 3</strong>: Override unit system if auto-detection wrong
4. <strong>Future</strong>: Request custom plausibility ranges
feature</p>
</div>
<div class="section level4">
<h4 id="q6-can-i-use-this-quality-score-in-my-manuscript">Q6: Can I use this quality score in my manuscript?<a class="anchor" aria-label="anchor" href="#q6-can-i-use-this-quality-score-in-my-manuscript"></a>
</h4>
<p><strong>A</strong>: With substantial caveats only. Not suitable as
primary quality metric.</p>
<p><strong>Acceptable</strong>: - “Data quality screening performed
using heuristic scoring (grades A-D based on automated rules for
missingness, outliers, sample size). All variables achieved grade B or
higher.” - Report specific components: “Missing data ranged from 0-15%
across variables”</p>
<p><strong>Not Acceptable</strong>: - “Data quality validated with grade
A score” - Using score for regulatory submission without additional
validation - Claiming score is externally validated</p>
<p><strong>Better Approach</strong>: - Report component metrics directly
(% missing, # outliers, skewness) - Use established quality frameworks
(STROBE, RECORD, etc.) - Quality score is for internal screening, not
publication</p>
</div>
<div class="section level4">
<h4 id="q7-whats-the-difference-between-mad-and-sd-for-spread">Q7: What’s the difference between MAD and SD for spread?<a class="anchor" aria-label="anchor" href="#q7-whats-the-difference-between-mad-and-sd-for-spread"></a>
</h4>
<p><strong>A</strong>: Both measure spread, but MAD is robust to
outliers.</p>
<table class="table">
<colgroup>
<col width="14%">
<col width="23%">
<col width="43%">
<col width="18%">
</colgroup>
<thead><tr class="header">
<th>Metric</th>
<th>Calculation</th>
<th>Sensitive to Outliers?</th>
<th>Use When</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>SD</td>
<td>√[∑(x-mean)²/n]</td>
<td>Yes (heavily)</td>
<td>Normal data, no outliers</td>
</tr>
<tr class="even">
<td>MAD</td>
<td>median(|x-median|) × 1.4826</td>
<td>No (resistant)</td>
<td>Skewed data, outliers present</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong>:</p>
<pre><code>Data: 10, 12, 11, 13, 10, 95 (outlier)
SD = 33.6 (inflated by outlier)
MAD = 1.5 (unaffected by outlier)</code></pre>
<p><strong>Action</strong>: - If outliers present: Report MAD - If
normal distribution: Report SD - Can report both for transparency</p>
</div>
<div class="section level4">
<h4 id="q8-the-runs-test-says-random-but-i-know-data-collection-had-issues--why">Q8: The runs test says “random” but I know data collection had
issues. Why?<a class="anchor" aria-label="anchor" href="#q8-the-runs-test-says-random-but-i-know-data-collection-had-issues--why"></a>
</h4>
<p><strong>A</strong>: Statistical tests have limited power, especially
with small samples or subtle patterns.</p>
<p><strong>Explanation</strong>: - Runs test detects obvious
clustering/alternating - May miss: Block missingness (e.g., weekends),
periodic patterns, subtle biases - n&lt;20: Low power to detect
patterns</p>
<p><strong>Action</strong>: - Complement statistical test with: - Visual
inspection of missingness over time/ID - Review of data collection logs
- Subject-matter knowledge - Label assessment as HEURISTIC - Report
known issues regardless of test result</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="reporting-quality-assessment-results">Reporting Quality Assessment Results<a class="anchor" aria-label="anchor" href="#reporting-quality-assessment-results"></a>
</h3>
<div class="section level4">
<h4 id="in-methods-section">In Methods Section<a class="anchor" aria-label="anchor" href="#in-methods-section"></a>
</h4>
<p><strong>Minimal</strong>: &gt; “Data quality was assessed for all
variables using automated screening. Variables with &gt;20% missing data
were imputed using [method]. Outliers were identified using consensus
detection (≥2 of 3 methods: Z-score, IQR, MAD) and verified in source
documents before removal.”</p>
<p><strong>Comprehensive</strong>: &gt; “We performed comprehensive
single-variable quality assessment using a multi-method approach.
Missing data patterns were evaluated using Wald-Wolfowitz runs tests
(α=0.05) and quantified with descriptive statistics. Outliers were
detected using three independent methods (Z-score |z|&gt;3, IQR 1.5×IQR
rule, Modified Z-score |M|&gt;3.5); consensus outliers (flagged by ≥2
methods) were investigated for data entry errors and clinical
plausibility. Variables with severe right skew (skewness &gt;1) were
log-transformed before outlier detection. Heuristic quality scoring (A-D
grades) was used for internal screening but not as a validated quality
metric. [Specific details of quality issues and resolutions].”</p>
</div>
<div class="section level4">
<h4 id="in-results-section">In Results Section<a class="anchor" aria-label="anchor" href="#in-results-section"></a>
</h4>
<p><strong>Minimal</strong>: &gt; “All variables had &lt;15% missing
data. Three outliers were identified and verified as data entry errors
(corrected), and 2 extreme but valid values were retained.”</p>
<p><strong>Comprehensive</strong>: &gt; “Data quality assessment
identified the following: Missing data ranged from 0-22% across
variables (median 3.2%); runs test indicated random missingness patterns
for all variables (all p&gt;0.05). Outlier detection (consensus
approach) identified 14 potential outliers across 8 variables; manual
review confirmed 6 as data entry errors (corrected), 5 as clinically
implausible values (queried with site), and 3 as extreme but valid
values (retained). Five variables exhibited severe right skew (skewness
&gt;1.5) and were log-transformed for outlier detection and subsequent
parametric tests. Heuristic quality scores ranged from B to A across
variables.”</p>
</div>
<div class="section level4">
<h4 id="in-limitations">In Limitations<a class="anchor" aria-label="anchor" href="#in-limitations"></a>
</h4>
<p><strong>Example</strong>: &gt; “Data quality assessment used
heuristic screening tools with arbitrary thresholds (e.g., |z|&gt;3 for
outliers); these are not validated quality metrics. Manual review of
flagged values was performed to mitigate false positives. Missing data
were assumed missing completely at random based on statistical tests,
but residual bias cannot be excluded.”</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="advanced-topics">Advanced Topics<a class="anchor" aria-label="anchor" href="#advanced-topics"></a>
</h3>
<div class="section level4">
<h4 id="when-to-use-each-outlier-transformation">When to Use Each Outlier Transformation<a class="anchor" aria-label="anchor" href="#when-to-use-each-outlier-transformation"></a>
</h4>
<table class="table">
<colgroup>
<col width="38%">
<col width="40%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Data Characteristic</th>
<th>Recommended Transform</th>
<th>Rationale</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Right-skewed biomarker (e.g., CRP, PSA)</td>
<td>Log</td>
<td>Multiplicative process, often log-normal</td>
</tr>
<tr class="even">
<td>Count data with overdispersion</td>
<td>Square root</td>
<td>Variance-stabilizing for Poisson-ish data</td>
</tr>
<tr class="odd">
<td>Bounded continuous (e.g., %)</td>
<td>None or logit</td>
<td>Log/sqrt inappropriate for bounded scales</td>
</tr>
<tr class="even">
<td>Symmetric with heavy tails</td>
<td>None</td>
<td>Use MAD-based detection instead</td>
</tr>
<tr class="odd">
<td>Bimodal distribution</td>
<td>None</td>
<td>Outlier detection may misidentify modes</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="interpreting-mcar-test-results-if-enabled">Interpreting MCAR Test Results (if enabled)<a class="anchor" aria-label="anchor" href="#interpreting-mcar-test-results-if-enabled"></a>
</h4>
<p><strong>Little’s MCAR Test</strong> (requires <code>naniar</code>
package): - Null hypothesis: Data are missing completely at random - p
&lt; 0.05: Reject MCAR, suggests MAR or MNAR - p ≥ 0.05: Fail to reject
MCAR (but doesn’t prove it)</p>
<p><strong>Limitation</strong>: Requires multivariate data;
single-variable context limits utility</p>
<p><strong>Action</strong>: - p &gt; 0.05: Complete-case analysis likely
unbiased - p &lt; 0.05: Plan imputation or sensitivity analysis -
Combine with runs test for convergent evidence</p>
</div>
<div class="section level4">
<h4 id="quality-score-customization-future">Quality Score Customization (future)<a class="anchor" aria-label="anchor" href="#quality-score-customization-future"></a>
</h4>
<p>Current penalty weights are fixed: - Missing: 40 pts max - Outliers:
30 pts max - Variability: 25 pts max - Clinical: 20 pts max - Sample
size: 30 pts max</p>
<p><strong>For custom weighting</strong>, users can: 1. Review component
breakdown in output 2. Manually compute weighted score with their
priorities 3. Example: If missingness is critical, weight it 50 pts
instead</p>
<p><strong>Feature request</strong>: Configurable penalty weights in
future version</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="troubleshooting">Troubleshooting<a class="anchor" aria-label="anchor" href="#troubleshooting"></a>
</h3>
<div class="section level4">
<h4 id="issue-all-outliers-flagged-by-z-score-only-none-by-iqrmad">Issue: All outliers flagged by Z-score only, none by IQR/MAD<a class="anchor" aria-label="anchor" href="#issue-all-outliers-flagged-by-z-score-only-none-by-iqrmad"></a>
</h4>
<p><strong>Likely cause</strong>: Data are right-skewed; Z-score
over-flags upper tail</p>
<p><strong>Solution</strong>: 1. Check skewness (&gt;1 confirms) 2.
Re-run with <strong>Outlier Transform: Log</strong> 3. Verify consensus
on log scale 4. Report: “Outlier detection performed on log-transformed
scale”</p>
</div>
<div class="section level4">
<h4 id="issue-cv-suppression-message-even-though-i-want-to-see-it">Issue: CV suppression message even though I want to see it<a class="anchor" aria-label="anchor" href="#issue-cv-suppression-message-even-though-i-want-to-see-it"></a>
</h4>
<p><strong>Likely cause</strong>: Mean is near zero (by design to avoid
unstable ratios)</p>
<p><strong>Solution</strong>: 1. Lower <code>cvMinMean</code> threshold
(e.g., from 0.01 to 0.001) 2. Check if CV is meaningful for your data: -
✅ Meaningful: Ratio-scale data (weight, concentration, time) - ❌
Misleading: Interval scale (temperature in °C), difference scores 3. Use
MAD-based relative spread: MAD / median</p>
</div>
<div class="section level4">
<h4 id="issue-clinical-checks-flag-many-correct-values">Issue: Clinical checks flag many correct values<a class="anchor" aria-label="anchor" href="#issue-clinical-checks-flag-many-correct-values"></a>
</h4>
<p><strong>Likely cause</strong>: Population or unit mismatch</p>
<p><strong>Solution</strong>: 1. Check <strong>Unit System</strong>
setting: - Auto-detect may fail for mixed units - Override to Metric or
Imperial if known 2. Disable checks for specialized populations
(pediatric, ICU, etc.) 3. Manually review flagged values and document as
expected for your cohort</p>
</div>
<div class="section level4">
<h4 id="issue-quality-grade-seems-too-harshlenient">Issue: Quality grade seems too harsh/lenient<a class="anchor" aria-label="anchor" href="#issue-quality-grade-seems-too-harshlenient"></a>
</h4>
<p><strong>Likely cause</strong>: Heuristic thresholds don’t suit your
context</p>
<p><strong>Solution</strong>: 1. Review <strong>component
breakdown</strong> to identify specific penalties 2. Interpret grade in
context: - Clinical trial: Grade B may be excellent - Real-world
observational: Grade C may be expected 3. Use component metrics directly
instead of letter grade 4. Remember: Grade is screening tool, not
validated metric</p>
</div>
<div class="section level4">
<h4 id="issue-informative-only-warning-for-n9-sample">Issue: “INFORMATIVE ONLY” warning for n=9 sample<a class="anchor" aria-label="anchor" href="#issue-informative-only-warning-for-n9-sample"></a>
</h4>
<p><strong>Not an issue</strong>: This is by design for n&lt;10</p>
<p><strong>Explanation</strong>: - Small samples make outlier detection
unreliable - Single-method flags shown for QC purposes - Clear warning
prevents over-interpretation</p>
<p><strong>Action</strong>: - Use informative flags to detect obvious
errors - Manually verify all flagged values - Do not report as
statistically validated outliers - Collect more data if possible for
robust detection</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="example-workflow">Example Workflow<a class="anchor" aria-label="anchor" href="#example-workflow"></a>
</h3>
<div class="section level4">
<h4 id="step-1-initial-screening">Step 1: Initial Screening<a class="anchor" aria-label="anchor" href="#step-1-initial-screening"></a>
</h4>
<p><strong>Run checkdata with defaults</strong>: - Enable all display
options - Use auto-detect for unit system - Default transformation
(None)</p>
<p><strong>Review</strong>: - Quality grade for overall impression -
Missing % for each variable - Outlier counts</p>
</div>
<div class="section level4">
<h4 id="step-2-detailed-investigation">Step 2: Detailed Investigation<a class="anchor" aria-label="anchor" href="#step-2-detailed-investigation"></a>
</h4>
<p><strong>For variables with issues</strong>:</p>
<p><strong>High missing (&gt;20%)</strong>: - Check missingness pattern
(runs test p-value) - Assess dropout (last quarter %) - Plan imputation
or sensitivity analysis</p>
<p><strong>Many outliers</strong>: - Check skewness - If skewed, re-run
with transformation - Verify consensus outliers manually</p>
<p><strong>Clinical check flags</strong>: - Review in clinical context -
Override unit system if needed - Document expected outliers for
population</p>
</div>
<div class="section level4">
<h4 id="step-3-data-cleaning">Step 3: Data Cleaning<a class="anchor" aria-label="anchor" href="#step-3-data-cleaning"></a>
</h4>
<p><strong>For each identified issue</strong>:</p>
<p><strong>Data entry errors</strong> (verified outliers): - Correct in
source data - Document correction log - Re-run quality check</p>
<p><strong>Missing data</strong>: - Attempt to retrieve from source if
possible - Plan imputation if &gt;20% missing - Consider excluding
variable if &gt;50% missing</p>
<p><strong>Valid extreme values</strong>: - Retain in dataset - Flag for
sensitivity analysis - Document clinical rationale</p>
</div>
<div class="section level4">
<h4 id="step-4-final-quality-report">Step 4: Final Quality Report<a class="anchor" aria-label="anchor" href="#step-4-final-quality-report"></a>
</h4>
<p><strong>Prepare summary</strong>:</p>
<pre><code>Variable Quality Summary:
- Total variables checked: 25
- Variables with Grade A: 18 (72%)
- Variables with Grade B: 6 (24%)
- Variables with Grade C: 1 (4%)
- Variables excluded (&gt;50% missing): 0

Specific actions taken:
- Corrected 6 data entry errors (outliers verified in source)
- Queried 5 implausible values with data collection site
- Retained 3 extreme but valid values
- Planned multiple imputation for 2 variables (22-28% missing)
- Log-transformed 5 right-skewed variables for analysis</code></pre>
</div>
<div class="section level4">
<h4 id="step-5-documentation">Step 5: Documentation<a class="anchor" aria-label="anchor" href="#step-5-documentation"></a>
</h4>
<p><strong>For methods section</strong>: - Summarize quality assessment
approach - Report key quality metrics (% missing, # outliers) - Describe
cleaning procedures performed</p>
<p><strong>For analysis plan</strong>: - Note variables requiring
transformation - Specify imputation methods - Plan sensitivity analyses
for quality concerns</p>
<p><strong>For study files</strong>: - Save quality check output -
Maintain correction log - Archive cleaning decisions with rationale</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="references-and-further-reading">References and Further Reading<a class="anchor" aria-label="anchor" href="#references-and-further-reading"></a>
</h3>
<div class="section level4">
<h4 id="statistical-methods-1">Statistical Methods<a class="anchor" aria-label="anchor" href="#statistical-methods-1"></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<strong>Outlier Detection</strong>:
<ul>
<li>Iglewicz, B., &amp; Hoaglin, D. C. (1993). <em>How to detect and
handle outliers</em>. ASQC Quality Press.</li>
<li>Leys, C., et al. (2013). Detecting outliers: Do not use standard
deviation around the mean, use absolute deviation around the median.
<em>Journal of Experimental Social Psychology</em>, 49(4), 764-766.</li>
</ul>
</li>
<li>
<strong>Missing Data</strong>:
<ul>
<li>Little, R. J. A. (1988). A test of missing completely at random for
multivariate data with missing values. <em>Journal of the American
Statistical Association</em>, 83(404), 1198-1202.</li>
<li>Rubin, D. B. (1976). Inference and missing data.
<em>Biometrika</em>, 63(3), 581-592.</li>
</ul>
</li>
<li>
<strong>Quality Assessment</strong>:
<ul>
<li>Van den Broeck, J., et al. (2005). Data cleaning: detecting,
diagnosing, and editing data abnormalities. <em>PLoS Medicine</em>,
2(10), e267.</li>
<li>Kang, H. (2013). The prevention and handling of the missing data.
<em>Korean Journal of Anesthesiology</em>, 64(5), 402-406.</li>
</ul>
</li>
</ol>
</div>
<div class="section level4">
<h4 id="reporting-guidelines">Reporting Guidelines<a class="anchor" aria-label="anchor" href="#reporting-guidelines"></a>
</h4>
<ul>
<li>STROBE Statement (observational studies): <a href="https://www.strobe-statement.org/" class="external-link uri">https://www.strobe-statement.org/</a>
</li>
<li>RECORD Guidelines (routinely collected data): <a href="https://www.record-statement.org/" class="external-link uri">https://www.record-statement.org/</a>
</li>
<li>CONSORT (clinical trials): <a href="http://www.consort-statement.org/" class="external-link uri">http://www.consort-statement.org/</a>
</li>
</ul>
</div>
<div class="section level4">
<h4 id="r-packages-used">R Packages Used<a class="anchor" aria-label="anchor" href="#r-packages-used"></a>
</h4>
<ul>
<li>Base R: <code><a href="https://rdrr.io/r/stats/mad.html" class="external-link">stats::mad()</a></code>, <code><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">stats::quantile()</a></code>,
<code>stats::scale()</code>
</li>
<li>Optional: <code>naniar::mcar_test()</code> (if MCAR test
enabled)</li>
</ul>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="version-history">Version History<a class="anchor" aria-label="anchor" href="#version-history"></a>
</h3>
<p><strong>Current Version: 0.0.31</strong></p>
<div class="section level4">
<h4 id="recent-improvements-v0-0-31">Recent Improvements (v0.0.31)<a class="anchor" aria-label="anchor" href="#recent-improvements-v0-0-31"></a>
</h4>
<p><strong>Outlier Detection</strong>: - ✅ Added per-method flags
(Z-score, IQR, MAD) in results table - ✅ Implemented transformation
support (log, sqrt) for skewed data - ✅ Added method summary table with
thresholds and counts - ✅ Fixed severity assessment to use transformed
scale when applicable - ✅ Added informative-only mode for small samples
(n=3-9) - ✅ Scale notation in severity text (e.g., “on log scale”)</p>
<p><strong>Missingness Analysis</strong>: - ✅ Implemented
Wald-Wolfowitz runs test with p-values - ✅ Added Wilson score
confidence intervals for dropout detection - ✅ Labeled all methods as
“HEURISTIC” with limitations - ✅ Optional MCAR test support (requires
naniar package)</p>
<p><strong>Variability Metrics</strong>: - ✅ Added CV stability guard
(suppress when |mean| &lt; threshold) - ✅ Included MAD as robust spread
alternative - ✅ Enhanced IQR reporting with quartile values - ✅
Consistent CV handling across table and narrative</p>
<p><strong>Clinical Validation</strong>: - ✅ Implemented unit
auto-detection (weight, height, lab values) - ✅ Added configurable unit
system override (Auto/Metric/Imperial) - ✅ Labeled all checks as
“PLAUSIBILITY CHECK” with thresholds - ✅ Can be enabled/disabled
globally</p>
<p><strong>Categorical Analysis</strong>: - ✅ Enhanced entropy display
with maximum entropy context - ✅ Configurable rare category threshold
(default 5%, range 0.1-20%) - ✅ Tied interpretation to chi-squared
assumptions</p>
<p><strong>Quality Scoring</strong>: - ✅ Renamed to “HEURISTIC QUALITY
SCORE” with clear disclaimer - ✅ Added transparent component breakdown
showing penalties - ✅ Softened presentation to bands (Excellent 90-100)
vs precise points - ✅ Enhanced warning: “NOT a validated metric”</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="contact-and-support">Contact and Support<a class="anchor" aria-label="anchor" href="#contact-and-support"></a>
</h3>
<p><strong>Issues/Bug Reports</strong>: - GitHub repository: [Add
repository link] - Report bugs with example data and screenshots</p>
<p><strong>Feature Requests</strong>: - Custom plausibility bounds for
clinical checks - Configurable quality score weights - Additional
outlier detection methods - Multivariate quality assessment</p>
<p><strong>Documentation</strong>: - This guide: Comprehensive usage and
interpretation - In-app help: Brief summaries of options - Vignettes:
Example analyses with real data</p>
<hr>
</div>
<div class="section level3">
<h3 id="appendix-quick-reference">Appendix: Quick Reference<a class="anchor" aria-label="anchor" href="#appendix-quick-reference"></a>
</h3>
<div class="section level4">
<h4 id="interpretation-thresholds">Interpretation Thresholds<a class="anchor" aria-label="anchor" href="#interpretation-thresholds"></a>
</h4>
<table class="table">
<thead><tr class="header">
<th>Metric</th>
<th>Threshold</th>
<th>Interpretation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Missing %</td>
<td>&lt;5%</td>
<td>Minimal, complete-case OK</td>
</tr>
<tr class="even">
<td></td>
<td>5-20%</td>
<td>Moderate, consider imputation</td>
</tr>
<tr class="odd">
<td></td>
<td>20-50%</td>
<td>Substantial, require imputation</td>
</tr>
<tr class="even">
<td></td>
<td>&gt;50%</td>
<td>Severe, major validity concern</td>
</tr>
<tr class="odd">
<td>Outliers (n≥10)</td>
<td>≥2 methods</td>
<td>Consensus outlier, investigate</td>
</tr>
<tr class="even">
<td></td>
<td>1 method</td>
<td>Weak signal, likely normal</td>
</tr>
<tr class="odd">
<td>Skewness</td>
<td>-0.5 to 0.5</td>
<td>Approximately symmetric</td>
</tr>
<tr class="even">
<td></td>
<td>0.5 to 1 or -1 to -0.5</td>
<td>Moderate skew, consider transform</td>
</tr>
<tr class="odd">
<td></td>
<td>&gt;1 or &lt;-1</td>
<td>Severe skew, transform recommended</td>
</tr>
<tr class="even">
<td>CV</td>
<td>&lt;10%</td>
<td>Low relative variability</td>
</tr>
<tr class="odd">
<td></td>
<td>10-20%</td>
<td>Moderate relative variability</td>
</tr>
<tr class="even">
<td></td>
<td>20-50%</td>
<td>High relative variability</td>
</tr>
<tr class="odd">
<td></td>
<td>&gt;50%</td>
<td>Very high, consider MAD</td>
</tr>
<tr class="even">
<td>Runs test p</td>
<td>&lt;0.05</td>
<td>Reject randomness (clustered/alternating)</td>
</tr>
<tr class="odd">
<td></td>
<td>≥0.05</td>
<td>Consistent with random missing</td>
</tr>
<tr class="even">
<td>Quality Grade</td>
<td>A (90-100)</td>
<td>Excellent (heuristic)</td>
</tr>
<tr class="odd">
<td></td>
<td>B (80-89)</td>
<td>Good with minor issues</td>
</tr>
<tr class="even">
<td></td>
<td>C (70-79)</td>
<td>Quality concerns detected</td>
</tr>
<tr class="odd">
<td></td>
<td>D (&lt;70)</td>
<td>Significant quality issues</td>
</tr>
</tbody>
</table>
</div>
<div class="section level4">
<h4 id="decision-tree">Decision Tree<a class="anchor" aria-label="anchor" href="#decision-tree"></a>
</h4>
<pre><code>Variable Quality Check
│
├─ Numeric variable
│  │
│  ├─ Check skewness
│  │  ├─ &gt;1 → Use log transform for outlier detection
│  │  └─ ≤1 → Use raw data
│  │
│  ├─ Run outlier detection
│  │  ├─ n≥10 → Consensus (≥2 methods) required
│  │  ├─ 3≤n&lt;10 → Informative only (single method OK, verify manually)
│  │  └─ n&lt;3 → Insufficient data
│  │
│  ├─ Check missing %
│  │  ├─ &lt;20% → Complete-case analysis likely OK
│  │  └─ ≥20% → Plan imputation
│  │
│  └─ Check CV
│     ├─ Shown → Interpret relative variability
│     └─ Suppressed → Use MAD or IQR
│
└─ Categorical variable
   │
   ├─ Check entropy balance
   │  ├─ &gt;0.8 → Well balanced
   │  └─ &lt;0.6 → Imbalanced, check if OK
   │
   └─ Check rare categories
      ├─ Any &lt;threshold% → May violate chi-squared
      └─ All ≥threshold% → OK for standard tests</code></pre>
<hr>
<p><strong>End of Guide</strong></p>
<p><em>For questions or issues with this module, please refer to the
GitHub repository or contact the package maintainer.</em></p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://www.serdarbalci.com/" class="external-link">Serdar Balci</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
