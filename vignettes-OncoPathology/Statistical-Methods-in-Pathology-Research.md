# Statistical Methods in Pathology Research

https://chatgpt.com/share/68a6d06d-a3b4-8002-9b85-13cd174bc6d3



You’re asking about the statistical methods commonly used in research articles published in leading pathology journals such as Modern Pathology, American Journal of Surgical Pathology, American Journal of Pathology, Histopathology, and Archives of Pathology & Laboratory Medicine. While I couldn’t find journal‑specific breakdowns for each title, there is substantial evidence from reviews and audits of pathology literature that provide a strong general overview applicable across these journals.

⸻

Overview — Statistical Methods in Pathology Research

1. Frequent Statistical Tests and Methods

In a literature audit of 1,100 pathology papers from multiple journals in 2015, authors concluded that mastering around 12 statistical tests is sufficient for basic statistical literacy in pathology research  ￼. While the exact list wasn’t published in the summary, other sources provide insight on the most commonly used tests:
 • Descriptive Statistics: Means, medians, standard deviations, ranges.
 • Comparative Tests:
 • Parametric: Student’s t‑test (independent), paired t-test, ANOVA.
 • Nonparametric: Chi-square, Fisher’s exact, McNemar’s test, Mann–Whitney U, Wilcoxon signed‑rank test  ￼.
 • Diagnostic Accuracy Metrics: Sensitivity, specificity — particularly prevalent in cytopathology and diagnostic test studies  ￼.
 • Correlation and Agreement:
 • Correlation coefficients (e.g., Pearson’s r).
 • Agreement methods like Bland–Altman plots.
 • Method comparison regression such as Passing–Bablok regression  ￼ ￼.

2. Advanced Methods and Modeling

Beyond standard tests, many pathology studies also support more complex analysis:
 • Survival Analysis: Kaplan–Meier curves, log‑rank tests, Cox proportional hazards regression models—essential in prognostic studies such as tumor grading or staging research  ￼.
 • Regression Techniques: Linear regression, logistic regression, Poisson regression, and other multivariate models for diagnostic/prognostic modeling  ￼.
 • Exact Methods: Exact tests for small sample sizes or when assumptions for asymptotic tests fail  ￼.

3. Study Design, Missing Data & Validation

Important foundational factors influencing statistical methodology include:
 • Study Design & Diagnostic Validations: Emphasis on sensitivity, specificity, accuracy, and proper validation protocols for new tests  ￼.
 • Handling Missing Data: Imputation methods and strategies to deal with missingness in datasets  ￼.
 • Quality Control & Error Assessment: Statistics are crucial for evaluation of test precision, error, and ongoing quality control  ￼.
 • Scoring Systems: In histological scoring, appropriate statistical validation is essential to ensure reliability of comparisons  ￼.

4. Emerging and Specialized Techniques

In cutting-edge research settings—especially digital or molecular pathology—novel statistical approaches are gaining traction:
 • Bayesian models and spatial statistics: For example, modeling spatial point patterns in tumor microscopy images, using Marked Point Processes with MCMC and Bayesian inference  ￼.
 • Genomic and molecular data analysis: Methods like Significance Analysis of Microarrays (SAM) are employed to determine significant gene expression changes, using nonparametric and permutation-based approaches  ￼.

⸻

Key Takeaways by Category

Category Typical Statistical Tools
Descriptive & Comparative Means, medians, t-tests, ANOVA, chi-square, Fisher’s exact, nonparametric equivalents
Diagnostic Accuracy Sensitivity, specificity, agreement (Bland–Altman), Passing–Bablok
Association & Prediction Correlation, linear/logistic regression, multivariate modeling
Prognosis/Survival Kaplan–Meier, log-rank, Cox regression
Exact Methods Exact tests for small samples, mixed models
Data Handling Imputation for missing data, test validation metrics
Emerging Techniques Bayesian spatial models (e.g., MCMC), SAM for microarrays

⸻

How This Applies to Your Specific Journals

Although breakdowns per journal aren’t specified, most articles in reputable pathology publications such as Modern Pathology, American Journal of Surgical Pathology, American Journal of Pathology, Histopathology, and Archives of Pathology & Laboratory Medicine likely rely on a core set of these analyses depending on study focus—be it diagnostic accuracy, prognostic modeling, method validation, or molecular discovery.

⸻




Statistical Methods in Major Pathology Journals (2015–2025)

This review compares the statistical methods most frequently used in research papers across five leading pathology journals: Modern Pathology, American Journal of Surgical Pathology (AJSP), American Journal of Pathology (AJP), Histopathology, and Archives of Pathology & Laboratory Medicine (APLM). We surveyed literature from roughly the past decade to identify common approaches, categorizing them into descriptive statistics, group comparison tests, regression models, survival analysis, diagnostic accuracy measures, non-parametric methods, and advanced techniques (Bayesian, machine learning, spatial analysis). Notably, the vast majority of pathology research papers employ statistical analysis – one audit found that 81% of 1100 sampled pathology articles reported statistical methods ￼, with usage ranging from ~61% of papers in Modern Pathology to ~98% in the American Journal of Pathology ￼. Across pathology journals, a relatively small set of tests accounts for most analyses: one survey identified 18 statistical tests that appear frequently in pathology studies ￼, and knowledge of about 12 core tests would cover the needs of most pathologists ￼. Overall, simple inferential tests dominate – e.g. nearly half of pathology papers use chi-square/Fisher’s exact tests, one-third use t-tests, and about one-sixth use logistic regression ￼. Below, we break down each journal’s typical statistical methods, with examples and categorizations.

Modern Pathology (Translational Pathology Journal)

Modern Pathology focuses on clinicopathological and translational research in pathology (especially tumor pathology), often linking histopathological findings with clinical outcomes or molecular data. About 61% of Modern Pathology research articles utilize statistical analysis (the lowest of these journals) ￼, but those that do typically involve robust inferential methods reflecting its clinical-translational scope.
 • Descriptive Statistics: Virtually all studies include basic descriptive statistics to summarize patient cohorts and experimental data. Authors report measures like mean or median values (e.g. patient age, biomarker levels) and variability (standard deviations, ranges) for tumor groups or cohorts. For example, a typical Modern Pathology study of prognostic biomarkers will present descriptive tables of patient demographics, tumor characteristics, and marker expression levels (often with median values and interquartile ranges for skewed data). These descriptive summaries provide context but are usually accompanied by inferential tests ￼. Data visualization (e.g. histograms of marker distribution or scatterplots) is also common to explore patterns before formal testing ￼.
 • Comparative Tests (t-tests, ANOVA, χ²): Group comparison tests are very common. Modern Pathology studies frequently use χ² tests (chi-square) or Fisher’s exact tests to examine associations between categorical variables, such as immunohistochemical status vs. clinical outcomes ￼. In fact, chi-square or Fisher’s tests are among the most used statistics in pathology literature (~47% of studies with inferential stats use them) ￼. For comparing continuous measurements between two groups (e.g. biomarker levels in mutated vs. wild-type tumors), Student’s t-tests are often employed (appearing in about one-third of pathology papers) ￼. When more than two groups are compared (e.g. marker levels across multiple tumor subtypes), analysis of variance (ANOVA) is utilized ￼. For example, a Modern Pathology paper on melanoma regression compared patient and tumor features between groups: “Differences between the groups were tested using either chi-square test or Wilcoxon signed-rank test as appropriate” ￼, indicating use of chi-square for categorical data and a non-parametric test for paired comparisons. Overall, comparative hypothesis tests (χ², t-test, ANOVA) form the backbone of statistical analysis in this journal to detect significant differences between pathological groups.
 • Regression Models: Given the translational focus, Modern Pathology studies often employ multivariable models to control for confounding and assess independent prognostic factors. Logistic regression is commonly used to identify predictors of binary outcomes such as metastasis (yes/no) or test positive vs. negative. Multivariable logistic models allow pathologists to adjust for multiple covariates – indeed, about 17% of pathology articles use logistic or odds ratio analyses ￼. For instance, authors might report an odds ratio from a logistic regression evaluating whether a histologic feature independently predicts lymph node involvement. Linear regression appears less frequently (also ~17% of studies ￼) but is used when outcomes are continuous (e.g. gene expression levels correlated with a continuous variable like tumor size). Modern Pathology also sees Cox proportional hazards regression (a survival-specific regression) in many prognostic studies (often under the umbrella of survival analysis; see below). Regression models are integral in papers that build predictive models or adjust for multiple factors, reflecting the journal’s emphasis on rigorous analysis of prognostic markers and risk factors.
 • Survival Analysis: Because many Modern Pathology papers deal with prognostic biomarkers or tumor features, survival analysis is a prominent method. Studies frequently include Kaplan–Meier survival curves to estimate patient survival (overall survival, disease-free survival) stratified by pathology findings (e.g. marker-positive vs. negative), with log-rank tests comparing survival curves between groups ￼ ￼. For example, a report on neoadjuvant therapy response might note: “Survival probability as a function of time was computed using the Kaplan–Meier method, and the log-rank test was used to compare overall survival between responders and non-responders” ￼. Additionally, multivariable Cox proportional hazard models are widely used to identify independent prognostic factors (e.g. whether a histological feature predicts survival when controlling for stage and treatment) ￼. In fact, translational pathology journals like Modern Pathology tend to employ survival methods more often than some other pathology fields ￼. One analysis noted that “basic science and translational journals tend to use survival methods” extensively ￼. Thus, Modern Pathology papers commonly present hazard ratios from Cox models alongside Kaplan–Meier curves, making survival analysis a core statistical approach in this journal.
 • Diagnostic Accuracy Measures: Many articles in Modern Pathology evaluate new diagnostic tests or biomarkers, so diagnostic test accuracy (DTA) statistics are frequently reported. Authors often calculate sensitivity and specificity of a novel marker or technique against a gold standard. For example, a study on a histochemical stain might report that “at a cutoff of 5% tumor cells stained, sensitivity for detection of disease was 85.7% and specificity was 68.6%” ￼. Positive and negative predictive values (PPV, NPV) are also provided to indicate clinical utility. In addition, receiver operating characteristic (ROC) curve analysis is used to determine optimal cut-off points and the area under the curve (AUC) to quantify overall accuracy. Modern Pathology encourages following formal DTA study designs for diagnostic evaluations ￼, which means studies explicitly report these metrics. For instance, in an AI-based diagnostic study, an algorithm was able to detect a tumor feature “with sensitivity and specificity (AUC ≈ 0.89) similar to routine tests” ￼. Such metrics (sensitivity, specificity, AUC) are crucial in pathology papers that propose new diagnostic criteria or tools.
 • Non-Parametric Methods: Although parametric tests are standard, Modern Pathology studies do use non-parametric statistics when data do not meet assumptions (small sample sizes, non-normal distributions, or ordinal scores). Common choices include the Mann–Whitney U test (Wilcoxon rank-sum) for comparing two independent groups on a non-normal continuous outcome, and Kruskal–Wallis test for multiple-group comparisons without normality ￼ ￼. Paired non-parametric tests (like Wilcoxon signed-rank) are applied for pre-vs-post comparisons or matched data (e.g. biomarker expression in paired samples) ￼. While non-parametric tests appeared in roughly 8% of pathology studies in one survey ￼ (much lower than t-tests or χ²), they are employed as needed in Modern Pathology. For example, if immunohistochemical scoring is on an ordinal scale, authors might use a Mann–Whitney test instead of t-test. Overall, non-parametric methods serve as important alternatives in this journal when data characteristics dictate their use (ensuring statistical conclusions remain valid despite non-normal or ordinal data).
 • Advanced and Specialized Methods: Modern Pathology has increasingly featured advanced analytical techniques in recent years. Notably, there is a rise in studies using machine learning (ML) and artificial intelligence for image analysis and predictive modeling. Deep learning approaches (e.g. convolutional neural networks) have shown “tremendous utility in analysis of digital whole slide images” in pathology ￼, and Modern Pathology has published several such studies (e.g. AI algorithms predicting molecular subtypes directly from H&E slides). These papers often involve complex model training but still report traditional statistics for performance (such as accuracy, AUC, and confusion matrices). Spatial statistics have also emerged, where researchers analyze the spatial distribution of cells or molecules in tissue sections (for instance, calculating distances between immune cells and tumor cells to quantify tumor microenvironment architecture). Additionally, while relatively rare, Bayesian methods appear occasionally – for example, in quantitative studies of molecular pathology, Bayesian analysis might be used to integrate prior information or to calculate genetic risk probabilities ￼. Overall, Modern Pathology is at the forefront of introducing cutting-edge quantitative methods (AI-based classification, high-dimensional data analysis, etc.) into pathology research. These advanced methods complement the traditional biostatistical toolbox, especially as pathology moves toward more data-rich, digital and molecular studies.

American Journal of Surgical Pathology (AJSP)

The American Journal of Surgical Pathology publishes primarily anatomic pathology research, including clinicopathologic correlations, case series, and studies of disease classification and prognosis. Its content overlaps with Modern Pathology in focusing on tissue-based human studies, so statistical methods are similar in many respects. Nearly all AJSP research articles involve statistical analysis; as a translational journal it has a high rate of stats usage (comparable to Modern Pathology). The typical AJSP paper will include baseline descriptive stats and one or more of the common inferential tests or models to support its findings.
 • Descriptive Statistics: AJSP papers routinely start with descriptive summaries of the study cohort and variables. For example, in a study of a new tumor grading scheme, authors will describe the patient sample (number of cases, age range, sex distribution) and key pathological features (tumor sizes, frequencies of histologic subtypes) using means, medians, proportions, and standard deviations. Tables of descriptive data are common, giving readers a clear sense of the dataset before any comparisons are made. These descriptive statistics are essential for context, though by themselves they do not imply significance. Consistent with other pathology journals, a minority of papers rely only on descriptive analysis – most proceed to hypothesis testing ￼. Data visualization (bar charts for category frequencies, etc.) may be used to illustrate distributions of lesion types or scores, supplementing the numeric summaries.
 • Comparative Tests (t-tests, ANOVA, χ²): Inferential tests in AJSP emphasize comparing groups of patients or specimens to find significant differences. Chi-square tests (or Fisher’s exact for small N) are widely used to compare categorical data, such as the association between a histopathologic finding and a clinical parameter. For instance, AJSP authors might use a χ² test to examine if a particular mutation is more frequent in one tumor subtype than another. t-Tests (unpaired Student’s t) are common for comparing group means – e.g. testing if mean tumor size differs between two diagnostic categories. One literature survey found t-tests in roughly one-third of pathology studies overall ￼, reflecting their importance. ANOVA is employed when comparing more than two groups, for example, if analyzing three or more categories of a lesion grade or multiple immunohistochemical subgroups. AJSP often includes multi-group analyses (e.g. comparing gene expression across three tumor grades), where ANOVA is appropriate (followed by post-hoc tests if needed). In summary, AJSP heavily relies on these classic tests (χ², t, ANOVA) to detect group differences; these methods are core competencies since together they account for a large fraction of tests used in pathology research ￼.
 • Regression Models: Many AJSP studies use regression analysis to adjust for confounders or to build predictive models. Logistic regression is frequently seen in multivariate analyses of clinicopathologic studies – for instance, determining which histological factors independently predict lymph node metastasis or disease recurrence (outcomes coded as yes/no). AJSP papers often include a multivariate logistic model yielding odds ratios for various risk factors, which helps refine which factors are truly significant beyond simple associations. Similarly, linear regression appears when correlating continuous outcomes (e.g. extent of a proliferation index vs. another continuous variable like patient age or lab values). However, logistic models are generally more common due to the binary nature of many pathology endpoints (disease present/absent, high-grade vs low-grade, etc.). Moreover, when studies incorporate multiple variables, authors sometimes use stepwise regression or other model selection approaches to identify the best combination of predictors. By employing regression, AJSP articles ensure that reported prognosticators or associations are not simply due to one confounding factor. This use of multivariable models is consistent with broad pathology literature where roughly 17% of studies used logistic or odds ratio analyses ￼. It aligns with the journal’s clinical orientation – emphasizing which factors matter most when multiple variables interplay.
 • Survival Analysis: Prognostic studies are a mainstay of AJSP (e.g. assessing how a tumor feature impacts patient survival), so survival analysis techniques are common. Authors frequently generate Kaplan–Meier survival curves stratified by pathology findings (for example, showing disease-free survival in patients with vs. without a certain biomarker). They then use the log-rank test to compare survival distributions between groups; a significant log-rank p-value indicates the pathology factor is associated with different outcomes. Additionally, AJSP papers often include Cox proportional hazards regression to perform multivariate survival analysis. For example, in a study of sarcoma, a Cox model might evaluate whether tumor grade, size, and margin status each independently affect overall survival. Hazard ratios from Cox models are reported to quantify how much a factor increases the hazard of death or recurrence, adjusting for other variables. Because AJSP focuses on surgical pathology of often malignant diseases, these survival tools are pivotal. In fact, translational journals like AJSP are documented to “use survival methods” frequently ￼. A typical AJSP article on prognostic markers will thus present both univariate Kaplan–Meier analyses and multivariable Cox analyses, ensuring rigorous assessment of survival impact.
 • Diagnostic Accuracy Measures: AJSP occasionally publishes studies of novel diagnostic techniques or grading criteria, which involve diagnostic accuracy statistics. For instance, if a paper evaluates a new immunohistochemical panel for diagnosing a tumor, it will report metrics such as sensitivity, specificity, and accuracy of the panel compared to the reference standard diagnosis. ROC curves may be plotted to determine how well a quantitative marker discriminates between benign and malignant cases, with AUC summarizing its performance. Predictive values (PPV/NPV) might be given especially if the study is geared toward clinical test utility. Although AJSP is primarily a pathology (morphology) journal and not focused on lab test validation per se, many studies have a diagnostic component (e.g. distinguishing two tumor types), where these measures are relevant. Moreover, interobserver agreement is sometimes assessed for diagnostic criteria – for example, if multiple pathologists independently grade a feature, the Cohen’s kappa statistic is used to measure agreement. Kappa is widely reported in pathology literature for interobserver variability ￼. An AJSP article introducing a new histologic classification might note a kappa value demonstrating moderate or substantial agreement among pathologists on applying that classification. In summary, while not as prevalent as in purely lab medicine journals, diagnostic accuracy and agreement statistics do appear in AJSP when new diagnostic approaches or reproducibility are evaluated.
 • Non-Parametric Methods: AJSP authors resort to non-parametric tests when data characteristics require them. Surgical pathology studies can involve ordinal scoring systems (e.g. grading dysplasia 0–3) or non-normal data (e.g. immunostain scores that cluster at certain values). In such cases, Mann–Whitney U tests are used instead of t-tests for two-group comparisons, and Kruskal–Wallis for multiple groups. For paired comparisons (e.g. biomarker levels pre- and post-treatment in the same patients), the Wilcoxon signed-rank test is an appropriate choice if normality is questionable. Though overall non-parametric tests are less commonly reported than parametric ones (they comprised ~8% of tests in a 2015 audit ￼), AJSP includes them whenever the data dictate. Additionally, if a study compares categorical outcomes on paired samples (like biopsy vs resection diagnosis), a McNemar’s test (a non-parametric test for paired proportions) might be applied. The use of non-parametric methods in AJSP underscores the journal’s commitment to correct statistical practice; authors typically mention that a non-parametric alternative was chosen due to data distribution, ensuring that p-values and confidence intervals are valid despite any deviations from parametric assumptions.
 • Advanced and Specialized Methods: The statistical sophistication in AJSP tends to be moderate, with advanced methods used when relevant to the research question. Bayesian statistics are not commonly reported in AJSP articles, but on occasion, one might see a Bayesian approach in studies like diagnostic probability calculation or molecular classification (for example, using Bayesian modeling to integrate prior probabilities in assessing disease likelihood). Machine learning and AI methods are less prominent in AJSP than in Modern Pathology, but they are beginning to appear, especially in studies involving image analysis or large datasets. For instance, a recent AJSP paper might explore a machine learning classifier to differentiate histologic patterns; such a study would include performance metrics (accuracy, AUC) as noted above. Spatial analyses are rare but could feature in studies of tumor architecture (e.g. quantifying the spatial arrangement of cells in a tumor microenvironment). Another advanced area occasionally seen is cluster analysis or principal component analysis (PCA) in papers dealing with high-dimensional data (like gene expression or proteomic profiles of tumors) – for example, clustering cases by molecular profiles and correlating those clusters with histology. Overall, AJSP primarily relies on established biostatistical methods, but it is receptive to newer techniques when they enhance the analysis of pathology data.

American Journal of Pathology (AJP)

The American Journal of Pathology has a more basic and experimental pathology focus, including animal models, molecular mechanisms of disease, and translational research. It often publishes preclinical studies and mechanistic investigations, which influences its statistical profile. AJP had one of the highest rates of statistical usage (in one analysis, 98% of sampled AJP papers included statistical methods) ￼, reflecting that nearly every research study (even in vitro or animal experiments) incorporates quantitative analysis. The statistical methods in AJP cover a broad range, from simple comparisons in laboratory experiments to more complex analyses for translational studies.
 • Descriptive Statistics: In AJP, descriptive stats are used to summarize experimental data and animal study characteristics. For example, an experimental pathology study might describe the number of mice in each group, baseline measurements (means ± standard errors), or distribution of a histologic score in a treated vs control group. Descriptive tables or figure legends often list means, medians, and variability measures for key outcomes (e.g. “tumor volume was 1.2±0.3 cm³ in control vs 0.8±0.2 cm³ in treated mice”). These provide essential context. Additionally, AJP studies frequently present graphical descriptive data: bar graphs with error bars, line graphs for time-course experiments, etc., to visually convey group differences before formal testing. Although descriptive data alone do not test hypotheses, virtually all AJP papers progress to inferential statistics (since nearly all include some statistical comparison) ￼. The descriptive step in AJP is critical in experimental setups to show baseline comparability and the raw effect sizes observed.
 • Comparative Tests (t-tests, ANOVA, χ²): Given AJP’s emphasis on experimental work, parametric tests like t-tests and ANOVA are especially prominent. Controlled experiments (e.g. knockout vs wild-type mice, treated vs untreated cells) often involve comparing group means. The Student’s t-test is a workhorse in AJP for two-group comparisons – for instance, comparing mean lesion size in two mouse cohorts or mean gene expression between control and treated samples. t-tests (including paired t-tests when appropriate) are among the most frequently used tests in pathology research generally ￼ and AJP is no exception. When experiments have more than two groups (common in dose-response or multi-arm studies), ANOVA is used to determine if an overall difference exists among groups; if significant, authors typically follow with post-hoc comparisons (Tukey, Bonferroni, etc.) to pinpoint which groups differ. AJP papers often explicitly state something like: “ANOVA with post hoc Tukey’s test was performed to compare tumor burden across the three dosage groups.” For categorical outcomes or group proportions in experiments (less common than continuous measures, but e.g. fraction of animals with metastases in each group), chi-square tests or Fisher’s exact tests are used. For example, an AJP study might use a chi-square test to compare incidence of a pathology between genetically modified vs control animals. Overall, these basic tests (χ², t, ANOVA) form the backbone of hypothesis testing in AJP’s experimental studies, aligning with their high overall usage in pathology literature ￼.
 • Regression Models: AJP primarily features controlled experiments, but many studies also include observational or translational analyses (especially when using human specimens or complex datasets). Linear regression is used in some AJP studies to model relationships between continuous variables – for instance, correlating gene expression level with severity of pathology on a continuous scale. AJP papers might also use linear regression to adjust for covariates in animal experiments (though randomization often obviates many confounders). Logistic regression appears in AJP when analyzing binary outcomes or combining multiple predictors, particularly in translational studies involving patient samples or pathology data linked to outcomes. For example, if AJP publishes a study on a new biomarker tested in a human cohort, the authors might include a logistic regression to see if the biomarker (plus perhaps patient age, etc.) predicts disease presence. However, logistic models are somewhat less common in AJP compared to clinical journals; one reason is that many AJP studies have simpler experimental designs (two-group comparisons) that don’t require multivariate modeling. Still, when AJP articles venture into multivariable territory (e.g. combining multiple pathologic features to predict an outcome), they utilize logistic or linear regression as needed. Additionally, AJP occasionally features correlation analysis as a form of regression-lite: reporting Pearson or Spearman correlation coefficients to quantify associations between variables (like a histopathologic score and a molecular readout). These correlations help demonstrate relationships in experimental pathology (e.g. “fibrosis score correlated with hydroxyproline levels, Spearman r = 0.65, p<0.01”). In summary, regression methods in AJP are present but not as universal as in clinical journals; they’re used selectively for multivariate assessment and to quantify linear relationships in data.
 • Survival Analysis: AJP’s coverage of survival analysis is somewhat bimodal. Many AJP papers are animal studies without a “time-to-event” component, so they do not involve survival statistics. However, AJP also publishes work on human tissue and disease mechanisms where patient follow-up is relevant. In such translational studies (e.g. examining a pathway in human cancer tissues), authors often include Kaplan–Meier survival analysis to show that the molecular marker or histologic feature studied has prognostic significance. For instance, an AJP paper on a novel cancer biomarker might stratify a patient cohort by high vs low biomarker expression and plot Kaplan–Meier curves for survival, using log-rank tests to compare outcomes. They may further use Cox proportional hazards models to adjust for other factors, establishing that the biomarker independently predicts survival. Basic science journals like AJP indeed showed the highest prevalence of statistical usage ￼, and they tend to include survival analysis when applicable ￼ (one survey noted that “basic science journals [including AJP] tend to use survival methods” in studies that involve patient data ￼). As a result, while survival analysis is not relevant for purely in vitro or short-term animal experiments, it features in AJP’s human-focused papers. For example, a mechanistic study of a gene might conclude with an analysis of clinical samples linking that gene’s expression to patient survival via Kaplan–Meier and multivariate Cox analysis. Thus, AJP demonstrates flexibility: incorporating survival statistics for human outcome correlation, while many purely experimental papers skip this category entirely due to study design.
 • Diagnostic Accuracy Measures: Because AJP leans toward mechanistic and experimental work, classical diagnostic test evaluations are less common here than in clinical pathology journals. AJP studies rarely focus on assessing the sensitivity or specificity of a new clinical test; however, when AJP articles examine a novel biomarker or assay in a research context, they may report some diagnostic performance metrics. For example, in a study proposing a new blood marker for liver injury (in an animal model), authors might report how well the marker distinguishes treated vs control animals, possibly citing an AUC from an ROC analysis or a threshold yielding a certain sensitivity/specificity. When AJP does publish clinically oriented studies (e.g. on human diagnostic criteria or laboratory assays), those papers will include sensitivity, specificity, and ROC curves similar to other journals. Additionally, method comparison statistics can appear in AJP’s laboratory investigations: for instance, if comparing two measurement techniques, one might see correlation coefficients or Bland-Altman plots analyzing agreement (though these are more typical in lab medicine journals). Inter-rater reliability (kappa) is seldom a focus in AJP, since most studies are experimental rather than multi-observer clinical interpretations. An exception might be if AJP publishes a pathology study where multiple observers quantified a histologic phenotype – then kappa could be mentioned to demonstrate consistency. Overall, diagnostic accuracy stats are not a mainstay of AJP’s content, but the journal does include them when relevant, especially in bridging studies that validate new experimental findings against clinical benchmarks.
 • Non-Parametric Methods: AJP researchers use non-parametric tests when appropriate, though many experimental datasets meet parametric assumptions or have sufficient size for parametric tests. In small-n animal studies or when outcomes are scored on ordinal scales (e.g. pathology scores 0–4 in models of disease), non-parametric tests are prudent. Mann–Whitney U tests are applied in place of t-tests if normality is questionable (for example, comparing a semiquantitative histology score between two mouse groups). Kruskal–Wallis tests might be used if comparing ranks across multiple experimental groups. AJP authors often note in methods that they performed a normality test (such as Shapiro-Wilk) and chose non-parametric tests if criteria were not met. Additionally, if data are paired (e.g. measuring something in the same animal before and after an intervention), the Wilcoxon signed-rank test might be used as a non-parametric analog to a paired t-test. Non-parametric methods comprised a modest fraction of pathology study analyses (≈8% in one audit ￼), reflecting that parametric tests dominate but alternatives are employed when needed. AJP, being rigorous, follows this pattern: default to t-tests/ANOVA when assumptions hold, but readily switch to rank-based tests for non-normal or small-sample data. This ensures that even experimental pathology studies with non-Gaussian data distributions are analyzed appropriately without violating statistical assumptions.
 • Advanced and Specialized Methods: As a journal covering experimental pathology, AJP sometimes delves into advanced statistical or data-analytic techniques, especially in studies with high-dimensional data. Bioinformatics and “omics” data analysis often appear in AJP – for instance, gene expression profiling or proteomic analyses in disease models. Such studies may use techniques like hierarchical clustering, principal component analysis (PCA), or heatmap visualizations to make sense of large data matrices. They may also employ multiple comparison corrections (e.g. false discovery rate control) when testing thousands of genes, which is a statistical consideration beyond simple tests. On the statistical modeling front, AJP occasionally includes specialized regression models (e.g. Poisson or logistic regression for count data in pathology experiments, or mixed-effects models if data are longitudinal or clustered by animal). Bayesian approaches might appear in theoretical contexts or where prior information is incorporated (for example, Bayesian network models to integrate various molecular and histologic predictors of disease outcome). While Bayesian analysis isn’t mainstream in AJP articles, the journal’s scope means it will entertain such methods if justified by the study design. Lastly, machine learning is gradually making inroads into AJP as well: e.g. using a classifier to predict disease subclass from a molecular signature. These studies, though fewer in number, highlight AJP’s engagement with modern data science. In summary, AJP’s advanced methodological usage is driven by the demands of experimental research – the journal may feature anything from bioinformatic analyses for molecular data to complex models, reflecting the diverse quantitative needs of pathology research at the mechanistic level.

Histopathology

Histopathology is an international journal encompassing diagnostic and experimental human pathology. It often publishes clinicopathologic studies, evaluation of diagnostic criteria, and some molecular and translational research, making its statistical profile somewhat akin to AJSP and Modern Pathology. We did not have a specific audit of Histopathology in the 2015 survey (it wasn’t among the 11 journals sampled ￼), but based on its content and Pathological Society guidelines, one can infer the common statistical practices. In general, Histopathology articles employ standard biostatistics for group comparisons and outcome analyses, and the journal emphasizes proper study design and statistical reporting (as reflected in guidelines like MINPEPA for experimental pathology reporting ￼).
 • Descriptive Statistics: Histopathology papers typically begin with descriptive overviews of the case series or dataset. If a study covers (for example) 100 colorectal cancer cases with a new grading system, the authors will describe the patient demographics (age, sex distribution) and tumor attributes (tumor stages, frequencies of certain histologic features) in narrative or tables. Measures like median values (often used if data are skewed, e.g. serum marker levels) and ranges/interquartile ranges are provided, or means and standard deviations if appropriate. The journal expects clarity in such reporting; authors are advised to “keep it simple” and present key summary data without unnecessary clutter ￼. Descriptive stats set the stage for inference, and almost all original studies in Histopathology progress beyond description to perform statistical tests. Nonetheless, accurate descriptive reporting is valued to ensure readers understand the baseline characteristics and variability in the data.
 • Comparative Tests (t-tests, ANOVA, χ²): As a diagnostic pathology journal, Histopathology relies heavily on tests that compare groups or assess associations. Chi-square tests are extensively used to check associations between categorical variables – for instance, whether a particular histologic pattern is significantly associated with a clinical outcome or another pathology finding. Many studies include statements such as “Chi-square or Fisher’s exact test was used to compare categorical variables between groups,” which is standard for pathology research. t-Tests (unpaired or paired, as needed) are used to compare means between two groups, such as mean age between two diagnostic categories or mean expression level of a protein in diseased vs normal tissue. For more than two group comparisons (e.g. comparing three different subtypes of a disease on a quantitative variable), ANOVA is applied. The frequency of these tests in Histopathology likely mirrors their general frequency in pathology journals (chi-square and t-tests being among the top tests employed ￼). Given Histopathology’s focus on human pathology, these tests often underpin conclusions about whether differences in histologic measures or clinicopathologic parameters are statistically significant across patient groups.
 • Regression Models: Histopathology publications often involve multivariate data, thus regression analyses are common for controlling confounders or identifying independent predictors. Logistic regression is a mainstay for studies where the outcome is binary (e.g. presence vs absence of metastasis, benign vs malignant diagnosis). For example, a Histopathology article might examine multiple factors (tumor size, grade, biomarker status) in a logistic model to determine which independently predict lymph node metastasis; the results would be presented as odds ratios with confidence intervals. Similarly, linear regression may be used if a continuous outcome is studied (though less typical, since many pathology outcomes are categorical or time-to-event). Logistic models in pathology generally cover the ~15–20% range of usage ￼, and Histopathology likely follows suit, particularly in prognostic or predictive studies. The journal also values clear interpretation of these models – authors often provide an explanation of the meaning of an odds ratio or adjust for multiple comparisons to avoid overfitting. In some studies, you will see multivariate analysis sections explicitly, often combining logistic regression for binary outcomes or linear regression for continuous ones, reinforcing the journal’s commitment to robust analysis beyond simple 2×2 comparisons.
 • Survival Analysis: Histopathology deals with many oncology-related studies and thus frequently includes survival analysis when patient follow-up data are available. Kaplan–Meier survival curves are used to depict outcomes like overall survival or disease-free survival stratified by histopathologic factors (e.g. a novel grading or staging criteria, biomarker status). The log-rank test is then applied to check if survival differences between groups are statistically significant. For example, a study on a new tumor staging system might report that patients classified as high-risk by the new system have significantly worse survival on Kaplan–Meier analysis (p via log-rank < 0.01). In addition to univariate survival analysis, Histopathology papers often include Cox proportional hazards regression for multivariate survival analysis – ensuring that a pathology variable is an independent prognostic factor when controlling for other variables like age or treatment. The output (hazard ratios) is key in such studies. Indeed, like other translational journals, Histopathology has a strong representation of survival analysis; these methods comprised roughly 12–14% of statistical usage in translational/basic pathology categories in one study ￼. A noteworthy example in Histopathology might be a paper on breast cancer where Kaplan–Meier analysis showed a significant difference in 5-year survival by marker expression, and Cox regression confirmed that marker expression was an independent predictor of mortality (with hazard ratio ~2.0, p < 0.05). This illustrates how survival statistics are integrated to draw clinically meaningful conclusions in the journal.
 • Diagnostic Accuracy Measures: As a journal dedicated to diagnostic pathology, Histopathology often publishes studies that assess new diagnostic markers, scoring systems, or imaging techniques. These studies employ diagnostic accuracy metrics similar to those in Modern Pathology and APLM. Authors routinely report the sensitivity and specificity of a new test or criterion. For instance, a paper evaluating an immunohistochemical marker for a certain cancer might state: “Marker X showed 92% sensitivity and 85% specificity for diagnosing tumor Y in our series.” Positive and negative predictive values are given, especially when the study context implies a certain prevalence, to convey how reliable the test is in practice. ROC curve analysis is widely used; Histopathology papers often include ROC curves to determine the optimal cutoff value for a quantitative marker and the corresponding AUC (a high AUC close to 1.0 indicates excellent diagnostic discrimination). Additionally, likelihood ratios and diagnostic odds ratios sometimes appear for completeness in assessing test performance. The journal also encourages authors to validate diagnostic findings on independent data or via cross-validation when possible. Another aspect of diagnostic studies is interobserver agreement – when introducing a new histopathological classification or grading, Histopathology papers frequently measure reproducibility. They use Cohen’s kappa to quantify inter-pathologist agreement, following the common practice in pathology literature ￼. For example, a study on grading dysplasia in biopsies might report a kappa of 0.65 among three pathologists, indicating substantial agreement on the grading criteria. All these measures help demonstrate that a new diagnostic approach is both accurate and reliable, which is crucial for adoption in practice.
 • Non-Parametric Methods: Histopathology authors utilize non-parametric tests whenever the data’s nature dictates. Human pathology data can be skewed or ordinal (for example, semi-quantitative scoring of staining intensity 0–3). If the distribution of a continuous variable is non-normal or sample size is small, Mann–Whitney U tests serve as alternatives to t-tests. For comparing medians of more than two groups, Kruskal–Wallis tests are used. The journal’s readers are familiar with these tests’ usage – for instance, a study might note that a biomarker level comparison between tumor types was done with Mann–Whitney test because the data were not normally distributed. In cases of paired data (e.g. measurements on the same patient’s sample before and after treatment), the Wilcoxon signed-rank test can be applied if parametric assumptions fail. Non-parametric correlation (Spearman’s rho) may also be seen when relating two rank-based or skewed variables (e.g. correlating an immunohistochemical score with a semi-quantitative pathology feature). While these non-parametric methods are not the majority, they are an essential part of Histopathology’s statistical arsenal for valid analysis of non-normal data. Their use aligns with good practice guidelines (like MINPEPA) that emphasize using appropriate statistical tests based on data type and distribution ￼.
 • Advanced and Specialized Methods: Histopathology remains primarily focused on robust application of standard statistical methods, but it is not devoid of advanced techniques. In recent years, the journal has published some machine learning and digital pathology studies, reflecting the field’s growth. These include applications of neural networks or image analysis algorithms to histological slides. For example, a Histopathology paper might investigate an automated image analysis tool for quantifying immunohistochemical staining; such a study could involve an ML algorithm and report its performance (accuracy, AUC) and agreement with pathologist assessments (possibly using kappa). The journal also occasionally features meta-analyses or systematic reviews that involve statistical aggregation methods (e.g. forest plots, tests for heterogeneity, etc.), though these are less common. Additionally, Histopathology might see spatial statistics in studies examining tissue architecture – for instance, using software to compute spatial relationships between tumor cells and immune cells in the microscopic images, yielding metrics that can be compared statistically between cases (these analyses often entail advanced image processing and statistical modeling of spatial point patterns). Bayesian methods are rare in Histopathology but not entirely absent; a scenario could be Bayesian model comparisons for diagnostic probabilities or incorporating prior knowledge in small-sample studies (though most authors stick to frequentist approaches). In summary, while Histopathology emphasizes correct use of classical statistics, it is gradually incorporating more advanced analytics like AI-driven image analysis, always with an eye to maintaining rigorous validation of those methods in a diagnostic context.

Archives of Pathology & Laboratory Medicine (APLM)

Archives of Pathology & Laboratory Medicine covers a broad spectrum of pathology research, including anatomic pathology, laboratory medicine (clinical pathology), quality assurance, and education. It often features studies of diagnostic tests, laboratory techniques, and practice improvements, so its statistical usage leans toward evaluating test performance and agreement, in addition to the usual comparisons. APLM had a somewhat lower proportion of papers using inferential stats (~70% in one analysis of “general” pathology journals, which included APLM) ￼, possibly because it sometimes publishes case series or educational pieces without formal analysis. Nonetheless, the majority of APLM research studies do employ statistical methods, and a “small number of statistical tests are frequently used in pathology studies” including those in APLM ￼ ￼.
 • Descriptive Statistics: Many APLM articles start with descriptive data, especially for laboratory studies (e.g. describing reference ranges, patient cohort characteristics for a lab test study). For example, an APLM paper might detail the median values of a new biomarker in healthy vs diseased populations before delving into test comparisons. In quality assurance studies, descriptive stats may include percentages of compliance or error rates pre- and post-intervention. APLM emphasizes clarity in such data reporting because these baseline numbers often have practical implications (such as typical values in a population). Graphical summaries are also common: method comparison studies might show scatterplots of two assay results with a line of identity, while QA studies might use control charts to descriptively show performance over time. While purely descriptive studies exist, the journal generally expects authors to go further and statistically verify any observed differences or trends, given that over 80% of pathology papers with stats use inferential tests rather than just description ￼.
 • Comparative Tests (t-tests, ANOVA, χ²): APLM frequently features studies comparing different methods or groups, making t-tests and ANOVA important. For example, a clinical chemistry study in APLM might compare mean values obtained by two different assay kits (paired t-test if the same samples are run on both methods). Or a new procedure might be tested at multiple labs and ANOVA used to see if there are any systematic differences among labs. APLM’s anatomic pathology articles also use chi-square tests for categorical comparisons, such as evaluating if a new reporting protocol changes the frequency of certain diagnoses (comparing proportions before vs after implementation). In survey-based studies or educational research published in APLM, chi-square tests are used to compare categorical responses among different groups of respondents. Essentially, all the classic tests (χ², Fisher’s exact, t, ANOVA) are employed similarly to other journals for group comparisons. The known high-frequency tests in pathology – chi-square (~48% usage) and t-test (~33% usage) ￼ – certainly appear in APLM’s content, often to support conclusions about whether a new lab method or pathology practice yields a statistically significant improvement. Given the journal’s practical bent, authors often highlight when a difference is not only statistically significant but also clinically significant, although the latter is a contextual judgment rather than a statistical metric.
 • Regression Models: APLM papers make use of regression techniques primarily in two contexts: multivariate adjustment in observational studies and method comparison/validation. In pathology practice studies (e.g. analyzing factors contributing to diagnostic turnaround time or error rates), multivariable logistic regression might be used to identify independent predictors of an outcome (like error occurrence) among many candidate factors. Similarly, in studies correlating lab values with clinical outcomes, linear or logistic regression can help adjust for patient variables. APLM also sometimes includes health services or utilization analyses which could employ linear regression or time-series regression (if looking at trends over time with interventions). Another context is when evaluating a quantitative diagnostic test: authors might use linear regression to assess the correlation between a new test and an established reference test (reporting the regression equation and R² to show how well they agree). However, method comparison in lab medicine more often relies on correlation and Bland-Altman analysis than formal regression modeling – still, the concept of relationship is present. Overall, regression usage in APLM is moderate and purpose-driven. It likely mirrors the typical ~17% rate of logistic/odds usage in pathology studies ￼. For example, a 2017 APLM study on physician statistical literacy noted associations like having taken a statistics course and higher knowledge scores, which could have been evaluated via logistic regression (and indeed they found such factors were significantly associated with better knowledge ￼). In sum, APLM applies regression when needed to control confounders or to model relationships, particularly in studies dealing with multifactorial lab processes or outcomes.
 • Survival Analysis: As a comprehensive pathology journal, APLM does publish some clinical studies with patient follow-up, though perhaps less often than the subspecialty oncology-focused journals. When survival or time-to-event data are involved, APLM uses the standard toolkit: Kaplan–Meier curves and log-rank tests for univariate survival comparisons, and Cox proportional hazards models for multivariate survival analysis. For instance, APLM might have an article on long-term outcomes of patients after a certain diagnostic test; it could include a Kaplan–Meier analysis showing time to relapse stratified by test result, with a log-rank p-value indicating significant difference. Cox regression might then adjust for patient age, stage, etc., to confirm the test result is an independent predictor of outcome. However, many APLM studies are cross-sectional or diagnostic rather than longitudinal, so survival analysis is not as ubiquitous here as in Modern Pathology or AJSP. When APLM does include survival data, it ensures proper reporting of hazard ratios and confidence intervals. A point of interest: APLM’s broad scope includes autopsy pathology and forensic studies where survival analysis might not apply, as well as lab medicine studies that focus on diagnostic accuracy rather than patient survival. So, while APLM is fully equipped to publish survival statistics, the frequency is highly dependent on the topic mix in any given issue.
 • Diagnostic Accuracy Measures: This is a cornerstone for APLM. As the CAP’s flagship journal, APLM often evaluates new diagnostic tests, markers, or laboratory procedures, making sensitivity, specificity, and related measures extremely common in its papers. Authors will calculate the sensitivity and specificity of, say, a new immunohistochemical stain or a rapid molecular test relative to a gold standard diagnosis. For example, an APLM study might report: “At the optimized cutoff, the new assay had a sensitivity of 95% and specificity of 88% for detecting disease X” ￼. They will also report PPV and NPV if the study design warrants, and often discuss how results might vary with disease prevalence (a reflection of Bayesian conditional probability thinking, though usually not explicitly labeled Bayesian). ROC curves are frequently used to illustrate and quantify test performance; an APLM article evaluating a quantitative biomarker will typically include an ROC curve with AUC value, possibly comparing AUCs between different models or markers. Moreover, method comparison statistics are big in lab medicine: one finds correlation coefficients (Pearson’s r) between a new lab test and an established method, along with Bland-Altman plots to visualize agreement and any bias between methods (with mean difference and limits of agreement). The journal often expects authors to adhere to standards like reporting both sensitivity and specificity together ￼ and using ROC analysis for comprehensive test assessment ￼. Additionally, likelihood ratios can appear (particularly if a test is meant for ruling in or ruling out diagnoses), as they convey how many times more likely a positive (or negative) result is in diseased vs non-diseased persons. In the context of digital pathology or AI, APLM has published validation studies (e.g. AI for prostate biopsy diagnosis) which report these same metrics plus improvements in pathologist performance (e.g. “with AI assistance, pathologists improved their sensitivity and specificity by X%” ￼). Finally, kappa statistics are frequently encountered in APLM, especially for studies of diagnostic reproducibility or multi-reader trials. Since pathology often involves subjective interpretation, APLM papers evaluating a new grading scheme or classification will report inter-rater agreement (kappa) among pathologists ￼. In summary, diagnostic accuracy and agreement measures are arguably the defining statistical category for APLM, given its focus on validating and improving diagnostic tools in pathology.
 • Non-Parametric Methods: APLM authors use non-parametric tests in scenarios similar to other journals, with perhaps additional emphasis in lab studies where data may not follow normal distributions. For example, a study measuring enzyme levels might find a skewed distribution and choose a Mann–Whitney U test to compare median levels between patient groups. If evaluating multiple methods or conditions with non-normal data, a Kruskal–Wallis test could be used. In proficiency testing or interlaboratory comparisons published in APLM, data might be non-parametric (like ordinal scores of specimen adequacy), prompting the use of rank-based tests. Another common use is in quality improvement studies – e.g. comparing pre- vs post-intervention error rates with a paired non-parametric test if the number of observations is small. Wilcoxon signed-rank tests might be applied for paired design comparisons (such as the performance of the same labs before and after an intervention). Non-parametric correlation (Spearman’s rho) could be used in APLM when comparing rankings (for instance, correlation between two pathologists’ ordinal ratings). Although the majority of statistical tests in APLM likely remain parametric (owing to reasonable sample sizes and interest in means), the journal does not shy away from non-parametric approaches if they better fit the data. This is consistent with sound statistical practice: indeed, one analysis emphasizes using the appropriate test depending on data level and distribution ￼. APLM’s methodological rigor means that authors will often explicitly mention checking distributions and applying non-parametric methods accordingly, ensuring that their inferences (especially in critical diagnostic studies) are reliable.
 • Advanced and Specialized Methods: APLM’s range of content means it sometimes includes advanced statistical concepts, particularly in the realm of laboratory medicine and informatics. Bayesian statistics occasionally feature in APLM discussions, especially regarding predictive value and probability. For example, an APLM article might include a Bayesian perspective when discussing how post-test probability of disease changes with test results given pre-test odds (even if not doing a formal Bayesian analysis, the interpretation is Bayesian in spirit). In some laboratory modeling papers or clinical trial contexts, APLM might present Bayesian confidence intervals (credible intervals) or Bayesian updating of diagnostic probabilities, aligning with a broader movement in medicine to understand tests beyond simple sensitivity/specificity ￼. Machine learning and data science have also appeared in APLM – for instance, articles on digital pathology algorithms for image classification or on using big data to predict lab test utilization. These studies incorporate techniques like training/test dataset evaluation, cross-validation, and use performance stats we discussed (AUC, etc.). APLM has even published on topics such as the potential of machine learning in pathology practice ￼, reflecting the CAP’s interest in AI. Quality control statistics are another specialized area: control charts, sigma metrics, and other QC indices may be reported in lab-focused papers (these are statistical but tailored to lab process performance). Additionally, APLM’s broad scope can include epidemiological statistics if a study covers population pathology trends (e.g. incidence rates, confidence intervals, maybe even multivariate risk modeling across populations). In summary, APLM embraces advanced methods as needed – whether it’s leveraging Bayesian approaches for interpretation of diagnostic tests or incorporating modern machine learning validations – but always within a framework of improving pathology and laboratory practice. Its meta-research (like the 2017 statistical literacy survey ￼) highlights how the journal is also self-reflective in improving statistical use and training in the pathology community.

⸻

Sources:
 • Schmidt et al., Arch Pathol Lab Med 2017 – Survey of statistical methods in 1100 pathology articles (identified 18 common tests; e.g. chi-square in ~47%, t-test 33%, ANOVA 23%, logistic ~17%) ￼. This audit found statistical analysis in 81% of papers, ranging from 61% (Modern Pathology) to 98% (Am J Pathology) across journals ￼, and noted that mastering ~12 key tests could cover most needs ￼. Basic/translational journals tend to use more survival and kappa statistics, whereas cytopathology journals rely more on categorical tests ￼.
 • Modern Pathology: Example uses of survival analysis (Kaplan–Meier, log-rank) ￼ and group comparisons (chi-square, Wilcoxon) in a translational study ￼. CAP guidelines emphasize diagnostic test accuracy design (sensitivity, specificity) for diagnostic studies ￼. Emerging AI applications achieve high sensitivity/specificity (AUC ~0.89) for pathology tasks ￼.
 • AJSP/Histopathology: Standard use of χ², t, ANOVA, etc. (common across pathology journals) ￼. Frequent integration of Cox models and Kaplan–Meier for prognostic studies. Kappa often reported for new classification reproducibility ￼. Emphasis on appropriate parametric vs non-parametric test choice ￼.
 • AJP: Nearly universal stats usage ￼, reflecting experimental study designs always analyzed with at least t-tests or ANOVA. Less focus on diagnostic metrics, more on experimental comparisons. Still employs survival analysis when bridging to human data ￼. Primer articles stress proper design and analysis, including survival, correlation, and genetic data stats ￼.
 • APLM: High frequency of diagnostic accuracy statistics (sensitivity, specificity, PPV/NPV, ROC AUC) in lab test evaluation studies ￼. Many interobserver studies using kappa ￼. Advocacy for combined reporting of sensitivity & specificity and use of ROC for test assessments ￼. Example: Alzheimer type II astrocyte study in APLM reporting sensitivity 85.7%, specificity 68.6% for a histologic finding ￼. Machine learning validations in APLM also report these metrics, showing integration of new methods with traditional stats ￼.



