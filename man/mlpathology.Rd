% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mlpathology.h.R
\name{mlpathology}
\alias{mlpathology}
\title{Classification Performance Metrics for Digital Pathology}
\usage{
mlpathology(
  data,
  analysis_type = "classification",
  actual_labels,
  predicted_labels,
  predicted_probabilities,
  reference_segmentation,
  predicted_segmentation,
  model1_predictions,
  model2_predictions,
  model1_probabilities,
  model2_probabilities,
  roc_analysis = TRUE,
  roc_comparison = FALSE,
  confidence_level = 0.95,
  confusion_matrix_plot = TRUE,
  roc_plot = TRUE,
  bootstrap_validation = FALSE,
  bootstrap_runs = 1000
)
}
\arguments{
\item{data}{the data as a data frame}

\item{analysis_type}{Type of performance analysis to conduct}

\item{actual_labels}{True/actual classification labels}

\item{predicted_labels}{Predicted classification labels from model}

\item{predicted_probabilities}{Predicted probabilities for ROC analysis
(binary classification)}

\item{reference_segmentation}{Reference/ground truth segmentation masks
(binary)}

\item{predicted_segmentation}{Predicted segmentation masks from model
(binary)}

\item{model1_predictions}{Predictions from first model for comparison}

\item{model2_predictions}{Predictions from second model for comparison}

\item{model1_probabilities}{Probabilities from first model for ROC
comparison}

\item{model2_probabilities}{Probabilities from second model for ROC
comparison}

\item{roc_analysis}{Perform ROC curve analysis for binary classification}

\item{roc_comparison}{Compare ROC curves between two models using DeLong's
test}

\item{confidence_level}{Confidence level for performance metrics}

\item{confusion_matrix_plot}{Generate confusion matrix heatmap}

\item{roc_plot}{Generate ROC curve plot}

\item{bootstrap_validation}{Use bootstrap sampling for confidence intervals}

\item{bootstrap_runs}{Number of bootstrap replicates for validation}
}
\value{
A results object containing:
\tabular{llllll}{
\code{results$instructions} \tab \tab \tab \tab \tab a html \cr
\code{results$confusionmatrix} \tab \tab \tab \tab \tab a table \cr
\code{results$performancemetrics} \tab \tab \tab \tab \tab a table \cr
\code{results$rocanalysis} \tab \tab \tab \tab \tab a table \cr
\code{results$segmentationmetrics} \tab \tab \tab \tab \tab a table \cr
\code{results$modelcomparison} \tab \tab \tab \tab \tab a table \cr
\code{results$roccomparison} \tab \tab \tab \tab \tab a table \cr
\code{results$confusionmatrixplot} \tab \tab \tab \tab \tab an image \cr
\code{results$rocplot} \tab \tab \tab \tab \tab an image \cr
\code{results$interpretation} \tab \tab \tab \tab \tab a html \cr
}

Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:

\code{results$confusionmatrix$asDF}

\code{as.data.frame(results$confusionmatrix)}
}
\description{
Comprehensive evaluation of machine learning models and algorithms for
digital pathology applications. Provides classification metrics, ROC
analysis,
segmentation quality assessment, and statistical model comparison for AI
validation and algorithm comparison studies.
}
\examples{
data('classification_results')

mlpathology(data = classification_results,
           analysis_type = 'classification',
           actual_labels = actual,
           predicted_labels = predicted,
           predicted_probabilities = prob)

}
