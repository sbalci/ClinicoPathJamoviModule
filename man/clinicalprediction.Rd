% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clinicalprediction.h.R
\name{clinicalprediction}
\alias{clinicalprediction}
\title{Clinical Prediction Models & ML Interpretability}
\usage{
clinicalprediction(
  data,
  outcome_var,
  predictor_vars,
  patient_id,
  time_var,
  event_var,
  stratify_var,
  model_type = "random_forest",
  problem_type = "classification",
  outcome_type = "binary",
  feature_selection = TRUE,
  selection_method = "recursive_fe",
  feature_engineering = TRUE,
  handle_missing = "mice_imputation",
  train_proportion = 0.7,
  validation_method = "cv_10fold",
  hyperparameter_tuning = TRUE,
  tuning_method = "random_search",
  random_seed = 42,
  interpretability = TRUE,
  shap_analysis = TRUE,
  lime_analysis = FALSE,
  permutation_importance = TRUE,
  partial_dependence = TRUE,
  individual_explanations = FALSE,
  n_explanations = 10,
  performance_metrics = TRUE,
  calibration_analysis = TRUE,
  clinical_metrics = TRUE,
  roc_analysis = TRUE,
  threshold_optimization = TRUE,
  compare_models = FALSE,
  baseline_models = TRUE,
  ensemble_models = FALSE,
  risk_stratification = TRUE,
  n_risk_groups = 3,
  nomogram = TRUE,
  decision_curve = TRUE,
  external_validation = TRUE,
  bootstrap_ci = 1000,
  stability_analysis = TRUE,
  bias_analysis = TRUE,
  detailed_output = TRUE,
  clinical_report = TRUE,
  save_model = FALSE,
  export_predictions = FALSE,
  regulatory_documentation = TRUE
)
}
\arguments{
\item{data}{the data as a data frame}

\item{outcome_var}{Target variable for prediction (binary, continuous, or
survival)}

\item{predictor_vars}{Variables to use as predictors in the model}

\item{patient_id}{Patient identifier for tracking predictions}

\item{time_var}{Time to event variable for survival prediction models}

\item{event_var}{Event indicator for survival prediction models}

\item{stratify_var}{Variable for stratified sampling and validation}

\item{model_type}{Type of machine learning model to fit}

\item{problem_type}{Type of prediction problem}

\item{outcome_type}{Specific type of outcome variable}

\item{feature_selection}{Perform automated feature selection}

\item{selection_method}{Method for automatic feature selection}

\item{feature_engineering}{Perform automated feature engineering}

\item{handle_missing}{Method for handling missing data}

\item{train_proportion}{Proportion of data for training (70\\% = 0.7)}

\item{validation_method}{Method for model validation}

\item{hyperparameter_tuning}{Perform automated hyperparameter optimization}

\item{tuning_method}{Method for hyperparameter tuning}

\item{random_seed}{Random seed for reproducibility}

\item{interpretability}{Generate model interpretability analysis}

\item{shap_analysis}{Generate SHAP (SHapley Additive exPlanations) values}

\item{lime_analysis}{Generate LIME (Local Interpretable Model-agnostic
Explanations)}

\item{permutation_importance}{Calculate permutation feature importance}

\item{partial_dependence}{Generate partial dependence plots for key
features}

\item{individual_explanations}{Explain individual predictions using
SHAP/LIME}

\item{n_explanations}{Number of individual predictions to explain in detail}

\item{performance_metrics}{Calculate comprehensive performance metrics}

\item{calibration_analysis}{Assess model calibration}

\item{clinical_metrics}{Calculate clinical decision analysis metrics}

\item{roc_analysis}{Perform ROC curve analysis with confidence intervals}

\item{threshold_optimization}{Optimize prediction threshold for clinical
use}

\item{compare_models}{Compare multiple model types}

\item{baseline_models}{Include simple baseline models for comparison}

\item{ensemble_models}{Create ensemble of best performing models}

\item{risk_stratification}{Create risk stratification groups}

\item{n_risk_groups}{Number of risk stratification groups (e.g.,
low/medium/high)}

\item{nomogram}{Create clinical nomogram for risk calculation}

\item{decision_curve}{Perform decision curve analysis for clinical utility}

\item{external_validation}{Prepare model for external validation}

\item{bootstrap_ci}{Number of bootstrap samples for confidence intervals}

\item{stability_analysis}{Assess model stability across different samples}

\item{bias_analysis}{Analyze model bias across demographic groups}

\item{detailed_output}{Include detailed model diagnostics and explanations}

\item{clinical_report}{Generate clinical interpretation report}

\item{save_model}{Save trained model for future predictions}

\item{export_predictions}{Export individual predictions with probabilities}

\item{regulatory_documentation}{Include documentation for regulatory
submission}
}
\value{
A results object containing:
\tabular{llllll}{
\code{results$overview} \tab \tab \tab \tab \tab a table \cr
\code{results$dataset_info} \tab \tab \tab \tab \tab a table \cr
\code{results$feature_selection_results} \tab \tab \tab \tab \tab a table \cr
\code{results$feature_engineering_summary} \tab \tab \tab \tab \tab a table \cr
\code{results$performance_summary} \tab \tab \tab \tab \tab a table \cr
\code{results$classification_metrics} \tab \tab \tab \tab \tab a table \cr
\code{results$survival_metrics} \tab \tab \tab \tab \tab a table \cr
\code{results$feature_importance} \tab \tab \tab \tab \tab a table \cr
\code{results$shap_summary} \tab \tab \tab \tab \tab a table \cr
\code{results$individual_explanations} \tab \tab \tab \tab \tab a table \cr
\code{results$model_comparison} \tab \tab \tab \tab \tab a table \cr
\code{results$risk_stratification} \tab \tab \tab \tab \tab a table \cr
\code{results$decision_curve_analysis} \tab \tab \tab \tab \tab a table \cr
\code{results$cross_validation_results} \tab \tab \tab \tab \tab a table \cr
\code{results$stability_analysis} \tab \tab \tab \tab \tab a table \cr
\code{results$bias_fairness_analysis} \tab \tab \tab \tab \tab a table \cr
\code{results$hyperparameter_results} \tab \tab \tab \tab \tab a table \cr
\code{results$clinical_interpretation} \tab \tab \tab \tab \tab a table \cr
\code{results$regulatory_summary} \tab \tab \tab \tab \tab a table \cr
\code{results$roc_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$calibration_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$feature_importance_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$shap_summary_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$shap_dependence_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$decision_curve_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$risk_distribution_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$model_comparison_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$stability_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$nomogram_plot} \tab \tab \tab \tab \tab an image \cr
}

Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:

\code{results$overview$asDF}

\code{as.data.frame(results$overview)}
}
\description{
Develop and validate clinical prediction models using machine learning
algorithms
with interpretability analysis. Includes comprehensive model comparison,
feature
selection, cross-validation, and explainable AI through SHAP and LIME
methods.
Designed for clinical research applications with regulatory compliance
features
for model validation and documentation.
}
\examples{
data('clinical_data')

clinicalprediction(
    data = clinical_data,
    outcome_var = "mortality",
    predictor_vars = c("age", "biomarker", "stage"),
    model_type = "random_forest",
    interpretability = TRUE,
    validation_method = "cv_10fold"
)

}
