% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/multiclassroc.h.R
\name{multiclassroc}
\alias{multiclassroc}
\title{Multi-class ROC Analysis}
\usage{
multiclassroc(
  data,
  outcome,
  predictors,
  method = "ovr",
  calculate_macro_auc = TRUE,
  calculate_micro_auc = TRUE,
  calculate_weighted_auc = TRUE,
  confidence_intervals = TRUE,
  ci_method = "bootstrap",
  bootstrap_samples = 1000,
  confidence_level = 0.95,
  pairwise_comparisons = FALSE,
  confusion_matrix = TRUE,
  class_metrics = TRUE,
  plot_roc_curves = TRUE,
  plot_method = "overlay",
  plot_diagonal = TRUE,
  random_seed = 42
)
}
\arguments{
\item{data}{the data as a data frame}

\item{outcome}{a string naming the outcome variable (must have 3+ levels)}

\item{predictors}{a vector of strings naming predictor variables
(continuous scores)}

\item{method}{method for multi-class ROC: 'ovr' (one class vs all others),
'ovo' (all pairwise comparisons), or 'multinomial' (global probability
model)}

\item{calculate_macro_auc}{calculate macro-average AUC across all classes
(unweighted mean)}

\item{calculate_micro_auc}{calculate micro-average AUC (aggregate all
predictions)}

\item{calculate_weighted_auc}{calculate weighted-average AUC (weighted by
class prevalence)}

\item{confidence_intervals}{calculate confidence intervals for AUC
estimates}

\item{ci_method}{method for confidence interval calculation}

\item{bootstrap_samples}{number of bootstrap samples for CI calculation}

\item{confidence_level}{confidence level for intervals (default: 0.95 for
95\\% CI)}

\item{pairwise_comparisons}{show detailed results for all pairwise class
comparisons (OvO method)}

\item{confusion_matrix}{show confusion matrix at optimal global threshold}

\item{class_metrics}{calculate sensitivity, specificity, PPV, NPV for each
class}

\item{plot_roc_curves}{plot ROC curves for each class}

\item{plot_method}{display method for ROC curves}

\item{plot_diagonal}{show diagonal reference line (random classifier)}

\item{random_seed}{random seed for reproducible bootstrap sampling}
}
\value{
A results object containing:
\tabular{llllll}{
\code{results$instructionsText} \tab \tab \tab \tab \tab a html \cr
\code{results$summaryTable} \tab \tab \tab \tab \tab a table \cr
\code{results$classAucTable} \tab \tab \tab \tab \tab a table \cr
\code{results$pairwiseTable} \tab \tab \tab \tab \tab a table \cr
\code{results$classMetricsTable} \tab \tab \tab \tab \tab a table \cr
\code{results$confusionMatrix} \tab \tab \tab \tab \tab a table \cr
\code{results$rocPlot} \tab \tab \tab \tab \tab an image \cr
\code{results$interpretationText} \tab \tab \tab \tab \tab a html \cr
}

Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:

\code{results$summaryTable$asDF}

\code{as.data.frame(results$summaryTable)}
}
\description{
Multi-class ROC Analysis for evaluating diagnostic performance with 3 or
more
diagnostic classes. This analysis extends traditional binary ROC to handle
multi-category outcomes using one-vs-rest, one-vs-one, and global
approaches.
}
\details{
Common applications include tumor subtype classification, disease staging
with
multiple levels, and AI model validation for multi-class predictions.
}
\examples{
# Example with tumor subtype classification
data <- data.frame(
  true_class = factor(sample(c("TypeA", "TypeB", "TypeC"), 100, replace=TRUE)),
  score_A = rnorm(100),
  score_B = rnorm(100),
  score_C = rnorm(100)
)

multiclassroc(
  data = data,
  outcome = 'true_class',
  predictors = c('score_A', 'score_B', 'score_C'),
  method = 'ovr',
  calculate_macro_auc = TRUE,
  confidence_intervals = TRUE
)

}
