% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tree.h.R
\name{tree}
\alias{tree}
\title{Medical Decision Tree Analysis}
\usage{
tree(
  data,
  vars = NULL,
  facs = NULL,
  target,
  targetLevel,
  algorithm = "rpart",
  tree_mode = "classification",
  train = NULL,
  trainLevel,
  validation = "cohort",
  consensus_validation = FALSE,
  bootstrap_samples = 100,
  model_averaging = FALSE,
  cv_folds = 5,
  cv_repeats = 3,
  stratified_sampling = TRUE,
  data_split_method = "stratified",
  test_split = 0.25,
  max_depth = 6,
  min_samples_split = 20,
  min_samples_leaf = 10,
  cost_complexity = 0.01,
  min_n = 20,
  tree_depth = 6,
  hyperparameter_tuning = FALSE,
  tuning_metric = "bacc",
  kappa_analysis = TRUE,
  advanced_metrics = FALSE,
  use_1se_rule = TRUE,
  xerror_pruning = FALSE,
  auto_prune = FALSE,
  prune_method = "one_se",
  rpart_prior = "",
  rpart_loss_matrix = "",
  clinical_loss_preset = "equal",
  enhanced_prior_probs = "data",
  population_prevalence = 0.1,
  custom_prior_values = "",
  rpart_split = "gini",
  rpart_surrogate = TRUE,
  rpart_usesurrogate = "2",
  rpart_maxsurrogate = 5,
  rpart_xval = 10,
  rpart_maxcompete = 4,
  c50_trials = 1,
  c50_winnow = FALSE,
  ctree_mincriterion = 0.95,
  rf_ntree = 500,
  rf_mtry = 0,
  xgb_nrounds = 100,
  xgb_eta = 0.3,
  set_seed = TRUE,
  seed_value = 42,
  show_cp_table = FALSE,
  show_variable_importance_detailed = FALSE,
  missing_data_method = "native",
  balanceClasses = FALSE,
  ensemble_method = "none",
  n_trees = 100,
  feature_selection = FALSE,
  feature_selection_method = "tree_importance",
  importance_method = "gini",
  show_tree_plot = TRUE,
  show_importance_plot = TRUE,
  show_performance_metrics = TRUE,
  show_confusion_matrix = TRUE,
  show_roc_curve = TRUE,
  show_validation_curves = FALSE,
  show_calibration_plot = FALSE,
  showPartitionPlot = FALSE,
  show_cp_plot = FALSE,
  tree_plot_style = "standard",
  plot_branch_style = 0.2,
  plot_margin = 0.1,
  show_node_statistics = FALSE,
  probability_display = TRUE,
  enhanced_node_info = "clinical",
  interpretability = FALSE,
  shap_analysis = FALSE,
  partial_dependence = FALSE,
  interaction_analysis = FALSE,
  clinical_context = "diagnosis",
  cost_sensitive_thresholds = FALSE,
  fn_fp_ratio = 1,
  prevalenceAdjustment = FALSE,
  expectedPrevalence = 10,
  bootstrap_confidence = FALSE,
  n_bootstrap = 1000,
  model_comparison = FALSE,
  modelComparisonMetric = "bacc",
  export_model = FALSE,
  exportPredictions = FALSE,
  show_clinical_interpretation = TRUE,
  model_stability_analysis = FALSE,
  learning_curves = FALSE,
  outlier_analysis = FALSE,
  prediction_intervals = FALSE,
  rpart_prediction_type = "class",
  show_rsq_plot = FALSE,
  competing_splits = FALSE,
  surrogate_splits = FALSE,
  advanced_pruning = "cp",
  pruning_validation_split = 0.2,
  cp_auto_selection = "one_se_rule",
  cp_sequence_analysis = FALSE,
  xerror_detailed_analysis = FALSE,
  impurity_analysis = FALSE,
  recursive_partitioning_trace = FALSE,
  use_custom_splitting = FALSE,
  custom_splitting_method = "custom_anova",
  custom_splitting_validation = TRUE,
  ensemble_diversity = FALSE,
  ensemble_size = 10,
  weighted_voting = FALSE,
  uncertainty_quantification = FALSE,
  calibration_analysis = FALSE,
  clinical_thresholds = FALSE,
  threshold_optimization = "youden",
  multi_threshold_analysis = FALSE,
  consensus_threshold = 0.6,
  stability_threshold = 0.8,
  advanced_pruning_method = "cost_complexity",
  pre_pruning_threshold = 0.01,
  post_pruning_validation_split = 0.2,
  rf_feature_selection_method = "importance_ranking",
  rf_proximity_analysis = FALSE,
  rf_oob_detailed_analysis = TRUE,
  algorithm_benchmarking = FALSE,
  benchmark_algorithms = "trees_only",
  performance_profiling = FALSE,
  adaptive_complexity_parameter = FALSE,
  dynamic_splitting_criteria = FALSE,
  tree_regularization_method = "none",
  regularization_strength = 0.1,
  automated_feature_engineering = FALSE,
  interaction_depth = 2,
  polynomial_degree = 2,
  fancy_tree_plot = FALSE,
  tree_structure_analysis = FALSE,
  cp_selection_visualization = FALSE,
  f1_score_analysis = FALSE,
  learning_curve_analysis = FALSE,
  residual_diagnostics = FALSE,
  hyperparameter_grid_search = FALSE,
  cross_validation_optimization = FALSE,
  ensemble_optimization = FALSE,
  surrogate_split_analysis = FALSE,
  missing_pattern_analysis = FALSE
)
}
\arguments{
\item{data}{The data as a data frame containing clinical variables,
biomarkers,  and patient outcomes for decision tree analysis.}

\item{vars}{Continuous variables such as biomarker levels, age,  laboratory
values, or quantitative pathological measurements.}

\item{facs}{Categorical variables such as tumor grade, stage,  histological
type, or patient demographics.}

\item{target}{Primary outcome variable: disease status, treatment response,
survival status, or diagnostic category.}

\item{targetLevel}{Level representing disease presence, positive outcome,
or event of interest for binary classification.}

\item{algorithm}{Algorithm to use: rpart provides traditional CART with
pruning; FFTrees creates simple, interpretable trees for medical decisions;
C5.0 offers advanced classification with boosting; ctree uses statistical
tests for splits; mob combines trees with parametric models; Random Forest
uses ensemble of trees for high accuracy; XGBoost provides gradient
boosting for complex patterns.}

\item{tree_mode}{Type of prediction problem: classification for disease
presence/absence, regression for continuous biomarkers, survival for
time-to-event analysis, Poisson for count/rate data, exponential for
survival with constant hazard.}

\item{train}{Variable indicating training vs validation cohorts.  If not
provided, data will be split automatically.}

\item{trainLevel}{Level indicating the training/discovery cohort.}

\item{validation}{Validation approach: cohort uses train variable if
provided, otherwise performs automatic splitting with selected method.
Stratified CV maintains class proportions, Repeated CV averages multiple
runs.}

\item{consensus_validation}{Use multiple validation methods and consensus
results. Combines cross-validation, bootstrap, and holdout for robust
estimates.}

\item{bootstrap_samples}{Number of bootstrap samples for bootstrap
validation. More samples provide better estimates but increase computation
time.}

\item{model_averaging}{Average predictions from multiple models for
improved accuracy. Combines different algorithms or parameter settings.}

\item{cv_folds}{Number of folds for cross-validation. 5-fold provides good
balance between bias and variance for clinical datasets.}

\item{cv_repeats}{Number of times to repeat cross-validation (for repeated
CV). More repeats provide more stable estimates but increase computation
time.}

\item{stratified_sampling}{Maintain class proportions in train/test splits.
Recommended for imbalanced medical datasets.}

\item{data_split_method}{Method for splitting data into train/test sets.
Stratified maintains original class proportions for clinical validity.}

\item{test_split}{Proportion of data reserved for testing (holdout
validation). Optimal ratio is 25\\% test / 75\\% train as recommended for
decision trees.}

\item{max_depth}{Maximum depth of decision tree. Deeper trees capture more
interactions but may overfit. Clinical trees typically 2-8 levels.}

\item{min_samples_split}{Minimum number of samples required to split a
node. Higher values prevent overfitting in clinical data.}

\item{min_samples_leaf}{Minimum number of samples in leaf nodes. Important
for clinical validity - too few samples reduce reliability.}

\item{cost_complexity}{Cost complexity parameter (tidymodels:
cost_complexity). Controls pruning -  lower values create more complex
trees. Corresponds to CP in rpart.}

\item{min_n}{Minimum number of data points in a node (tidymodels: min_n).
Higher values prevent overfitting in clinical data.}

\item{tree_depth}{Maximum tree depth (tidymodels: tree_depth). Deeper trees
capture  more interactions but may overfit. Clinical trees typically 2-8
levels.}

\item{hyperparameter_tuning}{Automatically optimize tree parameters using
cross-validation. Finds optimal complexity parameter and tree structure for
best performance.}

\item{tuning_metric}{Metric to optimize during hyperparameter tuning.
Choose based on clinical priorities (e.g., sensitivity for screening).}

\item{kappa_analysis}{Calculate Cohen's kappa statistic for agreement
beyond chance. Essential clinical metric for inter-rater reliability
assessment.}

\item{advanced_metrics}{Calculate advanced metrics: Matthews correlation
coefficient,  Youden's J statistic, diagnostic odds ratio, and clinical
utility index.}

\item{use_1se_rule}{Apply 1-standard-error rule for selecting simpler
models. Chooses most parsimonious tree within 1 SE of optimal performance.}

\item{xerror_pruning}{Use cross-validation error (xerror) from CP table for
optimal pruning. Automatically selects CP value that minimizes xerror.}

\item{auto_prune}{Automatically prune tree to optimal size based on
cross-validation. Prevents overfitting while maintaining predictive
performance.}

\item{prune_method}{Method for selecting optimal tree size after
cross-validation. 1-SE rule provides good balance between accuracy and
simplicity.}

\item{rpart_prior}{Prior probabilities for each class (comma-separated).
E.g., "0.3,0.7" for binary classification. Leave empty for data
proportions.}

\item{rpart_loss_matrix}{Loss matrix for misclassification costs
(comma-separated by rows). E.g., "0,1,5,0" for 2x2 matrix. Leave empty for
equal costs.}

\item{clinical_loss_preset}{Pre-configured loss matrices for common
clinical scenarios. Screening: False negatives cost 5x more than false
positives. Diagnosis: False positives cost 3x more than false negatives.}

\item{enhanced_prior_probs}{Prior probability settings for different
clinical contexts. Population: Use external disease prevalence estimates.
Balanced: Equal priors regardless of sample sizes.}

\item{population_prevalence}{Expected disease prevalence in target
population (0-1). Used when enhanced_prior_probs = "population".}

\item{custom_prior_values}{Custom prior probabilities (comma-separated,
must sum to 1). E.g., "0.2,0.3,0.5" for three-class problem.}

\item{rpart_split}{Splitting criterion for classification trees. Gini often
works well; Information gain may be better for multi-class.}

\item{rpart_surrogate}{Use surrogate splits to handle missing values. Finds
backup splits that mimic primary split when data is missing.}

\item{rpart_usesurrogate}{How to use surrogate splits: 0=only if helpful,
1=always, 2=if better than majority.}

\item{rpart_maxsurrogate}{Maximum number of surrogate splits to retain at
each node. More surrogates provide better missing data handling but
increase complexity.}

\item{rpart_xval}{Number of cross-validation folds for CP table generation.
Set to 0 to skip cross-validation (faster but less reliable pruning).}

\item{rpart_maxcompete}{Number of competing splits to save for each node.
Useful for understanding alternative splitting strategies.}

\item{c50_trials}{Number of boosting iterations for C5.0 algorithm. More
trials improve accuracy but reduce interpretability.}

\item{c50_winnow}{Enable winnowing in C5.0 to remove irrelevant attributes.
Useful for high-dimensional clinical data.}

\item{ctree_mincriterion}{Statistical criterion for ctree splits (1 -
p-value threshold). Higher values create simpler, more conservative trees.}

\item{rf_ntree}{Number of trees in random forest. More trees generally
improve performance but increase computation time.}

\item{rf_mtry}{Number of variables randomly sampled at each split. 0 =
automatic selection (sqrt for classification, p/3 for regression).}

\item{xgb_nrounds}{Number of boosting rounds for XGBoost. More rounds can
improve performance but risk overfitting.}

\item{xgb_eta}{Learning rate for XGBoost. Lower values require more rounds
but can lead to better performance.}

\item{set_seed}{Set random seed for reproducible results across runs.
Essential for clinical research reproducibility.}

\item{seed_value}{Specific seed value for random number generation. Use
same value to reproduce exact results.}

\item{show_cp_table}{Display CP table showing tree complexity vs
performance. Helps understand pruning decisions and model selection.}

\item{show_variable_importance_detailed}{Display comprehensive variable
importance analysis including surrogate splits and interaction effects.}

\item{missing_data_method}{Method for handling missing clinical data.
Native rpart handling  uses surrogate splits, which is often optimal for
clinical data.}

\item{balanceClasses}{Balance classes to handle rare diseases or imbalanced
outcomes.  Recommended for disease prevalence <20\\%.}

\item{ensemble_method}{Ensemble method to improve prediction accuracy and
robustness. Single trees are most interpretable; ensembles offer better
performance.}

\item{n_trees}{Number of trees in ensemble methods. More trees generally
improve  performance but increase computation time.}

\item{feature_selection}{Perform automated feature selection using advanced
algorithms. Helps identify most relevant clinical variables and biomarkers.}

\item{feature_selection_method}{Method for feature selection: Tree-based
uses rpart importance; Boruta identifies all-relevant features using
permutation tests; Variable Importance uses advanced metrics from caret
package.}

\item{importance_method}{Method for calculating feature importance.
Permutation and SHAP provide more reliable importance for clinical
interpretation.}

\item{show_tree_plot}{Display visual representation of the decision tree.
Shows decision paths and node information.}

\item{show_importance_plot}{Display feature importance rankings. Critical
for understanding which clinical variables drive predictions.}

\item{show_performance_metrics}{Display comprehensive performance
evaluation including accuracy, sensitivity, specificity, AUC, and clinical
metrics.}

\item{show_confusion_matrix}{Display detailed confusion matrix with
clinical interpretations. Shows actual vs predicted classifications.}

\item{show_roc_curve}{Display ROC curve analysis for binary classification.
Essential for clinical decision making and threshold selection.}

\item{show_validation_curves}{Display learning curves and validation
performance. Helps assess overfitting and training adequacy.}

\item{show_calibration_plot}{Display probability calibration plot.
Important for clinical applications requiring reliable probability
estimates.}

\item{showPartitionPlot}{Display 2D decision boundary visualization using
parttree.  Requires exactly 2 continuous variables for optimal
visualization.}

\item{show_cp_plot}{Display CP plot showing cross-validation error vs tree
complexity. Essential for understanding optimal pruning levels.}

\item{tree_plot_style}{Visualization style optimized for different clinical
audiences. Medical: simplified for clinical staff; Clinical: detailed for
researchers. Uniform: equal branch lengths; Compressed: space-efficient;
Fancy: publication-ready.}

\item{plot_branch_style}{Branch drawing style (0-1). 0=angled branches,
1=straight lines. Based on rpart vignette examples for publication-quality
plots.}

\item{plot_margin}{White space margin around the tree plot. Useful for
fitting node labels and avoiding clipping.}

\item{show_node_statistics}{Display detailed statistics for each node
including sample sizes, purity measures, and class distributions.}

\item{probability_display}{Display class probabilities in tree nodes for
clinical interpretation. Shows certainty levels for each prediction.}

\item{enhanced_node_info}{Level of information displayed in tree nodes.
Clinical mode optimized for medical decision making.}

\item{interpretability}{Perform advanced interpretability analysis
including SHAP values, partial dependence plots, and interaction effects.}

\item{shap_analysis}{Calculate SHAP (SHapley Additive exPlanations) values
for individual prediction explanations. Powerful for clinical decision
support.}

\item{partial_dependence}{Show how individual features affect predictions
across their value ranges. Helps understand clinical relationships.}

\item{interaction_analysis}{Analyze interactions between clinical
variables. Important for understanding combined effects of biomarkers.}

\item{clinical_context}{Clinical application context. Affects performance
thresholds, interpretation guidelines, and visualization emphasis.}

\item{cost_sensitive_thresholds}{Optimize decision thresholds considering
clinical costs of false positives vs false negatives.}

\item{fn_fp_ratio}{Relative cost of missing a positive case vs false alarm.
Screening (high ratio), confirmation tests (low ratio).}

\item{prevalenceAdjustment}{Adjust predictive values for expected disease
prevalence  in target population (different from study sample).}

\item{expectedPrevalence}{Expected disease prevalence in target population
for  adjusted predictive value calculations.}

\item{bootstrap_confidence}{Calculate bootstrap confidence intervals for
performance metrics. Provides uncertainty quantification for clinical
reporting.}

\item{n_bootstrap}{Number of bootstrap samples for confidence interval
calculation. More samples provide better estimates but increase computation
time.}

\item{model_comparison}{Compare performance of multiple algorithms
(FFTrees, CART, Logistic Regression). Useful for selecting the best
approach for your data.}

\item{modelComparisonMetric}{Primary metric for comparing algorithms.
Choose based on clinical priorities (sensitivity for screening, specificity
for confirmation).}

\item{export_model}{Export the trained model for external use or
deployment. Useful for clinical decision support system integration.}

\item{exportPredictions}{Add predicted classifications and probabilities to
the dataset for further analysis or reporting.}

\item{show_clinical_interpretation}{Display comprehensive clinical
interpretation guidelines specific to the selected clinical context and
results.}

\item{model_stability_analysis}{Analyze model stability across bootstrap
samples by examining consistency of splits, variable selection, and
predictions.}

\item{learning_curves}{Display learning curves showing performance vs
training size. Helps determine optimal sample size and detect overfitting.}

\item{outlier_analysis}{Identify influential observations and outliers that
may disproportionately affect tree structure and predictions.}

\item{prediction_intervals}{Calculate confidence intervals for individual
predictions using bootstrap or cross-validation methods.}

\item{rpart_prediction_type}{Type of prediction output from rpart model.
Class: predicted category; Prob: class probabilities; Vector: node IDs.}

\item{show_rsq_plot}{Show rsq.rpart() plot displaying R-squared vs tree
size. Useful for regression trees to assess explained variance.}

\item{competing_splits}{Display competing splits at each node showing
alternative  splitting criteria and their relative quality.}

\item{surrogate_splits}{Display surrogate splits used for missing data
handling. Shows backup splitting rules when primary variable is missing.}

\item{advanced_pruning}{Pruning method: CP uses cross-validation error, REP
uses holdout validation, MEP considers both error and tree size for optimal
clinical interpretability.}

\item{pruning_validation_split}{Proportion of data reserved for pruning
validation (REP/MEP methods). This is separate from the main test set.}

\item{cp_auto_selection}{Automatic selection of optimal complexity
parameter from CV results. 1-SE rule selects simplest tree within one
standard error of minimum.}

\item{cp_sequence_analysis}{Show detailed analysis of CP sequence with
error rates and tree sizes. Helps understand cost-complexity trade-offs.}

\item{xerror_detailed_analysis}{Show comprehensive xerror analysis with
standard errors and confidence intervals. Essential for understanding
pruning decisions.}

\item{impurity_analysis}{Compare Gini index vs Information gain splitting
criteria. Shows impurity reduction at each split for method comparison.}

\item{recursive_partitioning_trace}{Display step-by-step tree construction
process. Shows how the algorithm selects splits recursively.}

\item{use_custom_splitting}{Enable user-defined splitting functions for
advanced customization. Allows definition of custom init, eval, and split
functions.}

\item{custom_splitting_method}{Pre-defined custom splitting methods based
on rpart vignette examples. Custom methods provide enhanced splitting
criteria for specific domains.}

\item{custom_splitting_validation}{Validate custom splitting functions
before use. Ensures functions meet rpart requirements (init, eval, split
components).}

\item{ensemble_diversity}{Enhance ensemble diversity through parameter
variation. Creates diverse base learners for improved ensemble performance.}

\item{ensemble_size}{Number of base models in ensemble methods. More models
generally improve performance but increase computation.}

\item{weighted_voting}{Use performance-weighted voting in ensemble methods.
Better models get higher weights in final predictions.}

\item{uncertainty_quantification}{Quantify prediction uncertainty for
clinical decision support. Provides confidence intervals and uncertainty
estimates.}

\item{calibration_analysis}{Analyze and display probability calibration for
clinical reliability. Essential for models providing probability estimates.}

\item{clinical_thresholds}{Optimize decision thresholds for clinical
contexts. Balances sensitivity and specificity based on clinical
priorities.}

\item{threshold_optimization}{Method for optimizing classification
thresholds. Youden's J maximizes sensitivity + specificity - 1.}

\item{multi_threshold_analysis}{Analyze performance across multiple
decision thresholds. Shows trade-offs between sensitivity and specificity.}

\item{consensus_threshold}{Minimum agreement threshold for consensus
predictions. Higher values require more model agreement for final
decisions.}

\item{stability_threshold}{Minimum stability coefficient for model
acceptance. Higher values indicate more consistent models across samples.}

\item{advanced_pruning_method}{Advanced pruning method for optimal tree
size. Pre-pruning stops early, post-pruning removes branches afterward.}

\item{pre_pruning_threshold}{Minimum improvement threshold for pre-pruning.
Higher values create simpler, more conservative trees.}

\item{post_pruning_validation_split}{Proportion of training data reserved
for post-pruning validation. Used in reduced error pruning methods.}

\item{rf_feature_selection_method}{Method for selecting important features
in Random Forest. Boruta finds all-relevant features using statistical
tests.}

\item{rf_proximity_analysis}{Calculate proximity matrix for outlier
detection and clustering. Useful for understanding data structure in RF
models.}

\item{rf_oob_detailed_analysis}{Comprehensive out-of-bag error analysis
with confidence intervals. Provides unbiased performance estimates.}

\item{algorithm_benchmarking}{Compare tree performance against linear
models and clustering. Provides comprehensive algorithm comparison.}

\item{benchmark_algorithms}{Scope of algorithm comparison analysis.
Comprehensive includes logistic regression and k-means.}

\item{performance_profiling}{Profile algorithm performance including timing
and memory usage. Useful for production deployment decisions.}

\item{adaptive_complexity_parameter}{Automatically adapt CP based on data
characteristics. Uses data-driven approach for optimal tree complexity.}

\item{dynamic_splitting_criteria}{Use different splitting criteria at
different tree levels. Combines Gini and information gain adaptively.}

\item{tree_regularization_method}{Regularization method to prevent
overfitting. Different methods penalize complexity differently.}

\item{regularization_strength}{Strength of regularization penalty. Higher
values create simpler trees.}

\item{automated_feature_engineering}{Automatically create interaction terms
and transformations. Can improve tree performance for complex
relationships.}

\item{interaction_depth}{Maximum depth for automatic interaction terms. 2 =
pairwise, 3 = three-way interactions.}

\item{polynomial_degree}{Degree of polynomial features to create. Higher
degrees capture more complex non-linearities.}

\item{fancy_tree_plot}{Use rattle's fancyRpartPlot for enhanced tree
visualization. Provides publication-quality tree diagrams.}

\item{tree_structure_analysis}{Detailed analysis of tree structure
including node statistics, split quality measures, and branch complexity
metrics.}

\item{cp_selection_visualization}{Visualize complexity parameter selection
with xerror plots. Shows cross-validation error vs tree complexity.}

\item{f1_score_analysis}{Calculate F1 scores for all classes with
macro/micro averaging. Essential for imbalanced classification problems.}

\item{learning_curve_analysis}{Generate learning curves showing performance
vs sample size. Identifies optimal training size and overfitting patterns.}

\item{residual_diagnostics}{Comprehensive residual analysis for regression
trees. Includes normality tests and homoscedasticity checks.}

\item{hyperparameter_grid_search}{Systematic grid search over cp, maxdepth,
minsplit, minbucket. Finds optimal parameter combinations through
exhaustive search.}

\item{cross_validation_optimization}{Use cross-validation for robust
hyperparameter selection. Prevents overfitting to specific train-test
splits.}

\item{ensemble_optimization}{Optimize ensemble parameters for improved
performance. Includes optimal ensemble size and diversity measures.}

\item{surrogate_split_analysis}{Detailed analysis of surrogate splits for
missing data handling. Shows backup splitting rules and their
effectiveness.}

\item{missing_pattern_analysis}{Analyze patterns of missingness in the
dataset. Identifies MCAR, MAR, and MNAR mechanisms.}
}
\value{
A results object containing:
\tabular{llllll}{
\code{results$todo} \tab \tab \tab \tab \tab a html \cr
\code{results$text1} \tab \tab \tab \tab \tab a html \cr
\code{results$progress_feedback} \tab \tab \tab \tab \tab a html \cr
\code{results$model_summary} \tab \tab \tab \tab \tab a html \cr
\code{results$performance_table} \tab \tab \tab \tab \tab a table \cr
\code{results$clinicalMetricsTable} \tab \tab \tab \tab \tab a table \cr
\code{results$performance_table_explanation} \tab \tab \tab \tab \tab a html \cr
\code{results$confusion_matrix} \tab \tab \tab \tab \tab a html \cr
\code{results$confusion_matrix_explanation} \tab \tab \tab \tab \tab a html \cr
\code{results$confusion_matrix_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$tree_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$tree_plot_explanation} \tab \tab \tab \tab \tab a html \cr
\code{results$partitionPlot} \tab \tab \tab \tab \tab an image \cr
\code{results$importance_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$importance_plot_explanation} \tab \tab \tab \tab \tab a html \cr
\code{results$featureImportanceTable} \tab \tab \tab \tab \tab a table \cr
\code{results$roc_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$roc_plot_explanation} \tab \tab \tab \tab \tab a html \cr
\code{results$validation_curves} \tab \tab \tab \tab \tab an image \cr
\code{results$calibration_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$shap_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$partial_dependence_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$interaction_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$clinical_interpretation} \tab \tab \tab \tab \tab a html \cr
\code{results$clinicalInterpretation} \tab \tab \tab \tab \tab a html \cr
\code{results$riskStratification} \tab \tab \tab \tab \tab a html \cr
\code{results$feature_selection_results} \tab \tab \tab \tab \tab a html \cr
\code{results$bootstrap_intervals} \tab \tab \tab \tab \tab a html \cr
\code{results$crossValidationTable} \tab \tab \tab \tab \tab a table \cr
\code{results$bootstrapTable} \tab \tab \tab \tab \tab a table \cr
\code{results$modelComparison} \tab \tab \tab \tab \tab a table \cr
\code{results$cp_table_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$cp_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$rsq_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$detailed_importance_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$competing_splits_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$surrogate_splits_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$model_export} \tab \tab \tab \tab \tab a html \cr
\code{results$exportInfo} \tab \tab \tab \tab \tab a html \cr
\code{results$stability_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$stability_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$learning_curves_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$outlier_analysis_results} \tab \tab \tab \tab \tab a html \cr
\code{results$outlier_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$prediction_intervals_table} \tab \tab \tab \tab \tab a table \cr
\code{results$pruning_analysis} \tab \tab \tab \tab \tab a html \cr
\code{results$enhanced_cv_results} \tab \tab \tab \tab \tab a html \cr
\code{results$enhanced_cv_table} \tab \tab \tab \tab \tab a table \cr
\code{results$cp_sequence_analysis_results} \tab \tab \tab \tab \tab a html \cr
\code{results$xerror_detailed_analysis_results} \tab \tab \tab \tab \tab a html \cr
\code{results$impurity_analysis_results} \tab \tab \tab \tab \tab a html \cr
\code{results$recursive_partitioning_trace_results} \tab \tab \tab \tab \tab a html \cr
\code{results$xerror_confidence_plot} \tab \tab \tab \tab \tab an image \cr
\code{results$enhanced_confusion_matrix} \tab \tab \tab \tab \tab a html \cr
}

Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:

\code{results$performance_table$asDF}

\code{as.data.frame(results$performance_table)}
}
\description{
Comprehensive decision tree analysis for medical research, pathology and
oncology.
Combines FFTrees (Fast-and-Frugal Trees) and enhanced CART algorithms for
robust
clinical decision support. Provides extensive validation, performance
metrics,
interpretability analysis, and clinical interpretation guidelines.
}
\examples{
# Example for cancer diagnosis with comprehensive analysis
data(cancer_biomarkers)
tree(
    data = cancer_biomarkers,
    vars = c("PSA", "age", "tumor_size"),
    facs = c("grade", "stage"),
    target = "diagnosis",
    targetLevel = "cancer",
    algorithm = "fftrees",
    validation = "cv",
    show_performance_metrics = TRUE,
    show_tree_plot = TRUE,
    interpretability = TRUE
)

}
