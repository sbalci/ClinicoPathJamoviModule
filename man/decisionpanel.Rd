% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/decisionpanel.h.R
\name{decisionpanel}
\alias{decisionpanel}
\title{Decision Panel Optimization}
\usage{
decisionpanel(
  data,
  test1,
  test1Positive,
  test2,
  test2Positive,
  test3,
  test3Positive,
  test4,
  test4Positive,
  test5,
  test5Positive,
  gold,
  goldPositive,
  useCosts = FALSE,
  testCosts = "",
  fpCost = 100,
  fnCost = 1000,
  strategies = "all",
  parallelRules = "any",
  customThreshold = 2,
  maxTests = 3,
  sequentialStop = "positive",
  optimizationCriteria = "accuracy",
  panelOptimization = "forward",
  minImprovement = 0.01,
  redundancyThreshold = 0.7,
  minSensitivity = 0.8,
  minSpecificity = 0.8,
  createTree = FALSE,
  treeMethod = "costSensitive",
  maxDepth = 5,
  minSplit = 20,
  showAllCombinations = FALSE,
  topN = 10,
  compareStrategies = TRUE,
  bootstrap = FALSE,
  bootReps = 1000,
  plotTree = TRUE,
  plotComparison = TRUE,
  plotCostEffect = TRUE,
  plotROC = FALSE,
  prevalence = 0,
  crossValidate = FALSE,
  nFolds = 5,
  seed = 12345,
  showProgress = TRUE
)
}
\arguments{
\item{data}{The data as a data frame.}

\item{test1}{First diagnostic test variable.}

\item{test1Positive}{The positive level for Test 1.}

\item{test2}{Second diagnostic test variable.}

\item{test2Positive}{The positive level for Test 2.}

\item{test3}{Third diagnostic test variable (optional).}

\item{test3Positive}{The positive level for Test 3.}

\item{test4}{Fourth diagnostic test variable (optional).}

\item{test4Positive}{The positive level for Test 4.}

\item{test5}{Fifth diagnostic test variable (optional).}

\item{test5Positive}{The positive level for Test 5.}

\item{gold}{The gold standard variable for disease classification.}

\item{goldPositive}{The level of the gold standard variable that indicates
disease presence.}

\item{useCosts}{Include cost considerations in the optimization process.}

\item{testCosts}{Comma-separated costs for each test in the same order as
selected tests. Example: "10,25,50" for three tests.}

\item{fpCost}{Cost or harm associated with a false positive result.}

\item{fnCost}{Cost or harm associated with a false negative result.}

\item{strategies}{Which testing strategies to evaluate in the analysis.}

\item{parallelRules}{Rule for combining results in parallel testing.}

\item{customThreshold}{Number of positive tests required for overall
positive result (when using custom rule).}

\item{maxTests}{Maximum number of tests to combine in any strategy.}

\item{sequentialStop}{When to stop testing in sequential strategies.}

\item{optimizationCriteria}{Primary criterion for optimizing test panels.}

\item{panelOptimization}{Method for building optimal test panels.}

\item{minImprovement}{Minimum improvement in performance metric required to
add a test to the panel.}

\item{redundancyThreshold}{Correlation threshold above which tests are
considered redundant.}

\item{minSensitivity}{Minimum sensitivity constraint for panel selection.}

\item{minSpecificity}{Minimum specificity constraint for panel selection.}

\item{createTree}{Generate an optimal decision tree for test sequencing.}

\item{treeMethod}{Method for constructing the decision tree.}

\item{maxDepth}{Maximum depth of the decision tree.}

\item{minSplit}{Minimum number of observations required to split a node.}

\item{showAllCombinations}{Display performance metrics for all possible
test combinations.}

\item{topN}{Number of best-performing panels to display in results.}

\item{compareStrategies}{Show comparative analysis of different testing
strategies.}

\item{bootstrap}{Calculate bootstrap confidence intervals for performance
metrics.}

\item{bootReps}{Number of bootstrap replications for confidence intervals.}

\item{plotTree}{Display visual representation of the optimal decision tree.}

\item{plotComparison}{Create comparison plots for different testing
strategies.}

\item{plotCostEffect}{Create cost-effectiveness frontier plot.}

\item{plotROC}{Display ROC curves for top performing panels.}

\item{prevalence}{Known disease prevalence (0 = use sample prevalence).}

\item{crossValidate}{Perform k-fold cross-validation for panel performance.}

\item{nFolds}{Number of folds for cross-validation.}

\item{seed}{Random seed for reproducibility in bootstrap and
cross-validation.}

\item{showProgress}{Display progress indicators for long-running operations
like bootstrap and cross-validation.}
}
\value{
A results object containing:
\tabular{llllll}{
\code{results$summary} \tab \tab \tab \tab \tab a html \cr
\code{results$clinicalSummary} \tab \tab \tab \tab \tab a html \cr
\code{results$clinicalInterpretation} \tab \tab \tab \tab \tab a html \cr
\code{results$clinicalReport} \tab \tab \tab \tab \tab a html \cr
\code{results$clinicalWarnings} \tab \tab \tab \tab \tab a html \cr
\code{results$optimalPanel} \tab \tab \tab \tab \tab a table \cr
\code{results$strategyComparison} \tab \tab \tab \tab \tab a table \cr
\code{results$individualTests} \tab \tab \tab \tab \tab a table \cr
\code{results$panelBuilding} \tab \tab \tab \tab \tab a table \cr
\code{results$optimalPanelsBySize} \tab \tab \tab \tab \tab a table \cr
\code{results$testRedundancy} \tab \tab \tab \tab \tab a table \cr
\code{results$incrementalValue} \tab \tab \tab \tab \tab a table \cr
\code{results$resultImportance} \tab \tab \tab \tab \tab a table \cr
\code{results$allCombinations} \tab \tab \tab \tab \tab a table \cr
\code{results$treeStructure} \tab \tab \tab \tab \tab a html \cr
\code{results$treePerformance} \tab \tab \tab \tab \tab a table \cr
\code{results$crossValidation} \tab \tab \tab \tab \tab a table \cr
\code{results$bootstrapResults} \tab \tab \tab \tab \tab a table \cr
\code{results$treeVisualization} \tab \tab \tab \tab \tab an image \cr
\code{results$strategyComparisonPlot} \tab \tab \tab \tab \tab an image \cr
\code{results$costEffectivenessPlot} \tab \tab \tab \tab \tab an image \cr
\code{results$rocCurvesPlot} \tab \tab \tab \tab \tab an image \cr
\code{results$recommendations} \tab \tab \tab \tab \tab a html \cr
}

Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:

\code{results$optimalPanel$asDF}

\code{as.data.frame(results$optimalPanel)}
}
\description{
Optimize diagnostic test panels by evaluating various combination
strategies including parallel testing (cotest), sequential testing, and
repeated tests. Creates decision trees to minimize cost while maximizing
accuracy.
}
\examples{
\donttest{
# Load COVID-19 screening data
data("covid_screening_data", package = "ClinicoPath")

# Basic decision panel optimization
# Compare rapid antigen and PCR tests
basic_panel <- decisionpanel(
  data = covid_screening_data,
  tests = c("rapid_antigen", "pcr"),
  testLevels = "Positive,Positive",
  gold = "covid_status",
  goldPositive = "Positive",
  strategies = "all",
  optimizationCriteria = "accuracy"
)

# Cost-effectiveness analysis
# Include test costs and false positive/negative costs
cost_panel <- decisionpanel(
  data = covid_screening_data,
  tests = c("rapid_antigen", "pcr", "chest_ct"),
  testLevels = "Positive,Positive,Abnormal",
  gold = "covid_status",
  goldPositive = "Positive",
  strategies = "all",
  useCosts = TRUE,
  testCosts = "5,50,200",
  fpCost = 500,
  fnCost = 5000,
  optimizationCriteria = "utility"
)

# Sequential testing with decision tree
sequential_panel <- decisionpanel(
  data = covid_screening_data,
  tests = c("rapid_antigen", "pcr"),
  testLevels = "Positive,Positive",
  gold = "covid_status",
  goldPositive = "Positive",
  strategies = "sequential",
  sequentialStop = "positive",
  createTree = TRUE,
  treeMethod = "cart"
)

# Load breast cancer screening data
data("breast_cancer_data", package = "ClinicoPath")

# Advanced panel with validation
# Multiple tests with bootstrap confidence intervals
advanced_panel <- decisionpanel(
  data = breast_cancer_data,
  tests = c("clinical_exam", "mammography", "ultrasound"),
  testLevels = "Abnormal,BIRADS 3-5,Suspicious",
  gold = "cancer_status",
  goldPositive = "Cancer",
  strategies = "all",
  optimizationCriteria = "sensitivity",
  minSensitivity = 0.90,
  minSpecificity = 0.80,
  bootstrap = TRUE,
  bootReps = 1000,
  crossValidate = TRUE,
  nFolds = 5
)

# Parallel testing strategies
# Compare different combination rules
parallel_panel <- decisionpanel(
  data = breast_cancer_data,
  tests = c("clinical_exam", "mammography", "ultrasound"),
  testLevels = "Abnormal,BIRADS 3-5,Suspicious",
  gold = "cancer_status",
  goldPositive = "Cancer",
  strategies = "parallel",
  parallelRules = "any",
  compareStrategies = TRUE,
  plotComparison = TRUE
)
}
}
