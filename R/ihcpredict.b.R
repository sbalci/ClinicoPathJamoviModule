# This file is automatically generated, you probably don't want to edit this

ihcpredictOptions <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "ihcpredictOptions",
    inherit = jmvcore::Options,
    public = list(
        initialize = function(
            useStoredModel = "stored",
            trainingFile = "",
            trainingDiagnosis = "Diagnosis",
            catVars = NULL,
            contVars = NULL,
            caseId = NULL,
            predictionMethod = "hybrid",
            confidenceThreshold = 0.5,
            highConfidenceThreshold = 0.75,
            lowConfidenceThreshold = 0.25,
            panelWeight = 0.5,
            distanceWeight = 0.3,
            silhouetteWeight = 0.2,
            showAlternatives = TRUE,
            nAlternatives = 3,
            showEvidence = TRUE,
            flagLowConfidence = TRUE,
            showMarkerComparison = TRUE,
            validateMarkers = TRUE,
            requireAllMarkers = TRUE,
            scaleContVars = TRUE,
            handleMissing = "pairwise",
            exportPredictions = FALSE,
            predictionVarName = "Predicted_Diagnosis",
            confidenceVarName = "Prediction_Confidence",
            showPredictionPlot = TRUE,
            showConfidencePlot = TRUE,
            colorPalette = "colorblind",
            fontSize = "medium",
            plotContrast = FALSE,
            ...) {

            super$initialize(
                package="ClinicoPath",
                name="ihcpredict",
                requiresData=TRUE,
                ...)

            private$..useStoredModel <- jmvcore::OptionList$new(
                "useStoredModel",
                useStoredModel,
                options=list("stored", "file"),
                default="stored")
            private$..trainingFile <- jmvcore::OptionString$new(
                "trainingFile",
                trainingFile,
                default="")
            private$..trainingDiagnosis <- jmvcore::OptionString$new(
                "trainingDiagnosis",
                trainingDiagnosis,
                default="Diagnosis")
            private$..catVars <- jmvcore::OptionVariables$new(
                "catVars",
                catVars,
                suggested=list("nominal", "ordinal"),
                permitted=list("factor"))
            private$..contVars <- jmvcore::OptionVariables$new(
                "contVars",
                contVars,
                suggested=list("continuous"),
                permitted=list("numeric"))
            private$..caseId <- jmvcore::OptionVariable$new(
                "caseId",
                caseId,
                suggested=list("nominal", "id"),
                permitted=list("factor", "id"))
            private$..predictionMethod <- jmvcore::OptionList$new(
                "predictionMethod",
                predictionMethod,
                options=list("hybrid", "distance", "rules", "cluster"),
                default="hybrid")
            private$..confidenceThreshold <- jmvcore::OptionNumber$new(
                "confidenceThreshold",
                confidenceThreshold,
                min=0, max=1,
                default=0.5)
            private$..highConfidenceThreshold <- jmvcore::OptionNumber$new(
                "highConfidenceThreshold",
                highConfidenceThreshold,
                min=0, max=1,
                default=0.75)
            private$..lowConfidenceThreshold <- jmvcore::OptionNumber$new(
                "lowConfidenceThreshold",
                lowConfidenceThreshold,
                min=0, max=1,
                default=0.25)
            private$..panelWeight <- jmvcore::OptionNumber$new(
                "panelWeight",
                panelWeight,
                min=0, max=1,
                default=0.5)
            private$..distanceWeight <- jmvcore::OptionNumber$new(
                "distanceWeight",
                distanceWeight,
                min=0, max=1,
                default=0.3)
            private$..silhouetteWeight <- jmvcore::OptionNumber$new(
                "silhouetteWeight",
                silhouetteWeight,
                min=0, max=1,
                default=0.2)
            private$..showAlternatives <- jmvcore::OptionBool$new(
                "showAlternatives",
                showAlternatives,
                default=TRUE)
            private$..nAlternatives <- jmvcore::OptionInteger$new(
                "nAlternatives",
                nAlternatives,
                min=1, max=5,
                default=3)
            private$..showEvidence <- jmvcore::OptionBool$new(
                "showEvidence",
                showEvidence,
                default=TRUE)
            private$..flagLowConfidence <- jmvcore::OptionBool$new(
                "flagLowConfidence",
                flagLowConfidence,
                default=TRUE)
            private$..showMarkerComparison <- jmvcore::OptionBool$new(
                "showMarkerComparison",
                showMarkerComparison,
                default=TRUE)
            private$..validateMarkers <- jmvcore::OptionBool$new(
                "validateMarkers",
                validateMarkers,
                default=TRUE)
            private$..requireAllMarkers <- jmvcore::OptionBool$new(
                "requireAllMarkers",
                requireAllMarkers,
                default=TRUE)
            private$..scaleContVars <- jmvcore::OptionBool$new(
                "scaleContVars",
                scaleContVars,
                default=TRUE)
            private$..handleMissing <- jmvcore::OptionList$new(
                "handleMissing",
                handleMissing,
                options=list("complete", "pairwise"),
                default="pairwise")
            private$..exportPredictions <- jmvcore::OptionBool$new(
                "exportPredictions",
                exportPredictions,
                default=FALSE)
            private$..predictionVarName <- jmvcore::OptionString$new(
                "predictionVarName",
                predictionVarName,
                default="Predicted_Diagnosis")
            private$..confidenceVarName <- jmvcore::OptionString$new(
                "confidenceVarName",
                confidenceVarName,
                default="Prediction_Confidence")
            private$..showPredictionPlot <- jmvcore::OptionBool$new(
                "showPredictionPlot",
                showPredictionPlot,
                default=TRUE)
            private$..showConfidencePlot <- jmvcore::OptionBool$new(
                "showConfidencePlot",
                showConfidencePlot,
                default=TRUE)
            private$..colorPalette <- jmvcore::OptionList$new(
                "colorPalette",
                colorPalette,
                options=list("default", "colorblind", "viridis", "high_contrast"),
                default="colorblind")
            private$..fontSize <- jmvcore::OptionList$new(
                "fontSize",
                fontSize,
                options=list("small", "medium", "large", "extra_large"),
                default="medium")
            private$..plotContrast <- jmvcore::OptionBool$new(
                "plotContrast",
                plotContrast,
                default=FALSE)

            self$.addOption(private$..useStoredModel)
            self$.addOption(private$..trainingFile)
            self$.addOption(private$..trainingDiagnosis)
            self$.addOption(private$..catVars)
            self$.addOption(private$..contVars)
            self$.addOption(private$..caseId)
            self$.addOption(private$..predictionMethod)
            self$.addOption(private$..confidenceThreshold)
            self$.addOption(private$..highConfidenceThreshold)
            self$.addOption(private$..lowConfidenceThreshold)
            self$.addOption(private$..panelWeight)
            self$.addOption(private$..distanceWeight)
            self$.addOption(private$..silhouetteWeight)
            self$.addOption(private$..showAlternatives)
            self$.addOption(private$..nAlternatives)
            self$.addOption(private$..showEvidence)
            self$.addOption(private$..flagLowConfidence)
            self$.addOption(private$..showMarkerComparison)
            self$.addOption(private$..validateMarkers)
            self$.addOption(private$..requireAllMarkers)
            self$.addOption(private$..scaleContVars)
            self$.addOption(private$..handleMissing)
            self$.addOption(private$..exportPredictions)
            self$.addOption(private$..predictionVarName)
            self$.addOption(private$..confidenceVarName)
            self$.addOption(private$..showPredictionPlot)
            self$.addOption(private$..showConfidencePlot)
            self$.addOption(private$..colorPalette)
            self$.addOption(private$..fontSize)
            self$.addOption(private$..plotContrast)
        }),
    active = list(
        useStoredModel = function() private$..useStoredModel$value,
        trainingFile = function() private$..trainingFile$value,
        trainingDiagnosis = function() private$..trainingDiagnosis$value,
        catVars = function() private$..catVars$value,
        contVars = function() private$..contVars$value,
        caseId = function() private$..caseId$value,
        predictionMethod = function() private$..predictionMethod$value,
        confidenceThreshold = function() private$..confidenceThreshold$value,
        highConfidenceThreshold = function() private$..highConfidenceThreshold$value,
        lowConfidenceThreshold = function() private$..lowConfidenceThreshold$value,
        panelWeight = function() private$..panelWeight$value,
        distanceWeight = function() private$..distanceWeight$value,
        silhouetteWeight = function() private$..silhouetteWeight$value,
        showAlternatives = function() private$..showAlternatives$value,
        nAlternatives = function() private$..nAlternatives$value,
        showEvidence = function() private$..showEvidence$value,
        flagLowConfidence = function() private$..flagLowConfidence$value,
        showMarkerComparison = function() private$..showMarkerComparison$value,
        validateMarkers = function() private$..validateMarkers$value,
        requireAllMarkers = function() private$..requireAllMarkers$value,
        scaleContVars = function() private$..scaleContVars$value,
        handleMissing = function() private$..handleMissing$value,
        exportPredictions = function() private$..exportPredictions$value,
        predictionVarName = function() private$..predictionVarName$value,
        confidenceVarName = function() private$..confidenceVarName$value,
        showPredictionPlot = function() private$..showPredictionPlot$value,
        showConfidencePlot = function() private$..showConfidencePlot$value,
        colorPalette = function() private$..colorPalette$value,
        fontSize = function() private$..fontSize$value,
        plotContrast = function() private$..plotContrast$value),
    private = list(
        ..useStoredModel = NA,
        ..trainingFile = NA,
        ..trainingDiagnosis = NA,
        ..catVars = NA,
        ..contVars = NA,
        ..caseId = NA,
        ..predictionMethod = NA,
        ..confidenceThreshold = NA,
        ..highConfidenceThreshold = NA,
        ..lowConfidenceThreshold = NA,
        ..panelWeight = NA,
        ..distanceWeight = NA,
        ..silhouetteWeight = NA,
        ..showAlternatives = NA,
        ..nAlternatives = NA,
        ..showEvidence = NA,
        ..flagLowConfidence = NA,
        ..showMarkerComparison = NA,
        ..validateMarkers = NA,
        ..requireAllMarkers = NA,
        ..scaleContVars = NA,
        ..handleMissing = NA,
        ..exportPredictions = NA,
        ..predictionVarName = NA,
        ..confidenceVarName = NA,
        ..showPredictionPlot = NA,
        ..showConfidencePlot = NA,
        ..colorPalette = NA,
        ..fontSize = NA,
        ..plotContrast = NA)
)

ihcpredictResults <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "ihcpredictResults",
    inherit = jmvcore::Group,
    active = list(
        instructions = function() private$.items[[" instructions"]],
        modelSummary = function() private$.items[["modelSummary"]],
        validationResults = function() private$.items[["validationResults"]],
        predictions = function() private$.items[["predictions"]],
        alternativeDiagnoses = function() private$.items[["alternativeDiagnoses"]],
        predictionEvidence = function() private$.items[["predictionEvidence"]],
        lowConfidenceCases = function() private$.items[["lowConfidenceCases"]],
        markerComparison = function() private$.items[["markerComparison"]],
        predictionSummary = function() private$.items[["predictionSummary"]],
        confidenceByDiagnosis = function() private$.items[["confidenceByDiagnosis"]],
        predictionPlot = function() private$.items[["predictionPlot"]],
        confidencePlot = function() private$.items[["confidencePlot"]],
        markerHeatmap = function() private$.items[["markerHeatmap"]],
        clinicalGuidance = function() private$.items[["clinicalGuidance"]],
        technicalDetails = function() private$.items[["technicalDetails"]],
        exportSummary = function() private$.items[["exportSummary"]]),
    private = list(),
    public=list(
        initialize=function(options) {
            super$initialize(
                options=options,
                name="",
                title="IHC Diagnostic Prediction")
            self$add(jmvcore::Html$new(
                options=options,
                name="instructions",
                title="Instructions"))
            self$add(jmvcore::Html$new(
                options=options,
                name="modelSummary",
                title="Reference Model Summary",
                visible=TRUE,
                clearWith=list("useStoredModel", "trainingFile", "trainingDiagnosis")))
            self$add(jmvcore::Table$new(
                options=options,
                name="validationResults",
                title="Marker Validation",
                visible="(validateMarkers)",
                clearWith=list("catVars", "contVars", "trainingFile"),
                columns=list(
                    list(name="marker", title="Marker", type="text"),
                    list(name="in_training", title="In Training Set", type="text"),
                    list(name="in_query", title="In Query Set", type="text"),
                    list(name="type_match", title="Data Type Match", type="text"),
                    list(name="status", title="Validation Status", type="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="predictions",
                title="Diagnostic Predictions",
                visible=TRUE,
                clearWith=list("catVars", "contVars", "predictionMethod", "confidenceThreshold", "panelWeight", "distanceWeight", "silhouetteWeight"),
                columns=list(
                    list(name="case_id", title="Case ID", type="text"),
                    list(name="predicted_diagnosis", title="Predicted Diagnosis", type="text"),
                    list(name="confidence", title="Confidence Score", type="number", format="zto"),
                    list(name="confidence_level", title="Confidence Level", type="text"),
                    list(name="prediction_method", title="Method Used", type="text"),
                    list(name="recommendation", title="Clinical Recommendation", type="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="alternativeDiagnoses",
                title="Alternative Diagnoses (Differential)",
                visible="(showAlternatives)",
                clearWith=list("catVars", "contVars", "predictionMethod", "nAlternatives"),
                columns=list(
                    list(name="case_id", title="Case ID", type="text"),
                    list(name="rank", title="Rank", type="integer"),
                    list(name="alternative_diagnosis", title="Alternative Diagnosis", type="text"),
                    list(name="confidence", title="Confidence Score", type="number", format="zto"),
                    list(name="difference_from_primary", title="Difference from Primary", type="number", format="zto"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="predictionEvidence",
                title="Prediction Evidence Details",
                visible="(showEvidence)",
                clearWith=list("catVars", "contVars", "predictionMethod"),
                columns=list(
                    list(name="case_id", title="Case ID", type="text"),
                    list(name="predicted_diagnosis", title="Predicted Diagnosis", type="text"),
                    list(name="panel_match", title="Panel Match", type="text"),
                    list(name="panel_ppv", title="Panel PPV", type="number", format="zto,pc"),
                    list(name="assigned_cluster", title="Assigned Cluster", type="text"),
                    list(name="cluster_purity", title="Cluster Purity", type="number", format="zto,pc"),
                    list(name="distance_to_centroid", title="Distance to Centroid", type="number"),
                    list(name="silhouette_score", title="Silhouette Score", type="number"),
                    list(name="overall_confidence", title="Overall Confidence", type="number", format="zto"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="lowConfidenceCases",
                title="Low Confidence Predictions (Review Required)",
                visible="(flagLowConfidence)",
                clearWith=list("catVars", "contVars", "predictionMethod", "lowConfidenceThreshold"),
                columns=list(
                    list(name="case_id", title="Case ID", type="text"),
                    list(name="predicted_diagnosis", title="Predicted Diagnosis", type="text"),
                    list(name="confidence", title="Confidence Score", type="number", format="zto"),
                    list(name="quality_flag", title="Quality Flag", type="text"),
                    list(name="primary_issue", title="Primary Issue", type="text"),
                    list(name="recommendation", title="Recommendation", type="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="markerComparison",
                title="Marker Expression Comparison",
                visible="(showMarkerComparison)",
                clearWith=list("catVars", "contVars", "predictionMethod"),
                columns=list(
                    list(name="case_id", title="Case ID", type="text"),
                    list(name="marker", title="Marker", type="text"),
                    list(name="query_value", title="Query Case Value", type="text"),
                    list(name="predicted_diagnosis", title="Predicted Diagnosis", type="text"),
                    list(name="centroid_value", title="Centroid Value", type="text"),
                    list(name="match_status", title="Match Status", type="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="predictionSummary",
                title="Prediction Summary Statistics",
                visible=TRUE,
                clearWith=list("catVars", "contVars", "predictionMethod"),
                columns=list(
                    list(name="statistic", title="Statistic", type="text"),
                    list(name="value", title="Value", type="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="confidenceByDiagnosis",
                title="Confidence Statistics by Predicted Diagnosis",
                visible=TRUE,
                clearWith=list("catVars", "contVars", "predictionMethod"),
                columns=list(
                    list(name="diagnosis", title="Predicted Diagnosis", type="text"),
                    list(name="n_cases", title="N Cases", type="integer"),
                    list(name="mean_confidence", title="Mean Confidence", type="number", format="zto"),
                    list(name="median_confidence", title="Median Confidence", type="number", format="zto"),
                    list(name="min_confidence", title="Min Confidence", type="number", format="zto"),
                    list(name="max_confidence", title="Max Confidence", type="number", format="zto"),
                    list(name="n_high_confidence", title="N High Confidence", type="integer"),
                    list(name="n_low_confidence", title="N Low Confidence", type="integer"))))
            self$add(jmvcore::Image$new(
                options=options,
                name="predictionPlot",
                title="Prediction Visualization (PCA/MCA)",
                width=800,
                height=700,
                renderFun=".plotPredictions",
                visible="(showPredictionPlot)",
                clearWith=list("catVars", "contVars", "predictionMethod", "colorPalette", "fontSize", "plotContrast")))
            self$add(jmvcore::Image$new(
                options=options,
                name="confidencePlot",
                title="Confidence Score Distribution",
                width=700,
                height=500,
                renderFun=".plotConfidenceDistribution",
                visible="(showConfidencePlot)",
                clearWith=list("predictionMethod", "highConfidenceThreshold", "lowConfidenceThreshold", "colorPalette", "fontSize", "plotContrast")))
            self$add(jmvcore::Image$new(
                options=options,
                name="markerHeatmap",
                title="Query Cases vs Training Centroids Heatmap",
                width=900,
                height=700,
                renderFun=".plotMarkerHeatmap",
                visible="(showMarkerComparison)",
                clearWith=list("catVars", "contVars", "predictionMethod", "colorPalette", "fontSize", "plotContrast")))
            self$add(jmvcore::Html$new(
                options=options,
                name="clinicalGuidance",
                title="Clinical Interpretation and Next Steps",
                visible=TRUE))
            self$add(jmvcore::Html$new(
                options=options,
                name="technicalDetails",
                title="Technical Details",
                visible=TRUE))
            self$add(jmvcore::Preformatted$new(
                options=options,
                name="exportSummary",
                title="Export Summary (Copy-Ready Report)",
                visible=TRUE,
                clearWith=list("catVars", "contVars", "predictionMethod")))}))

ihcpredictBase <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "ihcpredictBase",
    inherit = jmvcore::Analysis,
    public = list(
        initialize = function(options, data=NULL, datasetId="", analysisId="", revision=0) {
            super$initialize(
                package = "ClinicoPath",
                name = "ihcpredict",
                version = c(1,0,0),
                options = options,
                results = ihcpredictResults$new(options=options),
                data = data,
                datasetId = datasetId,
                analysisId = analysisId,
                revision = revision,
                pause = NULL,
                completeWhenFilled = FALSE,
                requiresMissings = FALSE,
                weightsSupport = 'na')
        }))

#' IHC Diagnostic Prediction
#'
#' Predicts diagnoses for cases with unknown diagnoses based on IHC marker
#' expression patterns, using a trained reference model.
#'
#' @param data The data as a data frame
#' @param useStoredModel Model source - stored or file
#' @param trainingFile Path to CSV file with training cases
#' @param trainingDiagnosis Name of diagnosis variable in training data
#' @param catVars Categorical IHC markers
#' @param contVars Continuous IHC markers
#' @param caseId Case identifier variable
#' @param predictionMethod Prediction algorithm (hybrid, distance, rules, cluster)
#' @param confidenceThreshold Minimum confidence threshold (0-1)
#' @param highConfidenceThreshold High confidence threshold (0-1)
#' @param lowConfidenceThreshold Low confidence threshold (0-1)
#' @param panelWeight Weight for panel matches (0-1)
#' @param distanceWeight Weight for distance scores (0-1)
#' @param silhouetteWeight Weight for silhouette scores (0-1)
#' @param showAlternatives Show alternative diagnoses
#' @param nAlternatives Number of alternatives to show
#' @param showEvidence Show prediction evidence
#' @param flagLowConfidence Flag low confidence cases
#' @param showMarkerComparison Show marker comparison table
#' @param validateMarkers Validate marker consistency
#' @param requireAllMarkers Require all training markers
#' @param scaleContVars Scale continuous variables
#' @param handleMissing Missing data method (complete, pairwise)
#' @param exportPredictions Export predictions to dataset
#' @param predictionVarName Name for prediction variable
#' @param confidenceVarName Name for confidence variable
#' @param showPredictionPlot Show prediction visualization
#' @param showConfidencePlot Show confidence distribution
#' @param colorPalette Color palette for plots
#' @param fontSize Font size for plots
#' @param plotContrast High contrast mode
#' @return A results object containing prediction tables and plots
#' @export
ihcpredict <- function(
    data,
    useStoredModel = "stored",
    trainingFile = "",
    trainingDiagnosis = "Diagnosis",
    catVars = NULL,
    contVars = NULL,
    caseId = NULL,
    predictionMethod = "hybrid",
    confidenceThreshold = 0.5,
    highConfidenceThreshold = 0.75,
    lowConfidenceThreshold = 0.25,
    panelWeight = 0.5,
    distanceWeight = 0.3,
    silhouetteWeight = 0.2,
    showAlternatives = TRUE,
    nAlternatives = 3,
    showEvidence = TRUE,
    flagLowConfidence = TRUE,
    showMarkerComparison = TRUE,
    validateMarkers = TRUE,
    requireAllMarkers = TRUE,
    scaleContVars = TRUE,
    handleMissing = "pairwise",
    exportPredictions = FALSE,
    predictionVarName = "Predicted_Diagnosis",
    confidenceVarName = "Prediction_Confidence",
    showPredictionPlot = TRUE,
    showConfidencePlot = TRUE,
    colorPalette = "colorblind",
    fontSize = "medium",
    plotContrast = FALSE) {

    if ( ! requireNamespace("jmvcore", quietly=TRUE))
        stop("ihcpredict requires jmvcore to be installed (restart may be required)")

    if ( ! missing(catVars)) catVars <- jmvcore::resolveQuo(jmvcore::enquo(catVars))
    if ( ! missing(contVars)) contVars <- jmvcore::resolveQuo(jmvcore::enquo(contVars))
    if ( ! missing(caseId)) caseId <- jmvcore::resolveQuo(jmvcore::enquo(caseId))
    if (missing(data))
        data <- jmvcore::marshalData(
            parent.frame(),
            `if`( ! missing(catVars), catVars, NULL),
            `if`( ! missing(contVars), contVars, NULL),
            `if`( ! missing(caseId), caseId, NULL))

    options <- ihcpredictOptions$new(
        useStoredModel = useStoredModel,
        trainingFile = trainingFile,
        trainingDiagnosis = trainingDiagnosis,
        catVars = catVars,
        contVars = contVars,
        caseId = caseId,
        predictionMethod = predictionMethod,
        confidenceThreshold = confidenceThreshold,
        highConfidenceThreshold = highConfidenceThreshold,
        lowConfidenceThreshold = lowConfidenceThreshold,
        panelWeight = panelWeight,
        distanceWeight = distanceWeight,
        silhouetteWeight = silhouetteWeight,
        showAlternatives = showAlternatives,
        nAlternatives = nAlternatives,
        showEvidence = showEvidence,
        flagLowConfidence = flagLowConfidence,
        showMarkerComparison = showMarkerComparison,
        validateMarkers = validateMarkers,
        requireAllMarkers = requireAllMarkers,
        scaleContVars = scaleContVars,
        handleMissing = handleMissing,
        exportPredictions = exportPredictions,
        predictionVarName = predictionVarName,
        confidenceVarName = confidenceVarName,
        showPredictionPlot = showPredictionPlot,
        showConfidencePlot = showConfidencePlot,
        colorPalette = colorPalette,
        fontSize = fontSize,
        plotContrast = plotContrast)

    analysis <- ihcpredictClass$new(
        options = options,
        data = data)

    analysis$run()

    analysis$results
}

# ============================================================================
# Implementation Class
# ============================================================================

ihcpredictClass <- if (requireNamespace('jmvcore', quietly=TRUE)) R6::R6Class(
    "ihcpredictClass",
    inherit = ihcpredictBase,
    private = list(

        # ====================================================================
        # Initialization
        # ====================================================================

        .init = function() {

            private$.populateInstructions()

            # Initialize analysis state
            private$analysisState <- list(
                trainingModel = NULL,
                queryData = NULL,
                predictions = NULL,
                alternatives = NULL,
                evidence = NULL,
                lowConfidenceCases = NULL,
                markerComparison = NULL,
                validationResults = NULL
            )

        },

        # ====================================================================
        # Main Analysis Run
        # ====================================================================

        .run = function() {

            opts <- self$options

            # Check for minimum requirements
            if (is.null(opts$catVars) && is.null(opts$contVars)) {
                return()
            }

            # Load query data
            queryData <- self$data
            queryData <- jmvcore::naOmit(queryData)

            if (nrow(queryData) == 0) {
                self$results$modelSummary$setContent("<p>No valid query cases found.</p>")
                return()
            }

            # Get marker variables
            catVars <- opts$catVars
            contVars <- opts$contVars
            markerVars <- c(catVars, contVars)

            if (length(markerVars) == 0) {
                self$results$modelSummary$setContent("<p>Please select at least one IHC marker.</p>")
                return()
            }

            # Load training model
            trainingModel <- tryCatch({
                private$.loadTrainingModel(opts)
            }, error = function(e) {
                self$results$modelSummary$setContent(
                    paste0("<p><strong>Error loading training model:</strong> ", e$message, "</p>")
                )
                return(NULL)
            })

            if (is.null(trainingModel)) {
                return()
            }

            # Validate markers
            if (isTRUE(opts$validateMarkers)) {
                validationResults <- private$.validateMarkers(
                    trainingModel, queryData, markerVars, opts$requireAllMarkers
                )
                private$analysisState$validationResults <- validationResults
                private$.populateValidationResults()

                # Check for critical validation failures
                if (any(validationResults$status == "ERROR")) {
                    return()
                }
            }

            # Perform predictions
            predictions <- private$.predictDiagnoses(
                trainingModel, queryData, markerVars, opts
            )

            private$analysisState$predictions <- predictions
            private$analysisState$trainingModel <- trainingModel
            private$analysisState$queryData <- queryData

            # Generate alternative diagnoses
            if (isTRUE(opts$showAlternatives)) {
                alternatives <- private$.generateAlternatives(
                    predictions, opts$nAlternatives %||% 3
                )
                private$analysisState$alternatives <- alternatives
            }

            # Generate evidence
            if (isTRUE(opts$showEvidence)) {
                evidence <- private$.generateEvidence(predictions, trainingModel)
                private$analysisState$evidence <- evidence
            }

            # Flag low confidence cases
            if (isTRUE(opts$flagLowConfidence)) {
                lowConfidenceCases <- private$.flagLowConfidence(
                    predictions, opts$lowConfidenceThreshold %||% 0.25
                )
                private$analysisState$lowConfidenceCases <- lowConfidenceCases
            }

            # Generate marker comparison
            if (isTRUE(opts$showMarkerComparison)) {
                markerComparison <- private$.compareMarkers(
                    queryData, trainingModel, predictions, markerVars
                )
                private$analysisState$markerComparison <- markerComparison
            }

            # Populate all tables
            private$.populateModelSummary()
            private$.populatePredictions()
            private$.populateAlternatives()
            private$.populateEvidence()
            private$.populateLowConfidence()
            private$.populateMarkerComparison()
            private$.populateSummaryStats()
            private$.populateConfidenceByDiagnosis()
            private$.populateClinicalGuidance()
            private$.populateTechnicalDetails()
            private$.populateExportSummary()

            # Export predictions if requested
            if (isTRUE(opts$exportPredictions)) {
                private$.exportPredictions()
            }

        },

        # ====================================================================
        # Load Training Model
        # ====================================================================

        .loadTrainingModel = function(opts) {

            if (opts$useStoredModel == "stored") {
                # Try to retrieve from jamovi state (future enhancement)
                stop("Stored model functionality not yet implemented. Please use 'Load training data from CSV file' option.")
            } else {
                # Load from CSV file
                trainingFile <- opts$trainingFile
                if (trainingFile == "" || is.null(trainingFile)) {
                    stop("Please specify a training data file path.")
                }

                if (!file.exists(trainingFile)) {
                    stop(paste0("Training file not found: ", trainingFile))
                }

                trainingData <- read.csv(trainingFile, stringsAsFactors = TRUE)
                diagnosisVar <- opts$trainingDiagnosis %||% "Diagnosis"

                if (!diagnosisVar %in% colnames(trainingData)) {
                    stop(paste0("Diagnosis column '", diagnosisVar, "' not found in training data."))
                }

                # Extract markers
                catVars <- opts$catVars
                contVars <- opts$contVars
                markerVars <- c(catVars, contVars)

                # Check markers exist
                missing_markers <- setdiff(markerVars, colnames(trainingData))
                if (length(missing_markers) > 0) {
                    stop(paste0("Markers not found in training data: ", paste(missing_markers, collapse=", ")))
                }

                # Build training model
                model <- private$.buildTrainingModel(
                    trainingData, diagnosisVar, markerVars, catVars, contVars, opts
                )

                return(model)
            }
        },

        # ====================================================================
        # Build Training Model
        # ====================================================================

        .buildTrainingModel = function(trainingData, diagnosisVar, markerVars, catVars, contVars, opts) {

            diagnosis <- as.factor(trainingData[[diagnosisVar]])
            diagnoses <- levels(diagnosis)

            # Calculate cluster centroids
            markerData <- trainingData[, markerVars, drop = FALSE]

            # Convert categorical to numeric for centroid calculation
            markerMatrix <- markerData
            for (v in catVars) {
                if (is.factor(markerMatrix[[v]])) {
                    # Binary: Positive=1, Negative=0
                    markerMatrix[[v]] <- as.numeric(!(markerMatrix[[v]] %in% c("Negative", "negative", "neg", "0", "-")))
                }
            }

            # Scale continuous if requested
            if (isTRUE(opts$scaleContVars) && length(contVars) > 0) {
                scaling_params <- list()
                for (v in contVars) {
                    scaling_params[[v]] <- list(
                        mean = mean(markerMatrix[[v]], na.rm = TRUE),
                        sd = sd(markerMatrix[[v]], na.rm = TRUE)
                    )
                    markerMatrix[[v]] <- scale(markerMatrix[[v]])
                }
            } else {
                scaling_params <- NULL
            }

            # Calculate centroids per diagnosis
            centroids <- list()
            cluster_mapping <- list()  # Diagnosis -> cluster assignment

            for (dx in diagnoses) {
                dx_cases <- diagnosis == dx
                dx_data <- markerMatrix[dx_cases, , drop = FALSE]

                # Calculate mean for each marker
                centroid <- sapply(colnames(dx_data), function(m) {
                    mean(dx_data[[m]], na.rm = TRUE)
                })

                centroids[[dx]] <- centroid
                cluster_mapping[[dx]] <- dx  # Direct mapping for now
            }

            # Calculate optimal panels (if any)
            optimalPanels <- private$.calculateOptimalPanels(
                trainingData, diagnosisVar, markerVars
            )

            # Build model object
            model <- list(
                diagnoses = diagnoses,
                markerVars = markerVars,
                catVars = catVars,
                contVars = contVars,
                centroids = centroids,
                cluster_mapping = cluster_mapping,
                optimalPanels = optimalPanels,
                scaling_params = scaling_params,
                n_training = nrow(trainingData),
                training_file = opts$trainingFile
            )

            return(model)
        },

        # ====================================================================
        # Calculate Optimal Panels
        # ====================================================================

        .calculateOptimalPanels = function(trainingData, diagnosisVar, markerVars) {

            diagnosis <- as.factor(trainingData[[diagnosisVar]])
            diagnoses <- levels(diagnosis)

            # Convert markers to binary matrix
            n_markers <- length(markerVars)
            marker_matrix <- matrix(FALSE, nrow = nrow(trainingData), ncol = n_markers)
            colnames(marker_matrix) <- markerVars

            for (i in seq_along(markerVars)) {
                marker <- markerVars[i]
                marker_data <- trainingData[[marker]]

                if (is.factor(marker_data) || is.character(marker_data)) {
                    marker_matrix[, i] <- !(marker_data %in% c("Negative", "negative", "neg", "0", "-"))
                } else if (is.numeric(marker_data)) {
                    marker_matrix[, i] <- marker_data > median(marker_data, na.rm = TRUE)
                }
            }

            # Test 2-marker panels
            panels <- data.frame()

            for (i in 1:(n_markers - 1)) {
                for (j in (i + 1):n_markers) {
                    panel_name <- paste0(markerVars[i], " + ", markerVars[j])
                    combined_positive <- marker_matrix[, i] & marker_matrix[, j]

                    for (target_dx in diagnoses) {
                        tp <- sum(combined_positive & (diagnosis == target_dx))
                        tn <- sum(!combined_positive & (diagnosis != target_dx))
                        fp <- sum(combined_positive & (diagnosis != target_dx))
                        fn <- sum(!combined_positive & (diagnosis == target_dx))

                        if ((tp + fn) == 0 || (tp + fp) == 0) next

                        sens <- tp / (tp + fn)
                        spec <- tn / (tn + fp)
                        ppv <- tp / (tp + fp)
                        perf_score <- (sens * spec * ppv)^(1/3)

                        panels <- rbind(panels, data.frame(
                            panel = panel_name,
                            target_diagnosis = target_dx,
                            sensitivity = sens,
                            specificity = spec,
                            ppv = ppv,
                            performance_score = perf_score,
                            stringsAsFactors = FALSE
                        ))
                    }
                }
            }

            # Rank by performance score
            if (nrow(panels) > 0) {
                panels <- panels[order(-panels$performance_score), ]
            }

            return(panels)
        },

        # ====================================================================
        # Validate Markers
        # ====================================================================

        .validateMarkers = function(trainingModel, queryData, queryMarkers, requireAll) {

            trainingMarkers <- trainingModel$markerVars

            results <- data.frame()

            # Check each training marker
            for (marker in trainingMarkers) {
                in_training <- "YES"
                in_query <- ifelse(marker %in% colnames(queryData), "YES", "NO")

                type_match <- if (in_query == "YES") {
                    training_type <- ifelse(marker %in% trainingModel$catVars, "Categorical", "Continuous")
                    query_type <- ifelse(is.factor(queryData[[marker]]) || is.character(queryData[[marker]]),
                                        "Categorical", "Continuous")
                    ifelse(training_type == query_type, "YES", "NO")
                } else {
                    "N/A"
                }

                status <- if (in_query == "NO") {
                    ifelse(requireAll, "ERROR", "WARNING")
                } else if (type_match == "NO") {
                    "ERROR"
                } else {
                    "OK"
                }

                results <- rbind(results, data.frame(
                    marker = marker,
                    in_training = in_training,
                    in_query = in_query,
                    type_match = type_match,
                    status = status,
                    stringsAsFactors = FALSE
                ))
            }

            # Check for extra markers in query
            extra_markers <- setdiff(queryMarkers, trainingMarkers)
            for (marker in extra_markers) {
                results <- rbind(results, data.frame(
                    marker = marker,
                    in_training = "NO",
                    in_query = "YES",
                    type_match = "N/A",
                    status = "WARNING",
                    stringsAsFactors = FALSE
                ))
            }

            return(results)
        },

        # ====================================================================
        # Predict Diagnoses
        # ====================================================================

        .predictDiagnoses = function(trainingModel, queryData, markerVars, opts) {

            n_query <- nrow(queryData)
            predictions <- data.frame()

            for (i in 1:n_query) {
                case_row <- queryData[i, , drop = FALSE]
                case_id <- if (!is.null(opts$caseId)) {
                    as.character(case_row[[opts$caseId]])
                } else {
                    paste0("Case_", i)
                }

                # Extract marker values
                case_markers <- case_row[, markerVars, drop = FALSE]

                # Apply prediction method
                prediction <- switch(opts$predictionMethod,
                    hybrid = private$.predictHybrid(case_markers, trainingModel, opts),
                    distance = private$.predictDistance(case_markers, trainingModel, opts),
                    rules = private$.predictRules(case_markers, trainingModel, opts),
                    cluster = private$.predictCluster(case_markers, trainingModel, opts),
                    private$.predictHybrid(case_markers, trainingModel, opts)  # default
                )

                # Determine confidence level
                conf_level <- if (prediction$confidence >= opts$highConfidenceThreshold) {
                    "High"
                } else if (prediction$confidence >= opts$confidenceThreshold) {
                    "Moderate"
                } else if (prediction$confidence >= opts$lowConfidenceThreshold) {
                    "Low"
                } else {
                    "Very Low"
                }

                # Clinical recommendation
                recommendation <- if (conf_level == "High") {
                    "Accept diagnosis, proceed with treatment planning"
                } else if (conf_level == "Moderate") {
                    "Consider confirmatory testing if clinically important"
                } else if (conf_level == "Low") {
                    "Recommend molecular testing for confirmation"
                } else {
                    "Mandatory molecular testing - atypical immunoprofile"
                }

                predictions <- rbind(predictions, data.frame(
                    case_id = case_id,
                    predicted_diagnosis = prediction$diagnosis,
                    confidence = prediction$confidence,
                    confidence_level = conf_level,
                    prediction_method = opts$predictionMethod,
                    recommendation = recommendation,
                    # Store detailed predictions for alternatives
                    all_scores = I(list(prediction$all_scores)),
                    panel_match = I(list(prediction$panel_match)),
                    distance_score = prediction$distance_score,
                    silhouette_score = prediction$silhouette_score,
                    assigned_cluster = prediction$assigned_cluster,
                    stringsAsFactors = FALSE
                ))
            }

            return(predictions)
        },

        # ====================================================================
        # Prediction Methods
        # ====================================================================

        .predictHybrid = function(caseMarkers, trainingModel, opts) {

            # Get all component scores
            rules_pred <- private$.predictRules(caseMarkers, trainingModel, opts)
            distance_pred <- private$.predictDistance(caseMarkers, trainingModel, opts)
            cluster_pred <- private$.predictCluster(caseMarkers, trainingModel, opts)

            # Combine scores
            w1 <- opts$panelWeight %||% 0.5
            w2 <- opts$distanceWeight %||% 0.3
            w3 <- opts$silhouetteWeight %||% 0.2

            all_diagnoses <- trainingModel$diagnoses
            combined_scores <- rep(0, length(all_diagnoses))
            names(combined_scores) <- all_diagnoses

            for (dx in all_diagnoses) {
                panel_score <- rules_pred$all_scores[[dx]] %||% 0
                dist_score <- distance_pred$all_scores[[dx]] %||% 0
                sil_score <- (cluster_pred$all_scores[[dx]] %||% 0)

                combined_scores[dx] <- w1 * panel_score + w2 * dist_score + w3 * sil_score
            }

            # Normalize weights if they don't sum to 1
            weight_sum <- w1 + w2 + w3
            if (weight_sum != 1) {
                combined_scores <- combined_scores / weight_sum
            }

            # Best prediction
            best_dx <- names(which.max(combined_scores))
            best_conf <- combined_scores[best_dx]

            return(list(
                diagnosis = best_dx,
                confidence = best_conf,
                all_scores = combined_scores,
                panel_match = rules_pred$panel_match,
                distance_score = distance_pred$confidence,
                silhouette_score = cluster_pred$silhouette_score,
                assigned_cluster = cluster_pred$assigned_cluster
            ))
        },

        .predictRules = function(caseMarkers, trainingModel, opts) {

            optimalPanels <- trainingModel$optimalPanels

            if (is.null(optimalPanels) || nrow(optimalPanels) == 0) {
                # No panels available
                return(list(
                    diagnosis = trainingModel$diagnoses[1],
                    confidence = 0,
                    all_scores = setNames(rep(0, length(trainingModel$diagnoses)), trainingModel$diagnoses),
                    panel_match = NULL
                ))
            }

            # Convert case markers to binary
            case_binary <- list()
            for (marker in names(caseMarkers)) {
                val <- caseMarkers[[marker]]
                if (is.factor(val) || is.character(val)) {
                    case_binary[[marker]] <- !(val %in% c("Negative", "negative", "neg", "0", "-"))
                } else {
                    # For continuous, we'd need training median (use 0.5 as placeholder)
                    case_binary[[marker]] <- val > 0.5
                }
            }

            # Check each panel
            best_match <- NULL
            best_score <- 0

            for (i in 1:nrow(optimalPanels)) {
                panel <- optimalPanels[i, ]
                markers <- strsplit(panel$panel, " \\+ ")[[1]]

                # Check if all markers in panel are available
                if (!all(markers %in% names(case_binary))) next

                # Check if all markers are positive
                all_positive <- all(sapply(markers, function(m) case_binary[[m]]))

                if (all_positive) {
                    score <- panel$ppv  # Use PPV as panel score
                    if (score > best_score) {
                        best_score <- score
                        best_match <- panel
                    }
                }
            }

            if (!is.null(best_match)) {
                all_scores <- setNames(rep(0, length(trainingModel$diagnoses)), trainingModel$diagnoses)
                all_scores[best_match$target_diagnosis] <- best_score

                return(list(
                    diagnosis = best_match$target_diagnosis,
                    confidence = best_score,
                    all_scores = all_scores,
                    panel_match = best_match
                ))
            } else {
                # No panel match
                return(list(
                    diagnosis = trainingModel$diagnoses[1],
                    confidence = 0,
                    all_scores = setNames(rep(0, length(trainingModel$diagnoses)), trainingModel$diagnoses),
                    panel_match = NULL
                ))
            }
        },

        .predictDistance = function(caseMarkers, trainingModel, opts) {

            # Prepare case vector
            case_vec <- numeric(length(trainingModel$markerVars))
            names(case_vec) <- trainingModel$markerVars

            for (marker in trainingModel$markerVars) {
                if (marker %in% names(caseMarkers)) {
                    val <- caseMarkers[[marker]]

                    if (marker %in% trainingModel$catVars) {
                        # Binary encoding
                        case_vec[marker] <- as.numeric(!(val %in% c("Negative", "negative", "neg", "0", "-")))
                    } else {
                        # Continuous
                        case_vec[marker] <- as.numeric(val)

                        # Apply scaling if used in training
                        if (!is.null(trainingModel$scaling_params) && marker %in% names(trainingModel$scaling_params)) {
                            params <- trainingModel$scaling_params[[marker]]
                            case_vec[marker] <- (case_vec[marker] - params$mean) / params$sd
                        }
                    }
                } else {
                    case_vec[marker] <- NA
                }
            }

            # Calculate distances to all centroids
            distances <- sapply(trainingModel$diagnoses, function(dx) {
                centroid <- trainingModel$centroids[[dx]]
                sqrt(sum((case_vec - centroid)^2, na.rm = TRUE))
            })

            # Nearest diagnosis
            nearest_dx <- names(which.min(distances))
            nearest_dist <- distances[nearest_dx]

            # Convert distance to confidence score (inverse)
            confidence <- 1 / (1 + nearest_dist)

            # All scores (inverse distances normalized)
            all_scores <- 1 / (1 + distances)
            all_scores <- all_scores / sum(all_scores)  # Normalize to sum to 1

            return(list(
                diagnosis = nearest_dx,
                confidence = confidence,
                all_scores = all_scores,
                panel_match = NULL,
                distance_to_centroid = nearest_dist
            ))
        },

        .predictCluster = function(caseMarkers, trainingModel, opts) {

            # Similar to distance-based but uses cluster membership
            dist_pred <- private$.predictDistance(caseMarkers, trainingModel, opts)

            # Calculate silhouette-like score
            distances <- sapply(trainingModel$diagnoses, function(dx) {
                centroid <- trainingModel$centroids[[dx]]
                case_vec <- numeric(length(trainingModel$markerVars))
                names(case_vec) <- trainingModel$markerVars

                for (marker in trainingModel$markerVars) {
                    if (marker %in% names(caseMarkers)) {
                        val <- caseMarkers[[marker]]
                        if (marker %in% trainingModel$catVars) {
                            case_vec[marker] <- as.numeric(!(val %in% c("Negative", "negative", "neg", "0", "-")))
                        } else {
                            case_vec[marker] <- as.numeric(val)
                            if (!is.null(trainingModel$scaling_params) && marker %in% names(trainingModel$scaling_params)) {
                                params <- trainingModel$scaling_params[[marker]]
                                case_vec[marker] <- (case_vec[marker] - params$mean) / params$sd
                            }
                        }
                    } else {
                        case_vec[marker] <- NA
                    }
                }

                sqrt(sum((case_vec - centroid)^2, na.rm = TRUE))
            })

            # Assigned cluster
            assigned_cluster <- names(which.min(distances))
            a_dist <- distances[assigned_cluster]

            # Nearest alternative
            distances_sorted <- sort(distances)
            b_dist <- distances_sorted[2]  # Second nearest

            # Silhouette score
            silhouette <- (b_dist - a_dist) / max(a_dist, b_dist)

            # Normalize silhouette to 0-1
            silhouette_normalized <- (silhouette + 1) / 2

            return(list(
                diagnosis = assigned_cluster,
                confidence = silhouette_normalized,
                all_scores = dist_pred$all_scores,
                panel_match = NULL,
                silhouette_score = silhouette,
                assigned_cluster = assigned_cluster
            ))
        },

        # ====================================================================
        # Generate Alternatives
        # ====================================================================

        .generateAlternatives = function(predictions, nAlternatives) {

            alternatives <- data.frame()

            for (i in 1:nrow(predictions)) {
                pred <- predictions[i, ]
                all_scores <- pred$all_scores[[1]]

                if (is.null(all_scores)) next

                # Sort by confidence
                scores_sorted <- sort(all_scores, decreasing = TRUE)

                # Take top N alternatives (excluding primary)
                n_alts <- min(nAlternatives, length(scores_sorted) - 1)

                if (n_alts > 0) {
                    for (rank in 1:n_alts) {
                        alt_dx <- names(scores_sorted)[rank + 1]  # +1 to skip primary
                        alt_conf <- scores_sorted[rank + 1]
                        primary_conf <- pred$confidence
                        diff <- primary_conf - alt_conf

                        alternatives <- rbind(alternatives, data.frame(
                            case_id = pred$case_id,
                            rank = rank,
                            alternative_diagnosis = alt_dx,
                            confidence = alt_conf,
                            difference_from_primary = diff,
                            stringsAsFactors = FALSE
                        ))
                    }
                }
            }

            return(alternatives)
        },

        # ====================================================================
        # Generate Evidence
        # ====================================================================

        .generateEvidence = function(predictions, trainingModel) {

            evidence <- data.frame()

            for (i in 1:nrow(predictions)) {
                pred <- predictions[i, ]

                panel_match_text <- if (!is.null(pred$panel_match[[1]])) {
                    pm <- pred$panel_match[[1]]
                    pm$panel
                } else {
                    "None"
                }

                panel_ppv <- if (!is.null(pred$panel_match[[1]])) {
                    pred$panel_match[[1]]$ppv
                } else {
                    NA
                }

                # Cluster purity (% of diagnosis in assigned cluster)
                cluster_purity <- if (!is.null(pred$assigned_cluster)) {
                    # For now, use 100% since we're using diagnosis-based centroids
                    1.0
                } else {
                    NA
                }

                evidence <- rbind(evidence, data.frame(
                    case_id = pred$case_id,
                    predicted_diagnosis = pred$predicted_diagnosis,
                    panel_match = panel_match_text,
                    panel_ppv = panel_ppv,
                    assigned_cluster = pred$assigned_cluster %||% "N/A",
                    cluster_purity = cluster_purity,
                    distance_to_centroid = pred$distance_score %||% NA,
                    silhouette_score = pred$silhouette_score %||% NA,
                    overall_confidence = pred$confidence,
                    stringsAsFactors = FALSE
                ))
            }

            return(evidence)
        },

        # ====================================================================
        # Flag Low Confidence
        # ====================================================================

        .flagLowConfidence = function(predictions, threshold) {

            low_conf <- predictions[predictions$confidence < threshold, ]

            if (nrow(low_conf) == 0) {
                return(data.frame())
            }

            results <- data.frame()

            for (i in 1:nrow(low_conf)) {
                pred <- low_conf[i, ]

                quality_flag <- if (pred$confidence < 0) {
                    "Poor - likely misclassified"
                } else if (pred$confidence < 0.10) {
                    "Very low - ambiguous profile"
                } else if (pred$confidence < threshold) {
                    "Low - atypical features"
                } else {
                    "Borderline"
                }

                primary_issue <- if (is.null(pred$panel_match[[1]])) {
                    "No optimal panel match"
                } else if (!is.na(pred$silhouette_score) && pred$silhouette_score < 0.1) {
                    "Poor cluster membership"
                } else {
                    "Uncertain classification"
                }

                recommendation <- if (pred$confidence < 0.10) {
                    "Mandatory molecular testing - review IHC staining quality"
                } else if (pred$confidence < threshold) {
                    "Strongly recommend molecular confirmation"
                } else {
                    "Consider molecular testing if clinically important"
                }

                results <- rbind(results, data.frame(
                    case_id = pred$case_id,
                    predicted_diagnosis = pred$predicted_diagnosis,
                    confidence = pred$confidence,
                    quality_flag = quality_flag,
                    primary_issue = primary_issue,
                    recommendation = recommendation,
                    stringsAsFactors = FALSE
                ))
            }

            return(results)
        },

        # ====================================================================
        # Compare Markers
        # ====================================================================

        .compareMarkers = function(queryData, trainingModel, predictions, markerVars) {

            comparison <- data.frame()

            for (i in 1:nrow(predictions)) {
                pred <- predictions[i, ]
                case_row <- queryData[i, , drop = FALSE]
                predicted_dx <- pred$predicted_diagnosis

                # Get centroid for predicted diagnosis
                if (predicted_dx %in% names(trainingModel$centroids)) {
                    centroid <- trainingModel$centroids[[predicted_dx]]

                    for (marker in markerVars) {
                        query_val <- case_row[[marker]]
                        centroid_val <- centroid[marker]

                        # Format values
                        if (marker %in% trainingModel$catVars) {
                            query_text <- as.character(query_val)
                            centroid_text <- ifelse(centroid_val > 0.5, "Positive", "Negative")

                            match_status <- ifelse(
                                (query_val %in% c("Positive", "positive", "pos", "1", "+")) == (centroid_val > 0.5),
                                "Match", "Mismatch"
                            )
                        } else {
                            query_text <- sprintf("%.2f", as.numeric(query_val))
                            centroid_text <- sprintf("%.2f", centroid_val)

                            # Within 20% is considered match
                            diff_pct <- abs(as.numeric(query_val) - centroid_val) / centroid_val
                            match_status <- ifelse(diff_pct < 0.2, "Close match", "Different")
                        }

                        comparison <- rbind(comparison, data.frame(
                            case_id = pred$case_id,
                            marker = marker,
                            query_value = query_text,
                            predicted_diagnosis = predicted_dx,
                            centroid_value = centroid_text,
                            match_status = match_status,
                            stringsAsFactors = FALSE
                        ))
                    }
                }
            }

            return(comparison)
        },

        # ====================================================================
        # Population Functions
        # ====================================================================

        .populateInstructions = function() {

            html <- "
            <h3>IHC Diagnostic Prediction</h3>
            <p>This analysis predicts diagnoses for cases with unknown diagnoses based on IHC marker expression patterns.</p>

            <h4>Requirements:</h4>
            <ul>
                <li><strong>Training Data:</strong> CSV file with cases having known diagnoses (analyzed with ihccluster)</li>
                <li><strong>Query Data:</strong> Current dataset with cases to predict</li>
                <li><strong>Matching Markers:</strong> Same IHC markers in both datasets</li>
            </ul>

            <h4>Workflow:</h4>
            <ol>
                <li>Select 'Load training data from CSV file' as Model Source</li>
                <li>Specify path to training data CSV file</li>
                <li>Confirm diagnosis column name (default: 'Diagnosis')</li>
                <li>Select same IHC markers as in training data</li>
                <li>Choose prediction method (Hybrid recommended)</li>
                <li>Review predictions and confidence levels</li>
                <li>Follow clinical recommendations for low confidence cases</li>
            </ol>

            <p><strong>Note:</strong> Molecular testing is recommended for all cases with confidence < 0.50 or flagged as atypical.</p>
            "

            self$results$instructions$setContent(html)
        },

        .populateModelSummary = function() {

            model <- private$analysisState$trainingModel

            if (is.null(model)) {
                return()
            }

            html <- sprintf("
            <h3>Training Model Summary</h3>
            <table>
                <tr><td><strong>Training Cases:</strong></td><td>%d</td></tr>
                <tr><td><strong>Diagnoses:</strong></td><td>%s</td></tr>
                <tr><td><strong>Markers:</strong></td><td>%s</td></tr>
                <tr><td><strong>Training File:</strong></td><td>%s</td></tr>
            </table>
            ",
                model$n_training,
                paste(model$diagnoses, collapse=", "),
                paste(model$markerVars, collapse=", "),
                basename(model$training_file)
            )

            self$results$modelSummary$setContent(html)
        },

        .populateValidationResults = function() {

            validation <- private$analysisState$validationResults

            if (is.null(validation) || nrow(validation) == 0) {
                return()
            }

            table <- self$results$validationResults

            for (i in 1:nrow(validation)) {
                row <- validation[i, ]
                table$addRow(rowKey=i, values=list(
                    marker = row$marker,
                    in_training = row$in_training,
                    in_query = row$in_query,
                    type_match = row$type_match,
                    status = row$status
                ))
            }
        },

        .populatePredictions = function() {

            predictions <- private$analysisState$predictions

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            table <- self$results$predictions

            for (i in 1:nrow(predictions)) {
                row <- predictions[i, ]
                table$addRow(rowKey=i, values=list(
                    case_id = row$case_id,
                    predicted_diagnosis = row$predicted_diagnosis,
                    confidence = row$confidence,
                    confidence_level = row$confidence_level,
                    prediction_method = row$prediction_method,
                    recommendation = row$recommendation
                ))
            }
        },

        .populateAlternatives = function() {

            alternatives <- private$analysisState$alternatives

            if (is.null(alternatives) || nrow(alternatives) == 0) {
                return()
            }

            table <- self$results$alternativeDiagnoses

            for (i in 1:nrow(alternatives)) {
                row <- alternatives[i, ]
                table$addRow(rowKey=i, values=list(
                    case_id = row$case_id,
                    rank = row$rank,
                    alternative_diagnosis = row$alternative_diagnosis,
                    confidence = row$confidence,
                    difference_from_primary = row$difference_from_primary
                ))
            }
        },

        .populateEvidence = function() {

            evidence <- private$analysisState$evidence

            if (is.null(evidence) || nrow(evidence) == 0) {
                return()
            }

            table <- self$results$predictionEvidence

            for (i in 1:nrow(evidence)) {
                row <- evidence[i, ]
                table$addRow(rowKey=i, values=list(
                    case_id = row$case_id,
                    predicted_diagnosis = row$predicted_diagnosis,
                    panel_match = row$panel_match,
                    panel_ppv = row$panel_ppv,
                    assigned_cluster = row$assigned_cluster,
                    cluster_purity = row$cluster_purity,
                    distance_to_centroid = row$distance_to_centroid,
                    silhouette_score = row$silhouette_score,
                    overall_confidence = row$overall_confidence
                ))
            }
        },

        .populateLowConfidence = function() {

            lowConf <- private$analysisState$lowConfidenceCases

            if (is.null(lowConf) || nrow(lowConf) == 0) {
                return()
            }

            table <- self$results$lowConfidenceCases

            for (i in 1:nrow(lowConf)) {
                row <- lowConf[i, ]
                table$addRow(rowKey=i, values=list(
                    case_id = row$case_id,
                    predicted_diagnosis = row$predicted_diagnosis,
                    confidence = row$confidence,
                    quality_flag = row$quality_flag,
                    primary_issue = row$primary_issue,
                    recommendation = row$recommendation
                ))
            }
        },

        .populateMarkerComparison = function() {

            comparison <- private$analysisState$markerComparison

            if (is.null(comparison) || nrow(comparison) == 0) {
                return()
            }

            table <- self$results$markerComparison

            # Limit to first 100 rows to avoid overwhelming output
            n_rows <- min(nrow(comparison), 100)

            for (i in 1:n_rows) {
                row <- comparison[i, ]
                table$addRow(rowKey=i, values=list(
                    case_id = row$case_id,
                    marker = row$marker,
                    query_value = row$query_value,
                    predicted_diagnosis = row$predicted_diagnosis,
                    centroid_value = row$centroid_value,
                    match_status = row$match_status
                ))
            }
        },

        .populateSummaryStats = function() {

            predictions <- private$analysisState$predictions

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            table <- self$results$predictionSummary

            n_total <- nrow(predictions)
            n_high <- sum(predictions$confidence_level == "High")
            n_moderate <- sum(predictions$confidence_level == "Moderate")
            n_low <- sum(predictions$confidence_level == "Low")
            n_very_low <- sum(predictions$confidence_level == "Very Low")

            mean_conf <- mean(predictions$confidence)
            median_conf <- median(predictions$confidence)

            table$addRow(rowKey=1, values=list(statistic="Total Cases", value=as.character(n_total)))
            table$addRow(rowKey=2, values=list(statistic="High Confidence", value=sprintf("%d (%.1f%%)", n_high, 100*n_high/n_total)))
            table$addRow(rowKey=3, values=list(statistic="Moderate Confidence", value=sprintf("%d (%.1f%%)", n_moderate, 100*n_moderate/n_total)))
            table$addRow(rowKey=4, values=list(statistic="Low Confidence", value=sprintf("%d (%.1f%%)", n_low, 100*n_low/n_total)))
            table$addRow(rowKey=5, values=list(statistic="Very Low Confidence", value=sprintf("%d (%.1f%%)", n_very_low, 100*n_very_low/n_total)))
            table$addRow(rowKey=6, values=list(statistic="Mean Confidence", value=sprintf("%.3f", mean_conf)))
            table$addRow(rowKey=7, values=list(statistic="Median Confidence", value=sprintf("%.3f", median_conf)))
        },

        .populateConfidenceByDiagnosis = function() {

            predictions <- private$analysisState$predictions

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            table <- self$results$confidenceByDiagnosis

            diagnoses <- unique(predictions$predicted_diagnosis)
            opts <- self$options

            for (dx in diagnoses) {
                dx_preds <- predictions[predictions$predicted_diagnosis == dx, ]

                n_cases <- nrow(dx_preds)
                mean_conf <- mean(dx_preds$confidence)
                median_conf <- median(dx_preds$confidence)
                min_conf <- min(dx_preds$confidence)
                max_conf <- max(dx_preds$confidence)
                n_high <- sum(dx_preds$confidence >= (opts$highConfidenceThreshold %||% 0.75))
                n_low <- sum(dx_preds$confidence < (opts$lowConfidenceThreshold %||% 0.25))

                table$addRow(rowKey=dx, values=list(
                    diagnosis = dx,
                    n_cases = n_cases,
                    mean_confidence = mean_conf,
                    median_confidence = median_conf,
                    min_confidence = min_conf,
                    max_confidence = max_conf,
                    n_high_confidence = n_high,
                    n_low_confidence = n_low
                ))
            }
        },

        .populateClinicalGuidance = function() {

            predictions <- private$analysisState$predictions

            if (is.null(predictions)) {
                return()
            }

            n_low <- sum(predictions$confidence < 0.25, na.rm = TRUE)
            n_moderate <- sum(predictions$confidence >= 0.25 & predictions$confidence < 0.75, na.rm = TRUE)

            html <- sprintf("
            <h3>Clinical Interpretation and Next Steps</h3>

            <h4>Confidence Level Interpretation:</h4>
            <ul>
                <li><strong>High (≥0.75):</strong> Strong evidence, matches known patterns → Accept diagnosis</li>
                <li><strong>Moderate (0.50-0.74):</strong> Reasonable evidence → Consider confirmatory testing</li>
                <li><strong>Low (0.25-0.49):</strong> Weak evidence → Recommend molecular testing</li>
                <li><strong>Very Low (<0.25):</strong> Insufficient evidence → Mandatory molecular testing</li>
            </ul>

            <h4>Recommended Actions:</h4>
            <ul>
                <li><strong>%d cases flagged as very low confidence:</strong> Review IHC staining quality, consider repeat staining, mandatory molecular testing</li>
                <li><strong>%d cases with moderate confidence:</strong> Consider molecular testing if clinically important for treatment decisions</li>
                <li><strong>All low/very low cases:</strong> Discuss at multidisciplinary tumor board</li>
            </ul>

            <p><strong>Note:</strong> These are algorithmic predictions based on training data. Clinical judgment, morphology, and molecular testing should guide final diagnosis.</p>
            ",
                n_low,
                n_moderate
            )

            self$results$clinicalGuidance$setContent(html)
        },

        .populateTechnicalDetails = function() {

            opts <- self$options
            model <- private$analysisState$trainingModel

            if (is.null(model)) {
                return()
            }

            html <- sprintf("
            <h3>Technical Details</h3>

            <h4>Prediction Method: %s</h4>
            <p>%s</p>

            <h4>Confidence Score Calculation:</h4>
            <ul>
                <li><strong>Panel Weight:</strong> %.2f</li>
                <li><strong>Distance Weight:</strong> %.2f</li>
                <li><strong>Silhouette Weight:</strong> %.2f</li>
            </ul>

            <h4>Training Model Details:</h4>
            <ul>
                <li><strong>Training Set Size:</strong> %d cases</li>
                <li><strong>Diagnoses:</strong> %s</li>
                <li><strong>Markers:</strong> %d (%d categorical, %d continuous)</li>
                <li><strong>Scaling:</strong> %s</li>
            </ul>
            ",
                opts$predictionMethod,
                switch(opts$predictionMethod,
                    hybrid = "Combines optimal panel rules, distance to centroids, and cluster quality metrics.",
                    distance = "Uses Euclidean distance to diagnosis centroids (nearest centroid classifier).",
                    rules = "Applies optimal antibody panel rules identified in training data.",
                    cluster = "Assigns to nearest cluster based on Gower distance.",
                    "Hybrid method combining multiple approaches."
                ),
                opts$panelWeight %||% 0.5,
                opts$distanceWeight %||% 0.3,
                opts$silhouetteWeight %||% 0.2,
                model$n_training,
                paste(model$diagnoses, collapse=", "),
                length(model$markerVars),
                length(model$catVars),
                length(model$contVars),
                ifelse(isTRUE(opts$scaleContVars), "Z-score normalization applied to continuous markers", "No scaling")
            )

            self$results$technicalDetails$setContent(html)
        },

        .populateExportSummary = function() {

            predictions <- private$analysisState$predictions

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            # Create copy-ready report
            lines <- c(
                "IHC DIAGNOSTIC PREDICTION REPORT",
                "=" %>% rep(50) %>% paste(collapse=""),
                "",
                sprintf("Analysis Date: %s", Sys.Date()),
                sprintf("Total Cases: %d", nrow(predictions)),
                sprintf("Prediction Method: %s", self$options$predictionMethod),
                "",
                "PREDICTIONS BY CONFIDENCE LEVEL:",
                sprintf("  High (≥0.75):       %d cases (%.1f%%)",
                    sum(predictions$confidence_level == "High"),
                    100*sum(predictions$confidence_level == "High")/nrow(predictions)),
                sprintf("  Moderate (0.50-0.74): %d cases (%.1f%%)",
                    sum(predictions$confidence_level == "Moderate"),
                    100*sum(predictions$confidence_level == "Moderate")/nrow(predictions)),
                sprintf("  Low (0.25-0.49):    %d cases (%.1f%%)",
                    sum(predictions$confidence_level == "Low"),
                    100*sum(predictions$confidence_level == "Low")/nrow(predictions)),
                sprintf("  Very Low (<0.25):   %d cases (%.1f%%)",
                    sum(predictions$confidence_level == "Very Low"),
                    100*sum(predictions$confidence_level == "Very Low")/nrow(predictions)),
                "",
                "PREDICTED DIAGNOSES:",
                ""
            )

            # Add per-diagnosis summary
            diagnoses <- unique(predictions$predicted_diagnosis)
            for (dx in diagnoses) {
                dx_count <- sum(predictions$predicted_diagnosis == dx)
                dx_mean_conf <- mean(predictions$confidence[predictions$predicted_diagnosis == dx])
                lines <- c(lines, sprintf("  %s: %d cases (mean confidence: %.3f)", dx, dx_count, dx_mean_conf))
            }

            lines <- c(lines,
                "",
                "CLINICAL RECOMMENDATIONS:",
                sprintf("  • %d cases require molecular testing (confidence < 0.25)",
                    sum(predictions$confidence < 0.25)),
                sprintf("  • %d cases should consider molecular testing (confidence 0.25-0.50)",
                    sum(predictions$confidence >= 0.25 & predictions$confidence < 0.50)),
                "  • All low-confidence cases should be discussed at tumor board",
                "",
                "This report was generated by ClinicoPath IHC Diagnostic Prediction module.",
                "Clinical judgment and molecular confirmation should guide final diagnosis."
            )

            report <- paste(lines, collapse="\n")
            self$results$exportSummary$setContent(report)
        },

        # ====================================================================
        # Plot Functions
        # ====================================================================

        .plotPredictions = function(image, ggtheme, theme, ...) {
            # Placeholder for PCA/MCA visualization
            # Future enhancement: Project query cases onto training PCA space
        },

        .plotConfidenceDistribution = function(image, ggtheme, theme, ...) {

            predictions <- private$analysisState$predictions

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            opts <- self$options

            # Create histogram
            p <- ggplot2::ggplot(predictions, ggplot2::aes(x=confidence)) +
                ggplot2::geom_histogram(bins=30, fill="steelblue", color="white", alpha=0.7) +
                ggplot2::geom_vline(xintercept=opts$highConfidenceThreshold %||% 0.75,
                                   linetype="dashed", color="darkgreen", linewidth=1) +
                ggplot2::geom_vline(xintercept=opts$lowConfidenceThreshold %||% 0.25,
                                   linetype="dashed", color="darkred", linewidth=1) +
                ggplot2::labs(
                    title="Prediction Confidence Distribution",
                    x="Confidence Score",
                    y="Number of Cases"
                ) +
                ggplot2::annotate("text", x=opts$highConfidenceThreshold %||% 0.75, y=Inf,
                                 label="High Confidence", vjust=2, hjust=1.1, color="darkgreen") +
                ggplot2::annotate("text", x=opts$lowConfidenceThreshold %||% 0.25, y=Inf,
                                 label="Low Confidence", vjust=2, hjust=-0.1, color="darkred") +
                ggtheme

            print(p)
            TRUE
        },

        .plotMarkerHeatmap = function(image, ggtheme, theme, ...) {
            # Placeholder for heatmap visualization
            # Future enhancement: Heatmap of query cases vs training centroids
        },

        # ====================================================================
        # Export Functions
        # ====================================================================

        .exportPredictions = function() {

            predictions <- private$analysisState$predictions
            opts <- self$options

            if (is.null(predictions) || nrow(predictions) == 0) {
                return()
            }

            # Add prediction columns to dataset
            predVarName <- opts$predictionVarName %||% "Predicted_Diagnosis"
            confVarName <- opts$confidenceVarName %||% "Prediction_Confidence"

            # Create new columns
            self$results$addColumn(
                name=predVarName,
                title="Predicted Diagnosis",
                type="text",
                values=predictions$predicted_diagnosis
            )

            self$results$addColumn(
                name=confVarName,
                title="Prediction Confidence",
                type="number",
                values=predictions$confidence
            )
        },

        # Analysis state storage
        analysisState = NULL
    )
)
