
# This file is automatically generated, you probably don't want to edit this

bayesiandiagnosticOptions <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "bayesiandiagnosticOptions",
    inherit = jmvcore::Options,
    public = list(
        initialize = function(
            testVariable = NULL,
            referenceStandard = NULL,
            centerVariable = NULL,
            analysisType = "probability_update",
            priorType = "noninformative",
            priorSensitivityAlpha = 1,
            priorSensitivityBeta = 1,
            priorSpecificityAlpha = 1,
            priorSpecificityBeta = 1,
            priorPrevalenceAlpha = 1,
            priorPrevalenceBeta = 1,
            mcmcSamples = 5000,
            mcmcBurnin = 1000,
            mcmcChains = 3,
            mcmcThin = 1,
            credibleLevel = 0.95,
            credibleType = "hpd",
            calculatePostTest = TRUE,
            priorProbabilityRange = "clinical",
            customPriorMin = 1,
            customPriorMax = 80,
            specificPriorProbs = "5, 10, 25, 50",
            modelComparison = FALSE,
            comparisonCriteria = "waic",
            hierarchicalModel = "fixed",
            showPosteriorSummary = TRUE,
            showDiagnosticMeasures = TRUE,
            showPostTestTable = TRUE,
            showModelComparison = FALSE,
            showConvergenceDiagnostics = TRUE,
            showBayesianInterpretation = TRUE,
            plotPosteriors = TRUE,
            plotPostTest = TRUE,
            plotConvergence = TRUE,
            plotModelComparison = FALSE,
            plotCredibleRegions = TRUE,
            robustPriors = FALSE,
            adaptiveSampling = TRUE,
            parallelProcessing = TRUE,
            randomSeed = 12345,
            expertElicitation = FALSE,
            expertSensitivityMean = 80,
            expertSensitivitySD = 10,
            expertSpecificityMean = 85,
            expertSpecificitySD = 10, ...) {

            super$initialize(
                package="ClinicoPath",
                name="bayesiandiagnostic",
                requiresData=TRUE,
                ...)

            private$..testVariable <- jmvcore::OptionVariable$new(
                "testVariable",
                testVariable,
                suggested=list(
                    "continuous",
                    "nominal"),
                permitted=list(
                    "numeric",
                    "factor"))
            private$..referenceStandard <- jmvcore::OptionVariable$new(
                "referenceStandard",
                referenceStandard,
                suggested=list(
                    "nominal"),
                permitted=list(
                    "factor"))
            private$..centerVariable <- jmvcore::OptionVariable$new(
                "centerVariable",
                centerVariable,
                suggested=list(
                    "nominal"),
                permitted=list(
                    "factor"))
            private$..analysisType <- jmvcore::OptionList$new(
                "analysisType",
                analysisType,
                options=list(
                    "probability_update",
                    "beta_binomial",
                    "hierarchical",
                    "model_averaging"),
                default="probability_update")
            private$..priorType <- jmvcore::OptionList$new(
                "priorType",
                priorType,
                options=list(
                    "noninformative",
                    "weakly_informative",
                    "informative",
                    "expert"),
                default="noninformative")
            private$..priorSensitivityAlpha <- jmvcore::OptionNumber$new(
                "priorSensitivityAlpha",
                priorSensitivityAlpha,
                min=0.001,
                default=1)
            private$..priorSensitivityBeta <- jmvcore::OptionNumber$new(
                "priorSensitivityBeta",
                priorSensitivityBeta,
                min=0.001,
                default=1)
            private$..priorSpecificityAlpha <- jmvcore::OptionNumber$new(
                "priorSpecificityAlpha",
                priorSpecificityAlpha,
                min=0.001,
                default=1)
            private$..priorSpecificityBeta <- jmvcore::OptionNumber$new(
                "priorSpecificityBeta",
                priorSpecificityBeta,
                min=0.001,
                default=1)
            private$..priorPrevalenceAlpha <- jmvcore::OptionNumber$new(
                "priorPrevalenceAlpha",
                priorPrevalenceAlpha,
                min=0.001,
                default=1)
            private$..priorPrevalenceBeta <- jmvcore::OptionNumber$new(
                "priorPrevalenceBeta",
                priorPrevalenceBeta,
                min=0.001,
                default=1)
            private$..mcmcSamples <- jmvcore::OptionInteger$new(
                "mcmcSamples",
                mcmcSamples,
                min=1000,
                max=50000,
                default=5000)
            private$..mcmcBurnin <- jmvcore::OptionInteger$new(
                "mcmcBurnin",
                mcmcBurnin,
                min=100,
                max=10000,
                default=1000)
            private$..mcmcChains <- jmvcore::OptionInteger$new(
                "mcmcChains",
                mcmcChains,
                min=1,
                max=8,
                default=3)
            private$..mcmcThin <- jmvcore::OptionInteger$new(
                "mcmcThin",
                mcmcThin,
                min=1,
                max=50,
                default=1)
            private$..credibleLevel <- jmvcore::OptionNumber$new(
                "credibleLevel",
                credibleLevel,
                min=0.8,
                max=0.99,
                default=0.95)
            private$..credibleType <- jmvcore::OptionList$new(
                "credibleType",
                credibleType,
                options=list(
                    "hpd",
                    "equal_tailed",
                    "both"),
                default="hpd")
            private$..calculatePostTest <- jmvcore::OptionBool$new(
                "calculatePostTest",
                calculatePostTest,
                default=TRUE)
            private$..priorProbabilityRange <- jmvcore::OptionList$new(
                "priorProbabilityRange",
                priorProbabilityRange,
                options=list(
                    "clinical",
                    "full",
                    "low",
                    "high",
                    "custom"),
                default="clinical")
            private$..customPriorMin <- jmvcore::OptionNumber$new(
                "customPriorMin",
                customPriorMin,
                min=0.01,
                max=99,
                default=1)
            private$..customPriorMax <- jmvcore::OptionNumber$new(
                "customPriorMax",
                customPriorMax,
                min=1,
                max=99.99,
                default=80)
            private$..specificPriorProbs <- jmvcore::OptionString$new(
                "specificPriorProbs",
                specificPriorProbs,
                default="5, 10, 25, 50")
            private$..modelComparison <- jmvcore::OptionBool$new(
                "modelComparison",
                modelComparison,
                default=FALSE)
            private$..comparisonCriteria <- jmvcore::OptionList$new(
                "comparisonCriteria",
                comparisonCriteria,
                options=list(
                    "dic",
                    "waic",
                    "loo",
                    "bayes_factors"),
                default="waic")
            private$..hierarchicalModel <- jmvcore::OptionList$new(
                "hierarchicalModel",
                hierarchicalModel,
                options=list(
                    "fixed",
                    "random_intercept",
                    "random_slope_intercept",
                    "full_hierarchical"),
                default="fixed")
            private$..showPosteriorSummary <- jmvcore::OptionBool$new(
                "showPosteriorSummary",
                showPosteriorSummary,
                default=TRUE)
            private$..showDiagnosticMeasures <- jmvcore::OptionBool$new(
                "showDiagnosticMeasures",
                showDiagnosticMeasures,
                default=TRUE)
            private$..showPostTestTable <- jmvcore::OptionBool$new(
                "showPostTestTable",
                showPostTestTable,
                default=TRUE)
            private$..showModelComparison <- jmvcore::OptionBool$new(
                "showModelComparison",
                showModelComparison,
                default=FALSE)
            private$..showConvergenceDiagnostics <- jmvcore::OptionBool$new(
                "showConvergenceDiagnostics",
                showConvergenceDiagnostics,
                default=TRUE)
            private$..showBayesianInterpretation <- jmvcore::OptionBool$new(
                "showBayesianInterpretation",
                showBayesianInterpretation,
                default=TRUE)
            private$..plotPosteriors <- jmvcore::OptionBool$new(
                "plotPosteriors",
                plotPosteriors,
                default=TRUE)
            private$..plotPostTest <- jmvcore::OptionBool$new(
                "plotPostTest",
                plotPostTest,
                default=TRUE)
            private$..plotConvergence <- jmvcore::OptionBool$new(
                "plotConvergence",
                plotConvergence,
                default=TRUE)
            private$..plotModelComparison <- jmvcore::OptionBool$new(
                "plotModelComparison",
                plotModelComparison,
                default=FALSE)
            private$..plotCredibleRegions <- jmvcore::OptionBool$new(
                "plotCredibleRegions",
                plotCredibleRegions,
                default=TRUE)
            private$..robustPriors <- jmvcore::OptionBool$new(
                "robustPriors",
                robustPriors,
                default=FALSE)
            private$..adaptiveSampling <- jmvcore::OptionBool$new(
                "adaptiveSampling",
                adaptiveSampling,
                default=TRUE)
            private$..parallelProcessing <- jmvcore::OptionBool$new(
                "parallelProcessing",
                parallelProcessing,
                default=TRUE)
            private$..randomSeed <- jmvcore::OptionInteger$new(
                "randomSeed",
                randomSeed,
                default=12345)
            private$..expertElicitation <- jmvcore::OptionBool$new(
                "expertElicitation",
                expertElicitation,
                default=FALSE)
            private$..expertSensitivityMean <- jmvcore::OptionNumber$new(
                "expertSensitivityMean",
                expertSensitivityMean,
                min=1,
                max=100,
                default=80)
            private$..expertSensitivitySD <- jmvcore::OptionNumber$new(
                "expertSensitivitySD",
                expertSensitivitySD,
                min=1,
                max=50,
                default=10)
            private$..expertSpecificityMean <- jmvcore::OptionNumber$new(
                "expertSpecificityMean",
                expertSpecificityMean,
                min=1,
                max=100,
                default=85)
            private$..expertSpecificitySD <- jmvcore::OptionNumber$new(
                "expertSpecificitySD",
                expertSpecificitySD,
                min=1,
                max=50,
                default=10)

            self$.addOption(private$..testVariable)
            self$.addOption(private$..referenceStandard)
            self$.addOption(private$..centerVariable)
            self$.addOption(private$..analysisType)
            self$.addOption(private$..priorType)
            self$.addOption(private$..priorSensitivityAlpha)
            self$.addOption(private$..priorSensitivityBeta)
            self$.addOption(private$..priorSpecificityAlpha)
            self$.addOption(private$..priorSpecificityBeta)
            self$.addOption(private$..priorPrevalenceAlpha)
            self$.addOption(private$..priorPrevalenceBeta)
            self$.addOption(private$..mcmcSamples)
            self$.addOption(private$..mcmcBurnin)
            self$.addOption(private$..mcmcChains)
            self$.addOption(private$..mcmcThin)
            self$.addOption(private$..credibleLevel)
            self$.addOption(private$..credibleType)
            self$.addOption(private$..calculatePostTest)
            self$.addOption(private$..priorProbabilityRange)
            self$.addOption(private$..customPriorMin)
            self$.addOption(private$..customPriorMax)
            self$.addOption(private$..specificPriorProbs)
            self$.addOption(private$..modelComparison)
            self$.addOption(private$..comparisonCriteria)
            self$.addOption(private$..hierarchicalModel)
            self$.addOption(private$..showPosteriorSummary)
            self$.addOption(private$..showDiagnosticMeasures)
            self$.addOption(private$..showPostTestTable)
            self$.addOption(private$..showModelComparison)
            self$.addOption(private$..showConvergenceDiagnostics)
            self$.addOption(private$..showBayesianInterpretation)
            self$.addOption(private$..plotPosteriors)
            self$.addOption(private$..plotPostTest)
            self$.addOption(private$..plotConvergence)
            self$.addOption(private$..plotModelComparison)
            self$.addOption(private$..plotCredibleRegions)
            self$.addOption(private$..robustPriors)
            self$.addOption(private$..adaptiveSampling)
            self$.addOption(private$..parallelProcessing)
            self$.addOption(private$..randomSeed)
            self$.addOption(private$..expertElicitation)
            self$.addOption(private$..expertSensitivityMean)
            self$.addOption(private$..expertSensitivitySD)
            self$.addOption(private$..expertSpecificityMean)
            self$.addOption(private$..expertSpecificitySD)
        }),
    active = list(
        testVariable = function() private$..testVariable$value,
        referenceStandard = function() private$..referenceStandard$value,
        centerVariable = function() private$..centerVariable$value,
        analysisType = function() private$..analysisType$value,
        priorType = function() private$..priorType$value,
        priorSensitivityAlpha = function() private$..priorSensitivityAlpha$value,
        priorSensitivityBeta = function() private$..priorSensitivityBeta$value,
        priorSpecificityAlpha = function() private$..priorSpecificityAlpha$value,
        priorSpecificityBeta = function() private$..priorSpecificityBeta$value,
        priorPrevalenceAlpha = function() private$..priorPrevalenceAlpha$value,
        priorPrevalenceBeta = function() private$..priorPrevalenceBeta$value,
        mcmcSamples = function() private$..mcmcSamples$value,
        mcmcBurnin = function() private$..mcmcBurnin$value,
        mcmcChains = function() private$..mcmcChains$value,
        mcmcThin = function() private$..mcmcThin$value,
        credibleLevel = function() private$..credibleLevel$value,
        credibleType = function() private$..credibleType$value,
        calculatePostTest = function() private$..calculatePostTest$value,
        priorProbabilityRange = function() private$..priorProbabilityRange$value,
        customPriorMin = function() private$..customPriorMin$value,
        customPriorMax = function() private$..customPriorMax$value,
        specificPriorProbs = function() private$..specificPriorProbs$value,
        modelComparison = function() private$..modelComparison$value,
        comparisonCriteria = function() private$..comparisonCriteria$value,
        hierarchicalModel = function() private$..hierarchicalModel$value,
        showPosteriorSummary = function() private$..showPosteriorSummary$value,
        showDiagnosticMeasures = function() private$..showDiagnosticMeasures$value,
        showPostTestTable = function() private$..showPostTestTable$value,
        showModelComparison = function() private$..showModelComparison$value,
        showConvergenceDiagnostics = function() private$..showConvergenceDiagnostics$value,
        showBayesianInterpretation = function() private$..showBayesianInterpretation$value,
        plotPosteriors = function() private$..plotPosteriors$value,
        plotPostTest = function() private$..plotPostTest$value,
        plotConvergence = function() private$..plotConvergence$value,
        plotModelComparison = function() private$..plotModelComparison$value,
        plotCredibleRegions = function() private$..plotCredibleRegions$value,
        robustPriors = function() private$..robustPriors$value,
        adaptiveSampling = function() private$..adaptiveSampling$value,
        parallelProcessing = function() private$..parallelProcessing$value,
        randomSeed = function() private$..randomSeed$value,
        expertElicitation = function() private$..expertElicitation$value,
        expertSensitivityMean = function() private$..expertSensitivityMean$value,
        expertSensitivitySD = function() private$..expertSensitivitySD$value,
        expertSpecificityMean = function() private$..expertSpecificityMean$value,
        expertSpecificitySD = function() private$..expertSpecificitySD$value),
    private = list(
        ..testVariable = NA,
        ..referenceStandard = NA,
        ..centerVariable = NA,
        ..analysisType = NA,
        ..priorType = NA,
        ..priorSensitivityAlpha = NA,
        ..priorSensitivityBeta = NA,
        ..priorSpecificityAlpha = NA,
        ..priorSpecificityBeta = NA,
        ..priorPrevalenceAlpha = NA,
        ..priorPrevalenceBeta = NA,
        ..mcmcSamples = NA,
        ..mcmcBurnin = NA,
        ..mcmcChains = NA,
        ..mcmcThin = NA,
        ..credibleLevel = NA,
        ..credibleType = NA,
        ..calculatePostTest = NA,
        ..priorProbabilityRange = NA,
        ..customPriorMin = NA,
        ..customPriorMax = NA,
        ..specificPriorProbs = NA,
        ..modelComparison = NA,
        ..comparisonCriteria = NA,
        ..hierarchicalModel = NA,
        ..showPosteriorSummary = NA,
        ..showDiagnosticMeasures = NA,
        ..showPostTestTable = NA,
        ..showModelComparison = NA,
        ..showConvergenceDiagnostics = NA,
        ..showBayesianInterpretation = NA,
        ..plotPosteriors = NA,
        ..plotPostTest = NA,
        ..plotConvergence = NA,
        ..plotModelComparison = NA,
        ..plotCredibleRegions = NA,
        ..robustPriors = NA,
        ..adaptiveSampling = NA,
        ..parallelProcessing = NA,
        ..randomSeed = NA,
        ..expertElicitation = NA,
        ..expertSensitivityMean = NA,
        ..expertSensitivitySD = NA,
        ..expertSpecificityMean = NA,
        ..expertSpecificitySD = NA)
)

bayesiandiagnosticResults <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "bayesiandiagnosticResults",
    inherit = jmvcore::Group,
    active = list(
        instructions = function() private$.items[["instructions"]],
        posteriorSummary = function() private$.items[["posteriorSummary"]],
        diagnosticMeasures = function() private$.items[["diagnosticMeasures"]],
        postTestTable = function() private$.items[["postTestTable"]],
        modelComparison = function() private$.items[["modelComparison"]],
        convergenceDiagnostics = function() private$.items[["convergenceDiagnostics"]],
        posteriorPlots = function() private$.items[["posteriorPlots"]],
        postTestPlots = function() private$.items[["postTestPlots"]],
        convergencePlots = function() private$.items[["convergencePlots"]],
        modelComparisonPlots = function() private$.items[["modelComparisonPlots"]],
        credibleRegionPlots = function() private$.items[["credibleRegionPlots"]],
        priorPosteriorComparison = function() private$.items[["priorPosteriorComparison"]],
        interpretationGuide = function() private$.items[["interpretationGuide"]],
        sensitivityAnalysis = function() private$.items[["sensitivityAnalysis"]],
        expertElicitationSummary = function() private$.items[["expertElicitationSummary"]]),
    private = list(),
    public=list(
        initialize=function(options) {
            super$initialize(
                options=options,
                name="",
                title="Bayesian Diagnostic Methods")
            self$add(jmvcore::Html$new(
                options=options,
                name="instructions",
                title="Analysis Guide",
                visible=TRUE))
            self$add(jmvcore::Table$new(
                options=options,
                name="posteriorSummary",
                title="Posterior Summary Statistics",
                rows=7,
                visible="(showPosteriorSummary)",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "priorType",
                    "mcmcSamples"),
                columns=list(
                    list(
                        `name`="parameter", 
                        `title`="Parameter", 
                        `type`="text"),
                    list(
                        `name`="posterior_mean", 
                        `title`="Posterior Mean", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="posterior_median", 
                        `title`="Posterior Median", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="credible_lower", 
                        `title`="Credible Lower", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="credible_upper", 
                        `title`="Credible Upper", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="interpretation", 
                        `title`="Clinical Interpretation", 
                        `type`="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="diagnosticMeasures",
                title="Diagnostic Performance Measures",
                rows=1,
                visible="(showDiagnosticMeasures)",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType"),
                columns=list(
                    list(
                        `name`="measure", 
                        `title`="Performance Measure", 
                        `type`="text"),
                    list(
                        `name`="estimate", 
                        `title`="Posterior Estimate", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="credible_interval", 
                        `title`="95% Credible Interval", 
                        `type`="text"),
                    list(
                        `name`="clinical_utility", 
                        `title`="Clinical Utility", 
                        `type`="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="postTestTable",
                title="Post-test Probabilities",
                visible="(showPostTestTable && calculatePostTest)",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "priorProbabilityRange",
                    "specificPriorProbs"),
                columns=list(
                    list(
                        `name`="prior_probability", 
                        `title`="Prior Probability (%)", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_test_positive", 
                        `title`="Post-test if Positive (%)", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_pos_credible_lower", 
                        `title`="Credible Lower", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_pos_credible_upper", 
                        `title`="Credible Upper", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_test_negative", 
                        `title`="Post-test if Negative (%)", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_neg_credible_lower", 
                        `title`="Credible Lower", 
                        `type`="number", 
                        `format`="dp:1"),
                    list(
                        `name`="post_neg_credible_upper", 
                        `title`="Credible Upper", 
                        `type`="number", 
                        `format`="dp:1"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="modelComparison",
                title="Bayesian Model Comparison",
                visible="(showModelComparison && modelComparison)",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "comparisonCriteria"),
                columns=list(
                    list(
                        `name`="model", 
                        `title`="Model", 
                        `type`="text"),
                    list(
                        `name`="dic", 
                        `title`="DIC", 
                        `type`="number", 
                        `format`="dp:2"),
                    list(
                        `name`="waic", 
                        `title`="WAIC", 
                        `type`="number", 
                        `format`="dp:2"),
                    list(
                        `name`="loo", 
                        `title`="LOO", 
                        `type`="number", 
                        `format`="dp:2"),
                    list(
                        `name`="model_weight", 
                        `title`="Model Weight", 
                        `type`="number", 
                        `format`="zto;dp:4"),
                    list(
                        `name`="ranking", 
                        `title`="Model Ranking", 
                        `type`="integer"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="convergenceDiagnostics",
                title="MCMC Convergence Diagnostics",
                rows=3,
                visible="(showConvergenceDiagnostics)",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "mcmcSamples",
                    "mcmcChains"),
                columns=list(
                    list(
                        `name`="diagnostic", 
                        `title`="Diagnostic", 
                        `type`="text"),
                    list(
                        `name`="sensitivity", 
                        `title`="Sensitivity", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="specificity", 
                        `title`="Specificity", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="prevalence", 
                        `title`="Prevalence", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="overall_status", 
                        `title`="Overall Status", 
                        `type`="text"))))
            self$add(jmvcore::Image$new(
                options=options,
                name="posteriorPlots",
                title="Posterior Distributions",
                width=600,
                height=400,
                visible="(plotPosteriors)",
                renderFun=".posteriorPlots",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "priorType",
                    "credibleLevel")))
            self$add(jmvcore::Image$new(
                options=options,
                name="postTestPlots",
                title="Post-test Probability Curves",
                width=600,
                height=400,
                visible="(plotPostTest && calculatePostTest)",
                renderFun=".postTestPlots",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "priorProbabilityRange")))
            self$add(jmvcore::Image$new(
                options=options,
                name="convergencePlots",
                title="MCMC Convergence Plots",
                width=800,
                height=500,
                visible="(plotConvergence)",
                renderFun=".convergencePlots",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "mcmcSamples",
                    "mcmcChains")))
            self$add(jmvcore::Image$new(
                options=options,
                name="modelComparisonPlots",
                title="Model Comparison Plots",
                width=600,
                height=400,
                visible="(plotModelComparison && modelComparison)",
                renderFun=".modelComparisonPlots",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "comparisonCriteria")))
            self$add(jmvcore::Image$new(
                options=options,
                name="credibleRegionPlots",
                title="Credible Region Plots",
                width=600,
                height=500,
                visible="(plotCredibleRegions)",
                renderFun=".credibleRegionPlots",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "analysisType",
                    "credibleLevel",
                    "credibleType")))
            self$add(jmvcore::Image$new(
                options=options,
                name="priorPosteriorComparison",
                title="Prior vs Posterior Comparison",
                width=700,
                height=400,
                visible="(priorType != 'noninformative')",
                renderFun=".priorPosteriorComparison",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "priorType",
                    "priorSensitivityAlpha",
                    "priorSensitivityBeta",
                    "priorSpecificityAlpha",
                    "priorSpecificityBeta")))
            self$add(jmvcore::Html$new(
                options=options,
                name="interpretationGuide",
                title="Bayesian Interpretation Guide",
                visible="(showBayesianInterpretation)"))
            self$add(jmvcore::Table$new(
                options=options,
                name="sensitivityAnalysis",
                title="Prior Sensitivity Analysis",
                visible="(priorType == 'informative')",
                clearWith=list(
                    "testVariable",
                    "referenceStandard",
                    "priorSensitivityAlpha",
                    "priorSensitivityBeta",
                    "priorSpecificityAlpha",
                    "priorSpecificityBeta"),
                columns=list(
                    list(
                        `name`="prior_scenario", 
                        `title`="Prior Scenario", 
                        `type`="text"),
                    list(
                        `name`="sens_posterior_mean", 
                        `title`="Sensitivity (Mean)", 
                        `type`="number", 
                        `format`="zto;dp:3"),
                    list(
                        `name`="sens_credible_width", 
                        `title`="Sensitivity CI Width", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="spec_posterior_mean", 
                        `title`="Specificity (Mean)", 
                        `type`="number", 
                        `format`="zto;dp:3"),
                    list(
                        `name`="spec_credible_width", 
                        `title`="Specificity CI Width", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="robustness_assessment", 
                        `title`="Robustness", 
                        `type`="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="expertElicitationSummary",
                title="Expert Prior Elicitation Summary",
                visible="(expertElicitation)",
                clearWith=list(
                    "expertSensitivityMean",
                    "expertSensitivitySD",
                    "expertSpecificityMean",
                    "expertSpecificitySD"),
                columns=list(
                    list(
                        `name`="parameter", 
                        `title`="Parameter", 
                        `type`="text"),
                    list(
                        `name`="expert_mean", 
                        `title`="Expert Estimate", 
                        `type`="number", 
                        `format`="zto;dp:3"),
                    list(
                        `name`="expert_uncertainty", 
                        `title`="Expert Uncertainty (SD)", 
                        `type`="number", 
                        `format`="dp:3"),
                    list(
                        `name`="implied_beta_alpha", 
                        `title`="Implied Beta \u03B1", 
                        `type`="number", 
                        `format`="dp:2"),
                    list(
                        `name`="implied_beta_beta", 
                        `title`="Implied Beta \u03B2", 
                        `type`="number", 
                        `format`="dp:2"),
                    list(
                        `name`="effective_sample_size", 
                        `title`="Effective Sample Size", 
                        `type`="number", 
                        `format`="dp:1"))))}))

bayesiandiagnosticBase <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "bayesiandiagnosticBase",
    inherit = jmvcore::Analysis,
    public = list(
        initialize = function(options, data=NULL, datasetId="", analysisId="", revision=0) {
            super$initialize(
                package = "ClinicoPath",
                name = "bayesiandiagnostic",
                version = c(0,0,1),
                options = options,
                results = bayesiandiagnosticResults$new(options=options),
                data = data,
                datasetId = datasetId,
                analysisId = analysisId,
                revision = revision,
                pause = NULL,
                completeWhenFilled = FALSE,
                requiresMissings = FALSE,
                weightsSupport = 'auto')
        }))

#' Bayesian Diagnostic Methods
#'
#' Comprehensive Bayesian diagnostic methods for medical decision-making and 
#' test evaluation.
#' 
#' **Key Features:**
#' - Bayesian diagnostic probability updates with post-test probability 
#' calculations
#' - Bayesian credible intervals as alternatives to frequentist confidence 
#' intervals
#' - Beta-binomial models for overdispersed diagnostic accuracy data
#' - Hierarchical Bayesian models for multi-center diagnostic studies
#' 
#' **Applications:**
#' - Clinical diagnostic test evaluation with uncertainty quantification
#' - Multi-center diagnostic accuracy studies with center-specific effects
#' - Prior information integration from expert knowledge or literature
#' - Bayesian model averaging for diagnostic test combinations
#' - Complex diagnostic workflows with dependency modeling
#' 
#' @param data The data as a data frame containing diagnostic test results and
#'   reference standard.
#' @param testVariable Diagnostic test results (continuous or categorical)
#' @param referenceStandard True disease status (binary: positive/negative)
#' @param centerVariable Variable for multi-center or multi-study analysis
#' @param analysisType Type of Bayesian diagnostic analysis
#' @param priorType Type of prior distribution to use
#' @param priorSensitivityAlpha Beta prior alpha parameter for sensitivity
#' @param priorSensitivityBeta Beta prior beta parameter for sensitivity
#' @param priorSpecificityAlpha Beta prior alpha parameter for specificity
#' @param priorSpecificityBeta Beta prior beta parameter for specificity
#' @param priorPrevalenceAlpha Beta prior alpha parameter for prevalence
#' @param priorPrevalenceBeta Beta prior beta parameter for prevalence
#' @param mcmcSamples Number of MCMC samples for posterior inference
#' @param mcmcBurnin Number of burn-in samples to discard
#' @param mcmcChains Number of parallel MCMC chains
#' @param mcmcThin MCMC thinning interval
#' @param credibleLevel Credible interval probability level
#' @param credibleType Type of credible interval calculation
#' @param calculatePostTest Calculate Bayesian post-test probabilities
#' @param priorProbabilityRange Range of prior probabilities for post-test
#'   calculation
#' @param customPriorMin Minimum prior probability for custom range
#' @param customPriorMax Maximum prior probability for custom range
#' @param specificPriorProbs Specific prior probability values for detailed
#'   analysis
#' @param modelComparison Compare multiple Bayesian models
#' @param comparisonCriteria Criteria for Bayesian model comparison
#' @param hierarchicalModel Hierarchical structure for multi-center studies
#' @param showPosteriorSummary Show posterior means, medians, and credible
#'   intervals
#' @param showDiagnosticMeasures Show sensitivity, specificity, PPV, NPV with
#'   credible intervals
#' @param showPostTestTable Show post-test probabilities at different prior
#'   probabilities
#' @param showModelComparison Show model comparison statistics
#' @param showConvergenceDiagnostics Show MCMC convergence assessment
#' @param showBayesianInterpretation Show interpretation of Bayesian results
#' @param plotPosteriors Plot posterior distributions for diagnostic
#'   parameters
#' @param plotPostTest Plot post-test probabilities vs prior probabilities
#' @param plotConvergence Plot MCMC trace plots and diagnostics
#' @param plotModelComparison Plot model comparison and averaging results
#' @param plotCredibleRegions Plot credible regions for diagnostic performance
#' @param robustPriors Use robust priors less sensitive to outliers
#' @param adaptiveSampling Use adaptive MCMC for improved sampling efficiency
#' @param parallelProcessing Use parallel processing for MCMC chains
#' @param randomSeed Random seed for reproducible results
#' @param expertElicitation Enable expert knowledge incorporation
#' @param expertSensitivityMean Expert estimate of test sensitivity
#' @param expertSensitivitySD Expert uncertainty about sensitivity estimate
#' @param expertSpecificityMean Expert estimate of test specificity
#' @param expertSpecificitySD Expert uncertainty about specificity estimate
#' @return A results object containing:
#' \tabular{llllll}{
#'   \code{results$instructions} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$posteriorSummary} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$diagnosticMeasures} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$postTestTable} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$modelComparison} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$convergenceDiagnostics} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$posteriorPlots} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$postTestPlots} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$convergencePlots} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$modelComparisonPlots} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$credibleRegionPlots} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$priorPosteriorComparison} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$interpretationGuide} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$sensitivityAnalysis} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$expertElicitationSummary} \tab \tab \tab \tab \tab a table \cr
#' }
#'
#' Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:
#'
#' \code{results$posteriorSummary$asDF}
#'
#' \code{as.data.frame(results$posteriorSummary)}
#'
#' @export
bayesiandiagnostic <- function(
    data,
    testVariable,
    referenceStandard,
    centerVariable,
    analysisType = "probability_update",
    priorType = "noninformative",
    priorSensitivityAlpha = 1,
    priorSensitivityBeta = 1,
    priorSpecificityAlpha = 1,
    priorSpecificityBeta = 1,
    priorPrevalenceAlpha = 1,
    priorPrevalenceBeta = 1,
    mcmcSamples = 5000,
    mcmcBurnin = 1000,
    mcmcChains = 3,
    mcmcThin = 1,
    credibleLevel = 0.95,
    credibleType = "hpd",
    calculatePostTest = TRUE,
    priorProbabilityRange = "clinical",
    customPriorMin = 1,
    customPriorMax = 80,
    specificPriorProbs = "5, 10, 25, 50",
    modelComparison = FALSE,
    comparisonCriteria = "waic",
    hierarchicalModel = "fixed",
    showPosteriorSummary = TRUE,
    showDiagnosticMeasures = TRUE,
    showPostTestTable = TRUE,
    showModelComparison = FALSE,
    showConvergenceDiagnostics = TRUE,
    showBayesianInterpretation = TRUE,
    plotPosteriors = TRUE,
    plotPostTest = TRUE,
    plotConvergence = TRUE,
    plotModelComparison = FALSE,
    plotCredibleRegions = TRUE,
    robustPriors = FALSE,
    adaptiveSampling = TRUE,
    parallelProcessing = TRUE,
    randomSeed = 12345,
    expertElicitation = FALSE,
    expertSensitivityMean = 80,
    expertSensitivitySD = 10,
    expertSpecificityMean = 85,
    expertSpecificitySD = 10) {

    if ( ! requireNamespace("jmvcore", quietly=TRUE))
        stop("bayesiandiagnostic requires jmvcore to be installed (restart may be required)")

    if ( ! missing(testVariable)) testVariable <- jmvcore::resolveQuo(jmvcore::enquo(testVariable))
    if ( ! missing(referenceStandard)) referenceStandard <- jmvcore::resolveQuo(jmvcore::enquo(referenceStandard))
    if ( ! missing(centerVariable)) centerVariable <- jmvcore::resolveQuo(jmvcore::enquo(centerVariable))
    if (missing(data))
        data <- jmvcore::marshalData(
            parent.frame(),
            `if`( ! missing(testVariable), testVariable, NULL),
            `if`( ! missing(referenceStandard), referenceStandard, NULL),
            `if`( ! missing(centerVariable), centerVariable, NULL))

    for (v in referenceStandard) if (v %in% names(data)) data[[v]] <- as.factor(data[[v]])
    for (v in centerVariable) if (v %in% names(data)) data[[v]] <- as.factor(data[[v]])

    options <- bayesiandiagnosticOptions$new(
        testVariable = testVariable,
        referenceStandard = referenceStandard,
        centerVariable = centerVariable,
        analysisType = analysisType,
        priorType = priorType,
        priorSensitivityAlpha = priorSensitivityAlpha,
        priorSensitivityBeta = priorSensitivityBeta,
        priorSpecificityAlpha = priorSpecificityAlpha,
        priorSpecificityBeta = priorSpecificityBeta,
        priorPrevalenceAlpha = priorPrevalenceAlpha,
        priorPrevalenceBeta = priorPrevalenceBeta,
        mcmcSamples = mcmcSamples,
        mcmcBurnin = mcmcBurnin,
        mcmcChains = mcmcChains,
        mcmcThin = mcmcThin,
        credibleLevel = credibleLevel,
        credibleType = credibleType,
        calculatePostTest = calculatePostTest,
        priorProbabilityRange = priorProbabilityRange,
        customPriorMin = customPriorMin,
        customPriorMax = customPriorMax,
        specificPriorProbs = specificPriorProbs,
        modelComparison = modelComparison,
        comparisonCriteria = comparisonCriteria,
        hierarchicalModel = hierarchicalModel,
        showPosteriorSummary = showPosteriorSummary,
        showDiagnosticMeasures = showDiagnosticMeasures,
        showPostTestTable = showPostTestTable,
        showModelComparison = showModelComparison,
        showConvergenceDiagnostics = showConvergenceDiagnostics,
        showBayesianInterpretation = showBayesianInterpretation,
        plotPosteriors = plotPosteriors,
        plotPostTest = plotPostTest,
        plotConvergence = plotConvergence,
        plotModelComparison = plotModelComparison,
        plotCredibleRegions = plotCredibleRegions,
        robustPriors = robustPriors,
        adaptiveSampling = adaptiveSampling,
        parallelProcessing = parallelProcessing,
        randomSeed = randomSeed,
        expertElicitation = expertElicitation,
        expertSensitivityMean = expertSensitivityMean,
        expertSensitivitySD = expertSensitivitySD,
        expertSpecificityMean = expertSpecificityMean,
        expertSpecificitySD = expertSpecificitySD)

    analysis <- bayesiandiagnosticClass$new(
        options = options,
        data = data)

    analysis$run()

    analysis$results
}

