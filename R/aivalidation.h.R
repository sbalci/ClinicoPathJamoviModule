
# This file is automatically generated, you probably don't want to edit this

aivalidationOptions <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "aivalidationOptions",
    inherit = jmvcore::Options,
    public = list(
        initialize = function(
            predictorVars = NULL,
            outcomeVar = NULL,
            positiveLevel = NULL,
            compareModels = FALSE,
            youdensJ = FALSE,
            matthewsCC = FALSE,
            bootstrapCI = FALSE,
            nBootstrap = 1000,
            rocPlot = FALSE,
            crossValidation = "none",
            stratified = TRUE,
            randomSeed = 42,
            showExplanations = FALSE,
            showSummaries = FALSE, ...) {

            super$initialize(
                package="ClinicoPath",
                name="aivalidation",
                requiresData=TRUE,
                ...)

            private$..predictorVars <- jmvcore::OptionVariables$new(
                "predictorVars",
                predictorVars,
                suggested=list(
                    "continuous"),
                permitted=list(
                    "numeric"))
            private$..outcomeVar <- jmvcore::OptionVariable$new(
                "outcomeVar",
                outcomeVar,
                suggested=list(
                    "ordinal",
                    "nominal"),
                permitted=list(
                    "factor"))
            private$..positiveLevel <- jmvcore::OptionLevel$new(
                "positiveLevel",
                positiveLevel,
                variable="(outcomeVar)")
            private$..compareModels <- jmvcore::OptionBool$new(
                "compareModels",
                compareModels,
                default=FALSE)
            private$..youdensJ <- jmvcore::OptionBool$new(
                "youdensJ",
                youdensJ,
                default=FALSE)
            private$..matthewsCC <- jmvcore::OptionBool$new(
                "matthewsCC",
                matthewsCC,
                default=FALSE)
            private$..bootstrapCI <- jmvcore::OptionBool$new(
                "bootstrapCI",
                bootstrapCI,
                default=FALSE)
            private$..nBootstrap <- jmvcore::OptionInteger$new(
                "nBootstrap",
                nBootstrap,
                min=100,
                max=5000,
                default=1000)
            private$..rocPlot <- jmvcore::OptionBool$new(
                "rocPlot",
                rocPlot,
                default=FALSE)
            private$..crossValidation <- jmvcore::OptionList$new(
                "crossValidation",
                crossValidation,
                options=list(
                    "none",
                    "5-fold",
                    "10-fold"),
                default="none")
            private$..stratified <- jmvcore::OptionBool$new(
                "stratified",
                stratified,
                default=TRUE)
            private$..randomSeed <- jmvcore::OptionInteger$new(
                "randomSeed",
                randomSeed,
                min=1,
                default=42)
            private$..showExplanations <- jmvcore::OptionBool$new(
                "showExplanations",
                showExplanations,
                default=FALSE)
            private$..showSummaries <- jmvcore::OptionBool$new(
                "showSummaries",
                showSummaries,
                default=FALSE)

            self$.addOption(private$..predictorVars)
            self$.addOption(private$..outcomeVar)
            self$.addOption(private$..positiveLevel)
            self$.addOption(private$..compareModels)
            self$.addOption(private$..youdensJ)
            self$.addOption(private$..matthewsCC)
            self$.addOption(private$..bootstrapCI)
            self$.addOption(private$..nBootstrap)
            self$.addOption(private$..rocPlot)
            self$.addOption(private$..crossValidation)
            self$.addOption(private$..stratified)
            self$.addOption(private$..randomSeed)
            self$.addOption(private$..showExplanations)
            self$.addOption(private$..showSummaries)
        }),
    active = list(
        predictorVars = function() private$..predictorVars$value,
        outcomeVar = function() private$..outcomeVar$value,
        positiveLevel = function() private$..positiveLevel$value,
        compareModels = function() private$..compareModels$value,
        youdensJ = function() private$..youdensJ$value,
        matthewsCC = function() private$..matthewsCC$value,
        bootstrapCI = function() private$..bootstrapCI$value,
        nBootstrap = function() private$..nBootstrap$value,
        rocPlot = function() private$..rocPlot$value,
        crossValidation = function() private$..crossValidation$value,
        stratified = function() private$..stratified$value,
        randomSeed = function() private$..randomSeed$value,
        showExplanations = function() private$..showExplanations$value,
        showSummaries = function() private$..showSummaries$value),
    private = list(
        ..predictorVars = NA,
        ..outcomeVar = NA,
        ..positiveLevel = NA,
        ..compareModels = NA,
        ..youdensJ = NA,
        ..matthewsCC = NA,
        ..bootstrapCI = NA,
        ..nBootstrap = NA,
        ..rocPlot = NA,
        ..crossValidation = NA,
        ..stratified = NA,
        ..randomSeed = NA,
        ..showExplanations = NA,
        ..showSummaries = NA)
)

aivalidationResults <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "aivalidationResults",
    inherit = jmvcore::Group,
    active = list(
        instructions = function() private$.items[["instructions"]],
        performanceTable = function() private$.items[["performanceTable"]],
        comparisonTable = function() private$.items[["comparisonTable"]],
        cvPerformanceTable = function() private$.items[["cvPerformanceTable"]],
        rocPlot = function() private$.items[["rocPlot"]],
        methodologyExplanation = function() private$.items[["methodologyExplanation"]],
        resultsInterpretation = function() private$.items[["resultsInterpretation"]]),
    private = list(),
    public=list(
        initialize=function(options) {
            super$initialize(
                options=options,
                name="",
                title="AI Model Validation")
            self$add(jmvcore::Html$new(
                options=options,
                name="instructions",
                title="Instructions",
                visible=FALSE))
            self$add(jmvcore::Table$new(
                options=options,
                name="performanceTable",
                title="Model Performance Metrics",
                clearWith=list(
                    "predictorVars",
                    "outcomeVar",
                    "positiveLevel"),
                columns=list(
                    list(
                        `name`="predictor", 
                        `title`="Predictor", 
                        `type`="text"),
                    list(
                        `name`="auc", 
                        `title`="AUC", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="auc_lower", 
                        `title`="AUC 95% CI Lower", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="auc_upper", 
                        `title`="AUC 95% CI Upper", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="sensitivity", 
                        `title`="Sensitivity", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="specificity", 
                        `title`="Specificity", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="threshold", 
                        `title`="Optimal Threshold", 
                        `type`="number"),
                    list(
                        `name`="youdens_j", 
                        `title`="Youden's J", 
                        `type`="number", 
                        `format`="zto", 
                        `visible`="(youdensJ)"),
                    list(
                        `name`="mcc", 
                        `title`="MCC", 
                        `type`="number", 
                        `format`="zto", 
                        `visible`="(matthewsCC)"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="comparisonTable",
                title="Model Comparison (DeLong Test)",
                visible="(compareModels)",
                clearWith=list(
                    "predictorVars",
                    "outcomeVar",
                    "compareModels"),
                columns=list(
                    list(
                        `name`="comparison", 
                        `title`="Comparison", 
                        `type`="text"),
                    list(
                        `name`="auc1", 
                        `title`="AUC (Model 1)", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="auc2", 
                        `title`="AUC (Model 2)", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="difference", 
                        `title`="Difference", 
                        `type`="number"),
                    list(
                        `name`="p_value", 
                        `title`="p-value", 
                        `type`="number", 
                        `format`="zto,pvalue"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="cvPerformanceTable",
                title="Cross-Validation Performance",
                visible="(!crossValidation:none)",
                clearWith=list(
                    "predictorVars",
                    "outcomeVar",
                    "positiveLevel",
                    "crossValidation",
                    "stratified",
                    "randomSeed"),
                columns=list(
                    list(
                        `name`="predictor", 
                        `title`="Predictor", 
                        `type`="text"),
                    list(
                        `name`="mean_auc", 
                        `title`="Mean AUC", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="sd_auc", 
                        `title`="SD AUC", 
                        `type`="number"),
                    list(
                        `name`="mean_sensitivity", 
                        `title`="Mean Sensitivity", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="sd_sensitivity", 
                        `title`="SD Sensitivity", 
                        `type`="number"),
                    list(
                        `name`="mean_specificity", 
                        `title`="Mean Specificity", 
                        `type`="number", 
                        `format`="zto"),
                    list(
                        `name`="sd_specificity", 
                        `title`="SD Specificity", 
                        `type`="number"))))
            self$add(jmvcore::Image$new(
                options=options,
                name="rocPlot",
                title="ROC Curves",
                visible="(rocPlot)",
                requiresData=TRUE,
                width=600,
                height=450,
                renderFun=".plotROC",
                clearWith=list(
                    "predictorVars",
                    "outcomeVar",
                    "positiveLevel")))
            self$add(jmvcore::Html$new(
                options=options,
                name="methodologyExplanation",
                title="Methodology",
                visible="(showExplanations)"))
            self$add(jmvcore::Html$new(
                options=options,
                name="resultsInterpretation",
                title="Interpretation",
                visible="(showSummaries)"))}))

aivalidationBase <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "aivalidationBase",
    inherit = jmvcore::Analysis,
    public = list(
        initialize = function(options, data=NULL, datasetId="", analysisId="", revision=0) {
            super$initialize(
                package = "ClinicoPath",
                name = "aivalidation",
                version = c(0,0,32),
                options = options,
                results = aivalidationResults$new(options=options),
                data = data,
                datasetId = datasetId,
                analysisId = analysisId,
                revision = revision,
                pause = NULL,
                completeWhenFilled = FALSE,
                requiresMissings = FALSE,
                weightsSupport = 'auto')
        }))

#' AI Model Validation
#'
#' Simplified AI model validation tool for comparing diagnostic performance. 
#' Calculates AUC, sensitivity, and specificity for predictor variables and 
#' performs statistical comparison using DeLong test.
#' 
#'
#' @examples
#' \donttest{
#' data('medical_ai_data', package='ClinicoPath')
#'
#' aivalidation(data = medical_ai_data,
#'             predictorVars = c('AI_score', 'human_score', 'biomarker1'),
#'             outcomeVar = 'diagnosis',
#'             positiveLevel = 'positive',
#'             compareModels = TRUE)
#'}
#' @param data the data as a data frame
#' @param predictorVars a vector of strings naming the predictor variables (AI
#'   scores, human scores, biomarkers, etc.) from \code{data}. Limited to first
#'   5 for pairwise comparisons.
#' @param outcomeVar a string naming the binary outcome variable (gold
#'   standard) from \code{data}
#' @param positiveLevel the level of the outcome variable which represents the
#'   positive case
#' @param compareModels perform statistical comparison between models using
#'   DeLong test for AUC comparison
#' @param youdensJ calculate and display Youden's J statistic (Sensitivity +
#'   Specificity - 1)
#' @param matthewsCC calculate and display Matthews Correlation Coefficient
#'   (MCC)
#' @param bootstrapCI use bootstrap resampling for confidence intervals (more
#'   robust for small samples)
#' @param nBootstrap number of bootstrap iterations (higher values are more
#'   accurate but slower)
#' @param rocPlot generate ROC curves for all predictor variables
#' @param crossValidation cross-validation method for model validation
#'   (simplified to avoid resource limits)
#' @param stratified maintain outcome variable proportions across folds
#' @param randomSeed random seed for reproducible cross-validation results
#' @param showExplanations show detailed methodology explanations
#' @param showSummaries show interpretation summaries of results
#' @return A results object containing:
#' \tabular{llllll}{
#'   \code{results$instructions} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$performanceTable} \tab \tab \tab \tab \tab Performance metrics for each predictor variable \cr
#'   \code{results$comparisonTable} \tab \tab \tab \tab \tab Statistical comparison between predictor models using DeLong test \cr
#'   \code{results$cvPerformanceTable} \tab \tab \tab \tab \tab Cross-validated performance metrics for each predictor \cr
#'   \code{results$rocPlot} \tab \tab \tab \tab \tab ROC curves for all predictor models \cr
#'   \code{results$methodologyExplanation} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$resultsInterpretation} \tab \tab \tab \tab \tab a html \cr
#' }
#'
#' Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:
#'
#' \code{results$performanceTable$asDF}
#'
#' \code{as.data.frame(results$performanceTable)}
#'
#' @export
aivalidation <- function(
    data,
    predictorVars,
    outcomeVar,
    positiveLevel,
    compareModels = FALSE,
    youdensJ = FALSE,
    matthewsCC = FALSE,
    bootstrapCI = FALSE,
    nBootstrap = 1000,
    rocPlot = FALSE,
    crossValidation = "none",
    stratified = TRUE,
    randomSeed = 42,
    showExplanations = FALSE,
    showSummaries = FALSE) {

    if ( ! requireNamespace("jmvcore", quietly=TRUE))
        stop("aivalidation requires jmvcore to be installed (restart may be required)")

    if ( ! missing(predictorVars)) predictorVars <- jmvcore::resolveQuo(jmvcore::enquo(predictorVars))
    if ( ! missing(outcomeVar)) outcomeVar <- jmvcore::resolveQuo(jmvcore::enquo(outcomeVar))
    if (missing(data))
        data <- jmvcore::marshalData(
            parent.frame(),
            `if`( ! missing(predictorVars), predictorVars, NULL),
            `if`( ! missing(outcomeVar), outcomeVar, NULL))

    for (v in outcomeVar) if (v %in% names(data)) data[[v]] <- as.factor(data[[v]])

    options <- aivalidationOptions$new(
        predictorVars = predictorVars,
        outcomeVar = outcomeVar,
        positiveLevel = positiveLevel,
        compareModels = compareModels,
        youdensJ = youdensJ,
        matthewsCC = matthewsCC,
        bootstrapCI = bootstrapCI,
        nBootstrap = nBootstrap,
        rocPlot = rocPlot,
        crossValidation = crossValidation,
        stratified = stratified,
        randomSeed = randomSeed,
        showExplanations = showExplanations,
        showSummaries = showSummaries)

    analysis <- aivalidationClass$new(
        options = options,
        data = data)

    analysis$run()

    analysis$results
}

