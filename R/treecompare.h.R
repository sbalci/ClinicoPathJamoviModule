
# This file is automatically generated, you probably don't want to edit this

treecompareOptions <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "treecompareOptions",
    inherit = jmvcore::Options,
    public = list(
        initialize = function(
            vars = NULL,
            facs = NULL,
            target = NULL,
            targetLevel = NULL,
            include_cart = TRUE,
            include_rf = TRUE,
            include_gbm = FALSE,
            include_xgboost = FALSE,
            include_ctree = FALSE,
            validation = "repeated_cv",
            cv_folds = 5,
            cv_repeats = 5,
            bootstrap_samples = 200,
            test_split = 0.25,
            stratified_sampling = TRUE,
            primary_metric = "bacc",
            statistical_testing = TRUE,
            correction_method = "holm",
            tune_parameters = TRUE,
            tuning_method = "grid",
            cart_max_depth = 5,
            cart_min_split = 20,
            rf_ntrees = 500,
            rf_mtry_method = "auto",
            clinical_context = "diagnosis",
            interpretability_weight = 0.3,
            show_comparison_table = TRUE,
            show_performance_plot = TRUE,
            show_roc_comparison = TRUE,
            show_statistical_tests = TRUE,
            show_ranking_table = TRUE,
            show_computational_time = TRUE,
            show_clinical_recommendations = TRUE,
            show_detailed_metrics = FALSE,
            ensemble_best_models = FALSE,
            save_best_models = FALSE,
            set_seed = TRUE,
            seed_value = 42,
            parallel_processing = TRUE,
            verbose_output = FALSE, ...) {

            super$initialize(
                package="ClinicoPath",
                name="treecompare",
                requiresData=TRUE,
                ...)

            private$..vars <- jmvcore::OptionVariables$new(
                "vars",
                vars,
                suggested=list(
                    "continuous"),
                permitted=list(
                    "numeric"),
                default=NULL)
            private$..facs <- jmvcore::OptionVariables$new(
                "facs",
                facs,
                suggested=list(
                    "ordinal",
                    "nominal"),
                permitted=list(
                    "factor"),
                default=NULL)
            private$..target <- jmvcore::OptionVariable$new(
                "target",
                target,
                suggested=list(
                    "ordinal",
                    "nominal"),
                permitted=list(
                    "factor"))
            private$..targetLevel <- jmvcore::OptionLevel$new(
                "targetLevel",
                targetLevel,
                variable="(target)")
            private$..include_cart <- jmvcore::OptionBool$new(
                "include_cart",
                include_cart,
                default=TRUE)
            private$..include_rf <- jmvcore::OptionBool$new(
                "include_rf",
                include_rf,
                default=TRUE)
            private$..include_gbm <- jmvcore::OptionBool$new(
                "include_gbm",
                include_gbm,
                default=FALSE)
            private$..include_xgboost <- jmvcore::OptionBool$new(
                "include_xgboost",
                include_xgboost,
                default=FALSE)
            private$..include_ctree <- jmvcore::OptionBool$new(
                "include_ctree",
                include_ctree,
                default=FALSE)
            private$..validation <- jmvcore::OptionList$new(
                "validation",
                validation,
                options=list(
                    "repeated_cv",
                    "cv",
                    "bootstrap",
                    "holdout"),
                default="repeated_cv")
            private$..cv_folds <- jmvcore::OptionInteger$new(
                "cv_folds",
                cv_folds,
                default=5,
                min=3,
                max=10)
            private$..cv_repeats <- jmvcore::OptionInteger$new(
                "cv_repeats",
                cv_repeats,
                default=5,
                min=3,
                max=10)
            private$..bootstrap_samples <- jmvcore::OptionInteger$new(
                "bootstrap_samples",
                bootstrap_samples,
                default=200,
                min=100,
                max=500)
            private$..test_split <- jmvcore::OptionNumber$new(
                "test_split",
                test_split,
                default=0.25,
                min=0.1,
                max=0.4)
            private$..stratified_sampling <- jmvcore::OptionBool$new(
                "stratified_sampling",
                stratified_sampling,
                default=TRUE)
            private$..primary_metric <- jmvcore::OptionList$new(
                "primary_metric",
                primary_metric,
                options=list(
                    "bacc",
                    "auc",
                    "accuracy",
                    "sensitivity",
                    "specificity",
                    "f1"),
                default="bacc")
            private$..statistical_testing <- jmvcore::OptionBool$new(
                "statistical_testing",
                statistical_testing,
                default=TRUE)
            private$..correction_method <- jmvcore::OptionList$new(
                "correction_method",
                correction_method,
                options=list(
                    "bonferroni",
                    "holm",
                    "fdr",
                    "none"),
                default="holm")
            private$..tune_parameters <- jmvcore::OptionBool$new(
                "tune_parameters",
                tune_parameters,
                default=TRUE)
            private$..tuning_method <- jmvcore::OptionList$new(
                "tuning_method",
                tuning_method,
                options=list(
                    "grid",
                    "random"),
                default="grid")
            private$..cart_max_depth <- jmvcore::OptionInteger$new(
                "cart_max_depth",
                cart_max_depth,
                default=5,
                min=2,
                max=10)
            private$..cart_min_split <- jmvcore::OptionInteger$new(
                "cart_min_split",
                cart_min_split,
                default=20,
                min=5,
                max=100)
            private$..rf_ntrees <- jmvcore::OptionInteger$new(
                "rf_ntrees",
                rf_ntrees,
                default=500,
                min=100,
                max=1000)
            private$..rf_mtry_method <- jmvcore::OptionList$new(
                "rf_mtry_method",
                rf_mtry_method,
                options=list(
                    "auto",
                    "third",
                    "all"),
                default="auto")
            private$..clinical_context <- jmvcore::OptionList$new(
                "clinical_context",
                clinical_context,
                options=list(
                    "diagnosis",
                    "screening",
                    "prognosis",
                    "treatment",
                    "risk"),
                default="diagnosis")
            private$..interpretability_weight <- jmvcore::OptionNumber$new(
                "interpretability_weight",
                interpretability_weight,
                default=0.3,
                min=0,
                max=1)
            private$..show_comparison_table <- jmvcore::OptionBool$new(
                "show_comparison_table",
                show_comparison_table,
                default=TRUE)
            private$..show_performance_plot <- jmvcore::OptionBool$new(
                "show_performance_plot",
                show_performance_plot,
                default=TRUE)
            private$..show_roc_comparison <- jmvcore::OptionBool$new(
                "show_roc_comparison",
                show_roc_comparison,
                default=TRUE)
            private$..show_statistical_tests <- jmvcore::OptionBool$new(
                "show_statistical_tests",
                show_statistical_tests,
                default=TRUE)
            private$..show_ranking_table <- jmvcore::OptionBool$new(
                "show_ranking_table",
                show_ranking_table,
                default=TRUE)
            private$..show_computational_time <- jmvcore::OptionBool$new(
                "show_computational_time",
                show_computational_time,
                default=TRUE)
            private$..show_clinical_recommendations <- jmvcore::OptionBool$new(
                "show_clinical_recommendations",
                show_clinical_recommendations,
                default=TRUE)
            private$..show_detailed_metrics <- jmvcore::OptionBool$new(
                "show_detailed_metrics",
                show_detailed_metrics,
                default=FALSE)
            private$..ensemble_best_models <- jmvcore::OptionBool$new(
                "ensemble_best_models",
                ensemble_best_models,
                default=FALSE)
            private$..save_best_models <- jmvcore::OptionBool$new(
                "save_best_models",
                save_best_models,
                default=FALSE)
            private$..set_seed <- jmvcore::OptionBool$new(
                "set_seed",
                set_seed,
                default=TRUE)
            private$..seed_value <- jmvcore::OptionInteger$new(
                "seed_value",
                seed_value,
                default=42,
                min=1,
                max=999999)
            private$..parallel_processing <- jmvcore::OptionBool$new(
                "parallel_processing",
                parallel_processing,
                default=TRUE)
            private$..verbose_output <- jmvcore::OptionBool$new(
                "verbose_output",
                verbose_output,
                default=FALSE)

            self$.addOption(private$..vars)
            self$.addOption(private$..facs)
            self$.addOption(private$..target)
            self$.addOption(private$..targetLevel)
            self$.addOption(private$..include_cart)
            self$.addOption(private$..include_rf)
            self$.addOption(private$..include_gbm)
            self$.addOption(private$..include_xgboost)
            self$.addOption(private$..include_ctree)
            self$.addOption(private$..validation)
            self$.addOption(private$..cv_folds)
            self$.addOption(private$..cv_repeats)
            self$.addOption(private$..bootstrap_samples)
            self$.addOption(private$..test_split)
            self$.addOption(private$..stratified_sampling)
            self$.addOption(private$..primary_metric)
            self$.addOption(private$..statistical_testing)
            self$.addOption(private$..correction_method)
            self$.addOption(private$..tune_parameters)
            self$.addOption(private$..tuning_method)
            self$.addOption(private$..cart_max_depth)
            self$.addOption(private$..cart_min_split)
            self$.addOption(private$..rf_ntrees)
            self$.addOption(private$..rf_mtry_method)
            self$.addOption(private$..clinical_context)
            self$.addOption(private$..interpretability_weight)
            self$.addOption(private$..show_comparison_table)
            self$.addOption(private$..show_performance_plot)
            self$.addOption(private$..show_roc_comparison)
            self$.addOption(private$..show_statistical_tests)
            self$.addOption(private$..show_ranking_table)
            self$.addOption(private$..show_computational_time)
            self$.addOption(private$..show_clinical_recommendations)
            self$.addOption(private$..show_detailed_metrics)
            self$.addOption(private$..ensemble_best_models)
            self$.addOption(private$..save_best_models)
            self$.addOption(private$..set_seed)
            self$.addOption(private$..seed_value)
            self$.addOption(private$..parallel_processing)
            self$.addOption(private$..verbose_output)
        }),
    active = list(
        vars = function() private$..vars$value,
        facs = function() private$..facs$value,
        target = function() private$..target$value,
        targetLevel = function() private$..targetLevel$value,
        include_cart = function() private$..include_cart$value,
        include_rf = function() private$..include_rf$value,
        include_gbm = function() private$..include_gbm$value,
        include_xgboost = function() private$..include_xgboost$value,
        include_ctree = function() private$..include_ctree$value,
        validation = function() private$..validation$value,
        cv_folds = function() private$..cv_folds$value,
        cv_repeats = function() private$..cv_repeats$value,
        bootstrap_samples = function() private$..bootstrap_samples$value,
        test_split = function() private$..test_split$value,
        stratified_sampling = function() private$..stratified_sampling$value,
        primary_metric = function() private$..primary_metric$value,
        statistical_testing = function() private$..statistical_testing$value,
        correction_method = function() private$..correction_method$value,
        tune_parameters = function() private$..tune_parameters$value,
        tuning_method = function() private$..tuning_method$value,
        cart_max_depth = function() private$..cart_max_depth$value,
        cart_min_split = function() private$..cart_min_split$value,
        rf_ntrees = function() private$..rf_ntrees$value,
        rf_mtry_method = function() private$..rf_mtry_method$value,
        clinical_context = function() private$..clinical_context$value,
        interpretability_weight = function() private$..interpretability_weight$value,
        show_comparison_table = function() private$..show_comparison_table$value,
        show_performance_plot = function() private$..show_performance_plot$value,
        show_roc_comparison = function() private$..show_roc_comparison$value,
        show_statistical_tests = function() private$..show_statistical_tests$value,
        show_ranking_table = function() private$..show_ranking_table$value,
        show_computational_time = function() private$..show_computational_time$value,
        show_clinical_recommendations = function() private$..show_clinical_recommendations$value,
        show_detailed_metrics = function() private$..show_detailed_metrics$value,
        ensemble_best_models = function() private$..ensemble_best_models$value,
        save_best_models = function() private$..save_best_models$value,
        set_seed = function() private$..set_seed$value,
        seed_value = function() private$..seed_value$value,
        parallel_processing = function() private$..parallel_processing$value,
        verbose_output = function() private$..verbose_output$value),
    private = list(
        ..vars = NA,
        ..facs = NA,
        ..target = NA,
        ..targetLevel = NA,
        ..include_cart = NA,
        ..include_rf = NA,
        ..include_gbm = NA,
        ..include_xgboost = NA,
        ..include_ctree = NA,
        ..validation = NA,
        ..cv_folds = NA,
        ..cv_repeats = NA,
        ..bootstrap_samples = NA,
        ..test_split = NA,
        ..stratified_sampling = NA,
        ..primary_metric = NA,
        ..statistical_testing = NA,
        ..correction_method = NA,
        ..tune_parameters = NA,
        ..tuning_method = NA,
        ..cart_max_depth = NA,
        ..cart_min_split = NA,
        ..rf_ntrees = NA,
        ..rf_mtry_method = NA,
        ..clinical_context = NA,
        ..interpretability_weight = NA,
        ..show_comparison_table = NA,
        ..show_performance_plot = NA,
        ..show_roc_comparison = NA,
        ..show_statistical_tests = NA,
        ..show_ranking_table = NA,
        ..show_computational_time = NA,
        ..show_clinical_recommendations = NA,
        ..show_detailed_metrics = NA,
        ..ensemble_best_models = NA,
        ..save_best_models = NA,
        ..set_seed = NA,
        ..seed_value = NA,
        ..parallel_processing = NA,
        ..verbose_output = NA)
)

treecompareResults <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "treecompareResults",
    inherit = jmvcore::Group,
    active = list(
        instructions = function() private$.items[["instructions"]],
        algorithm_summary = function() private$.items[["algorithm_summary"]],
        comparison_table = function() private$.items[["comparison_table"]],
        performance_plot = function() private$.items[["performance_plot"]],
        roc_comparison = function() private$.items[["roc_comparison"]],
        statistical_tests = function() private$.items[["statistical_tests"]],
        ranking_table = function() private$.items[["ranking_table"]],
        clinical_recommendations = function() private$.items[["clinical_recommendations"]]),
    private = list(),
    public=list(
        initialize=function(options) {
            super$initialize(
                options=options,
                name="",
                title="Clinical Tree Algorithm Comparison",
                refs=list(
                    "ClinicoPathJamoviModule",
                    "rpart",
                    "randomForest",
                    "gbm",
                    "caret",
                    "pROC",
                    "ggplot2"))
            self$add(jmvcore::Html$new(
                options=options,
                name="instructions",
                title="Instructions",
                visible=FALSE,
                clearWith=list()))
            self$add(jmvcore::Html$new(
                options=options,
                name="algorithm_summary",
                title="Algorithm Summary",
                visible="(show_comparison_table)",
                clearWith=list(
                    "include_cart",
                    "include_rf",
                    "include_gbm",
                    "include_xgboost",
                    "include_ctree")))
            self$add(jmvcore::Table$new(
                options=options,
                name="comparison_table",
                title="Algorithm Comparison",
                visible="(show_comparison_table)",
                clearWith=list(
                    "vars",
                    "facs",
                    "target",
                    "targetLevel",
                    "validation",
                    "primary_metric"),
                columns=list(
                    list(
                        `name`="algorithm", 
                        `title`="Algorithm", 
                        `type`="text"),
                    list(
                        `name`="accuracy", 
                        `title`="Accuracy", 
                        `type`="number"),
                    list(
                        `name`="bacc", 
                        `title`="Balanced Accuracy", 
                        `type`="number"),
                    list(
                        `name`="auc", 
                        `title`="AUC", 
                        `type`="number"),
                    list(
                        `name`="sensitivity", 
                        `title`="Sensitivity", 
                        `type`="number"),
                    list(
                        `name`="specificity", 
                        `title`="Specificity", 
                        `type`="number"),
                    list(
                        `name`="f1_score", 
                        `title`="F1 Score", 
                        `type`="number"),
                    list(
                        `name`="computation_time", 
                        `title`="Time (sec)", 
                        `type`="number"))))
            self$add(jmvcore::Image$new(
                options=options,
                name="performance_plot",
                title="Performance Comparison",
                width=800,
                height=600,
                renderFun=".performance_plot",
                visible="(show_performance_plot)",
                clearWith=list(
                    "vars",
                    "facs",
                    "target",
                    "targetLevel",
                    "primary_metric")))
            self$add(jmvcore::Image$new(
                options=options,
                name="roc_comparison",
                title="ROC Comparison",
                width=700,
                height=500,
                renderFun=".roc_plot",
                visible="(show_roc_comparison)",
                clearWith=list(
                    "vars",
                    "facs",
                    "target",
                    "targetLevel")))
            self$add(jmvcore::Table$new(
                options=options,
                name="statistical_tests",
                title="Statistical Test Results",
                visible="(show_statistical_tests && statistical_testing)",
                clearWith=list(
                    "vars",
                    "facs",
                    "target",
                    "targetLevel",
                    "correction_method"),
                columns=list(
                    list(
                        `name`="comparison", 
                        `title`="Comparison", 
                        `type`="text"),
                    list(
                        `name`="statistic", 
                        `title`="Test Statistic", 
                        `type`="number"),
                    list(
                        `name`="p_value", 
                        `title`="P-value", 
                        `type`="number"),
                    list(
                        `name`="p_adjusted", 
                        `title`="Adjusted P-value", 
                        `type`="number"),
                    list(
                        `name`="significance", 
                        `title`="Significant", 
                        `type`="text"))))
            self$add(jmvcore::Table$new(
                options=options,
                name="ranking_table",
                title="Algorithm Ranking",
                visible="(show_ranking_table)",
                clearWith=list(
                    "primary_metric",
                    "interpretability_weight",
                    "clinical_context"),
                columns=list(
                    list(
                        `name`="rank", 
                        `title`="Rank", 
                        `type`="integer"),
                    list(
                        `name`="algorithm", 
                        `title`="Algorithm", 
                        `type`="text"),
                    list(
                        `name`="performance_score", 
                        `title`="Performance Score", 
                        `type`="number"),
                    list(
                        `name`="interpretability_score", 
                        `title`="Interpretability Score", 
                        `type`="number"),
                    list(
                        `name`="combined_score", 
                        `title`="Combined Score", 
                        `type`="number"),
                    list(
                        `name`="recommendation", 
                        `title`="Recommendation", 
                        `type`="text"))))
            self$add(jmvcore::Html$new(
                options=options,
                name="clinical_recommendations",
                title="Clinical Recommendations",
                visible="(show_clinical_recommendations)",
                clearWith=list(
                    "clinical_context",
                    "interpretability_weight",
                    "primary_metric")))}))

treecompareBase <- if (requireNamespace("jmvcore", quietly=TRUE)) R6::R6Class(
    "treecompareBase",
    inherit = jmvcore::Analysis,
    public = list(
        initialize = function(options, data=NULL, datasetId="", analysisId="", revision=0) {
            super$initialize(
                package = "ClinicoPath",
                name = "treecompare",
                version = c(0,0,31),
                options = options,
                results = treecompareResults$new(options=options),
                data = data,
                datasetId = datasetId,
                analysisId = analysisId,
                revision = revision,
                pause = NULL,
                completeWhenFilled = FALSE,
                requiresMissings = FALSE,
                weightsSupport = 'auto')
        }))

#' Clinical Tree Algorithm Comparison
#'
#' Comprehensive comparison of decision tree algorithms for clinical research.
#' Compares CART, Random Forest, and Gradient Boosting with cross-validation,
#' statistical testing, and clinical performance assessment.
#' 
#'
#' @examples
#' # Compare multiple tree algorithms
#' treecomparison(
#'     data = clinical_data,
#'     vars = c("biomarker1", "biomarker2", "age"),
#'     facs = c("grade", "stage"),
#'     target = "outcome",
#'     targetLevel = "positive",
#'     algorithms = c("cart", "rf", "gbm"),
#'     validation = "repeated_cv"
#' )
#'
#' @param data The data as a data frame for algorithm comparison.
#' @param vars .
#' @param facs .
#' @param target .
#' @param targetLevel .
#' @param include_cart Include Classification and Regression Trees (CART)
#'   algorithm.
#' @param include_rf Include Random Forest ensemble method.
#' @param include_gbm Include Gradient Boosting Machine (requires gbm
#'   package).
#' @param include_xgboost Include XGBoost algorithm (requires xgboost
#'   package).
#' @param include_ctree Include conditional inference trees (requires party
#'   package).
#' @param validation Validation method for fair algorithm comparison.
#' @param cv_folds .
#' @param cv_repeats .
#' @param bootstrap_samples .
#' @param test_split .
#' @param stratified_sampling .
#' @param primary_metric Primary metric for ranking algorithms.
#' @param statistical_testing Perform statistical tests to compare algorithm
#'   performance.
#' @param correction_method Correction method for multiple pairwise
#'   comparisons.
#' @param tune_parameters Automatically tune key parameters for each
#'   algorithm.
#' @param tuning_method .
#' @param cart_max_depth .
#' @param cart_min_split .
#' @param rf_ntrees .
#' @param rf_mtry_method .
#' @param clinical_context .
#' @param interpretability_weight Weight given to interpretability in final
#'   recommendations (0=performance only, 1=interpretability only).
#' @param show_comparison_table Display comprehensive comparison table with
#'   all metrics.
#' @param show_performance_plot Display box plots comparing algorithm
#'   performance.
#' @param show_roc_comparison Display overlaid ROC curves for all algorithms.
#' @param show_statistical_tests Display pairwise statistical test results.
#' @param show_ranking_table Display final algorithm ranking with
#'   recommendations.
#' @param show_computational_time Include computational time in comparison.
#' @param show_clinical_recommendations Provide clinical recommendations based
#'   on comparison results.
#' @param show_detailed_metrics Show detailed metrics for each algorithm
#'   (sensitivity, specificity, etc.).
#' @param ensemble_best_models Create ensemble combining top-performing
#'   algorithms.
#' @param save_best_models Save the best-performing models for future use.
#' @param set_seed .
#' @param seed_value .
#' @param parallel_processing Use multiple cores for faster comparison (if
#'   available).
#' @param verbose_output Show detailed progress during model comparison.
#' @return A results object containing:
#' \tabular{llllll}{
#'   \code{results$instructions} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$algorithm_summary} \tab \tab \tab \tab \tab a html \cr
#'   \code{results$comparison_table} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$performance_plot} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$roc_comparison} \tab \tab \tab \tab \tab an image \cr
#'   \code{results$statistical_tests} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$ranking_table} \tab \tab \tab \tab \tab a table \cr
#'   \code{results$clinical_recommendations} \tab \tab \tab \tab \tab a html \cr
#' }
#'
#' Tables can be converted to data frames with \code{asDF} or \code{\link{as.data.frame}}. For example:
#'
#' \code{results$comparison_table$asDF}
#'
#' \code{as.data.frame(results$comparison_table)}
#'
#' @export
treecompare <- function(
    data,
    vars = NULL,
    facs = NULL,
    target,
    targetLevel,
    include_cart = TRUE,
    include_rf = TRUE,
    include_gbm = FALSE,
    include_xgboost = FALSE,
    include_ctree = FALSE,
    validation = "repeated_cv",
    cv_folds = 5,
    cv_repeats = 5,
    bootstrap_samples = 200,
    test_split = 0.25,
    stratified_sampling = TRUE,
    primary_metric = "bacc",
    statistical_testing = TRUE,
    correction_method = "holm",
    tune_parameters = TRUE,
    tuning_method = "grid",
    cart_max_depth = 5,
    cart_min_split = 20,
    rf_ntrees = 500,
    rf_mtry_method = "auto",
    clinical_context = "diagnosis",
    interpretability_weight = 0.3,
    show_comparison_table = TRUE,
    show_performance_plot = TRUE,
    show_roc_comparison = TRUE,
    show_statistical_tests = TRUE,
    show_ranking_table = TRUE,
    show_computational_time = TRUE,
    show_clinical_recommendations = TRUE,
    show_detailed_metrics = FALSE,
    ensemble_best_models = FALSE,
    save_best_models = FALSE,
    set_seed = TRUE,
    seed_value = 42,
    parallel_processing = TRUE,
    verbose_output = FALSE) {

    if ( ! requireNamespace("jmvcore", quietly=TRUE))
        stop("treecompare requires jmvcore to be installed (restart may be required)")

    if ( ! missing(vars)) vars <- jmvcore::resolveQuo(jmvcore::enquo(vars))
    if ( ! missing(facs)) facs <- jmvcore::resolveQuo(jmvcore::enquo(facs))
    if ( ! missing(target)) target <- jmvcore::resolveQuo(jmvcore::enquo(target))
    if (missing(data))
        data <- jmvcore::marshalData(
            parent.frame(),
            `if`( ! missing(vars), vars, NULL),
            `if`( ! missing(facs), facs, NULL),
            `if`( ! missing(target), target, NULL))

    for (v in facs) if (v %in% names(data)) data[[v]] <- as.factor(data[[v]])
    for (v in target) if (v %in% names(data)) data[[v]] <- as.factor(data[[v]])

    options <- treecompareOptions$new(
        vars = vars,
        facs = facs,
        target = target,
        targetLevel = targetLevel,
        include_cart = include_cart,
        include_rf = include_rf,
        include_gbm = include_gbm,
        include_xgboost = include_xgboost,
        include_ctree = include_ctree,
        validation = validation,
        cv_folds = cv_folds,
        cv_repeats = cv_repeats,
        bootstrap_samples = bootstrap_samples,
        test_split = test_split,
        stratified_sampling = stratified_sampling,
        primary_metric = primary_metric,
        statistical_testing = statistical_testing,
        correction_method = correction_method,
        tune_parameters = tune_parameters,
        tuning_method = tuning_method,
        cart_max_depth = cart_max_depth,
        cart_min_split = cart_min_split,
        rf_ntrees = rf_ntrees,
        rf_mtry_method = rf_mtry_method,
        clinical_context = clinical_context,
        interpretability_weight = interpretability_weight,
        show_comparison_table = show_comparison_table,
        show_performance_plot = show_performance_plot,
        show_roc_comparison = show_roc_comparison,
        show_statistical_tests = show_statistical_tests,
        show_ranking_table = show_ranking_table,
        show_computational_time = show_computational_time,
        show_clinical_recommendations = show_clinical_recommendations,
        show_detailed_metrics = show_detailed_metrics,
        ensemble_best_models = ensemble_best_models,
        save_best_models = save_best_models,
        set_seed = set_seed,
        seed_value = seed_value,
        parallel_processing = parallel_processing,
        verbose_output = verbose_output)

    analysis <- treecompareClass$new(
        options = options,
        data = data)

    analysis$run()

    analysis$results
}

